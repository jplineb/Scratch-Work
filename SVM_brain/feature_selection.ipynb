{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Imports"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "import pandas as pd\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import KFold, cross_validate, LeaveOneOut\n",
    "from sklearn.feature_selection import SequentialFeatureSelector, SelectFromModel\n",
    "import time\n",
    "import numpy as np"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Read data in"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "# read from csv\n",
    "data_df = pd.read_csv('./data/eig_centrality.csv', header=None)\n",
    "# drop columns with zeros\n",
    "data_df = data_df.loc[:, (data_df != 0).any(axis=0)]\n",
    "data_df.head(20)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "    0         1         2         6         7         10        12        13   \\\n",
       "0     1 -0.067894 -0.062832 -0.031240 -0.071004 -0.030888  0.009534  0.044660   \n",
       "1     1  0.031793  0.025996  0.122030  0.109220 -0.005733  0.017223 -0.072822   \n",
       "2     1 -0.005251 -0.015806 -0.124040 -0.117020 -0.017355 -0.035984  0.106950   \n",
       "3     1  0.123150  0.096576 -0.045236 -0.005143 -0.017959 -0.060064  0.008232   \n",
       "4     1 -0.059846 -0.024500 -0.022105  0.022153  0.079495 -0.013115  0.019867   \n",
       "5     1 -0.047201 -0.023249  0.107190  0.117740 -0.010293 -0.040863 -0.098316   \n",
       "6     1 -0.089435 -0.080275  0.001140 -0.014447  0.027198 -0.026102  0.116720   \n",
       "7     1 -0.092537  0.003668 -0.129430 -0.107730  0.088690  0.042226  0.059388   \n",
       "8     1  0.022265  0.048711  0.048122  0.032252  0.037123 -0.059852  0.011789   \n",
       "9     1 -0.111080 -0.023740 -0.027010 -0.011543  0.089719  0.020014  0.013929   \n",
       "10    1 -0.106100 -0.110970 -0.030248  0.030623  0.060585 -0.005032 -0.020973   \n",
       "11    1  0.034145 -0.039078 -0.023830  0.007204 -0.005666 -0.064902  0.085135   \n",
       "12    1  0.015845 -0.010190  0.047412  0.037297 -0.003051 -0.042403  0.036934   \n",
       "13    1  0.060620  0.072223  0.024636  0.047925 -0.034810 -0.080044  0.065747   \n",
       "14    1 -0.065751 -0.060281 -0.032463 -0.013963  0.071757  0.014257 -0.072555   \n",
       "15    1  0.077271  0.046050  0.092528  0.043404  0.071967 -0.061013 -0.033032   \n",
       "16    1  0.001816  0.000318 -0.095647 -0.043152 -0.006485 -0.028258  0.095140   \n",
       "17    1  0.032649  0.059311 -0.093003 -0.073314 -0.050774 -0.057127  0.055778   \n",
       "18    1  0.147730  0.147670  0.104270  0.031001  0.043729 -0.028454  0.040738   \n",
       "19    1 -0.020742 -0.016114 -0.147870 -0.098222 -0.046168  0.009317  0.080326   \n",
       "\n",
       "         14        15   ...       285       286           287           288  \\\n",
       "0   0.043163  0.025440  ... -0.112760 -0.106070  0.000000e+00  0.000000e+00   \n",
       "1  -0.077072 -0.126650  ...  0.078364  0.049836  0.000000e+00  6.938900e-18   \n",
       "2   0.011851  0.077032  ...  0.021125  0.014470  0.000000e+00 -1.734700e-18   \n",
       "3  -0.076910 -0.042061  ... -0.043127 -0.024063  5.551100e-17 -1.110200e-16   \n",
       "4   0.032033  0.012232  ... -0.026404 -0.004397 -4.336800e-19  0.000000e+00   \n",
       "5  -0.047187 -0.101880  ... -0.047042 -0.084535  0.000000e+00  0.000000e+00   \n",
       "6   0.049616  0.060910  ... -0.005671 -0.003008  0.000000e+00  0.000000e+00   \n",
       "7   0.037930  0.075362  ... -0.015637  0.001023  2.168400e-19  0.000000e+00   \n",
       "8  -0.071290 -0.109800  ... -0.021779 -0.004315  2.710500e-20  0.000000e+00   \n",
       "9   0.058090  0.067178  ...  0.011984  0.053828 -6.938900e-18 -2.775600e-17   \n",
       "10 -0.019673  0.024242  ...  0.062965  0.062940  0.000000e+00  0.000000e+00   \n",
       "11 -0.042658  0.024541  ...  0.061231  0.028997  0.000000e+00  0.000000e+00   \n",
       "12 -0.075555 -0.095181  ... -0.009173  0.024759  0.000000e+00  0.000000e+00   \n",
       "13 -0.069461 -0.060218  ...  0.072504  0.054831  0.000000e+00  0.000000e+00   \n",
       "14  0.018194  0.052000  ... -0.044134 -0.021904  0.000000e+00  5.551100e-17   \n",
       "15 -0.022241  0.021110  ...  0.024254  0.070240  0.000000e+00  0.000000e+00   \n",
       "16  0.027813  0.032435  ... -0.037356 -0.029204  0.000000e+00 -8.673600e-19   \n",
       "17  0.093240  0.068316  ... -0.059713 -0.064066  0.000000e+00  0.000000e+00   \n",
       "18 -0.023784  0.067811  ... -0.012005 -0.010442  0.000000e+00  0.000000e+00   \n",
       "19  0.001634  0.132280  ... -0.070365 -0.057702  4.336800e-19  0.000000e+00   \n",
       "\n",
       "         289       290       291       292       293       294  \n",
       "0  -0.028195 -0.024616 -0.042535 -0.087451  0.003145 -0.047196  \n",
       "1  -0.076947 -0.078418 -0.064815  0.095082  0.054585  0.076347  \n",
       "2   0.068705  0.084321  0.047107  0.004649 -0.142760 -0.129450  \n",
       "3  -0.064510 -0.100380 -0.112950 -0.099919 -0.006036 -0.004228  \n",
       "4  -0.068379  0.006091 -0.050172  0.056009  0.077894  0.016500  \n",
       "5  -0.095798 -0.073266 -0.094619  0.084386  0.081942  0.105320  \n",
       "6  -0.009444  0.036900 -0.022935  0.029724 -0.020147 -0.023445  \n",
       "7   0.038453  0.111860  0.055049 -0.015476 -0.125960 -0.093968  \n",
       "8  -0.099726 -0.076015 -0.106140 -0.054908  0.038627  0.040091  \n",
       "9   0.059277  0.059997  0.101670  0.027837  0.029670  0.012809  \n",
       "10  0.101570  0.085317  0.101270  0.063186  0.042160  0.058404  \n",
       "11 -0.069128 -0.077827 -0.086727 -0.001458  0.028661  0.035871  \n",
       "12  0.000118 -0.034657 -0.012382 -0.021506  0.046270  0.051170  \n",
       "13 -0.105420 -0.109090 -0.120680  0.102510  0.030498  0.024234  \n",
       "14 -0.040422 -0.048511 -0.059853 -0.025872 -0.018114  0.004071  \n",
       "15  0.028435 -0.008305  0.058356  0.010474  0.074882  0.065339  \n",
       "16  0.111630  0.083624  0.074023 -0.076411 -0.071452 -0.099498  \n",
       "17  0.058057  0.064412  0.039438 -0.008334 -0.008848 -0.091850  \n",
       "18 -0.104330 -0.082659 -0.101880  0.038813  0.119490  0.069471  \n",
       "19 -0.021462  0.060300 -0.033271 -0.008966 -0.105530 -0.112170  \n",
       "\n",
       "[20 rows x 274 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>10</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>...</th>\n",
       "      <th>285</th>\n",
       "      <th>286</th>\n",
       "      <th>287</th>\n",
       "      <th>288</th>\n",
       "      <th>289</th>\n",
       "      <th>290</th>\n",
       "      <th>291</th>\n",
       "      <th>292</th>\n",
       "      <th>293</th>\n",
       "      <th>294</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.067894</td>\n",
       "      <td>-0.062832</td>\n",
       "      <td>-0.031240</td>\n",
       "      <td>-0.071004</td>\n",
       "      <td>-0.030888</td>\n",
       "      <td>0.009534</td>\n",
       "      <td>0.044660</td>\n",
       "      <td>0.043163</td>\n",
       "      <td>0.025440</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.112760</td>\n",
       "      <td>-0.106070</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-0.028195</td>\n",
       "      <td>-0.024616</td>\n",
       "      <td>-0.042535</td>\n",
       "      <td>-0.087451</td>\n",
       "      <td>0.003145</td>\n",
       "      <td>-0.047196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.031793</td>\n",
       "      <td>0.025996</td>\n",
       "      <td>0.122030</td>\n",
       "      <td>0.109220</td>\n",
       "      <td>-0.005733</td>\n",
       "      <td>0.017223</td>\n",
       "      <td>-0.072822</td>\n",
       "      <td>-0.077072</td>\n",
       "      <td>-0.126650</td>\n",
       "      <td>...</td>\n",
       "      <td>0.078364</td>\n",
       "      <td>0.049836</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>6.938900e-18</td>\n",
       "      <td>-0.076947</td>\n",
       "      <td>-0.078418</td>\n",
       "      <td>-0.064815</td>\n",
       "      <td>0.095082</td>\n",
       "      <td>0.054585</td>\n",
       "      <td>0.076347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.005251</td>\n",
       "      <td>-0.015806</td>\n",
       "      <td>-0.124040</td>\n",
       "      <td>-0.117020</td>\n",
       "      <td>-0.017355</td>\n",
       "      <td>-0.035984</td>\n",
       "      <td>0.106950</td>\n",
       "      <td>0.011851</td>\n",
       "      <td>0.077032</td>\n",
       "      <td>...</td>\n",
       "      <td>0.021125</td>\n",
       "      <td>0.014470</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-1.734700e-18</td>\n",
       "      <td>0.068705</td>\n",
       "      <td>0.084321</td>\n",
       "      <td>0.047107</td>\n",
       "      <td>0.004649</td>\n",
       "      <td>-0.142760</td>\n",
       "      <td>-0.129450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0.123150</td>\n",
       "      <td>0.096576</td>\n",
       "      <td>-0.045236</td>\n",
       "      <td>-0.005143</td>\n",
       "      <td>-0.017959</td>\n",
       "      <td>-0.060064</td>\n",
       "      <td>0.008232</td>\n",
       "      <td>-0.076910</td>\n",
       "      <td>-0.042061</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.043127</td>\n",
       "      <td>-0.024063</td>\n",
       "      <td>5.551100e-17</td>\n",
       "      <td>-1.110200e-16</td>\n",
       "      <td>-0.064510</td>\n",
       "      <td>-0.100380</td>\n",
       "      <td>-0.112950</td>\n",
       "      <td>-0.099919</td>\n",
       "      <td>-0.006036</td>\n",
       "      <td>-0.004228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.059846</td>\n",
       "      <td>-0.024500</td>\n",
       "      <td>-0.022105</td>\n",
       "      <td>0.022153</td>\n",
       "      <td>0.079495</td>\n",
       "      <td>-0.013115</td>\n",
       "      <td>0.019867</td>\n",
       "      <td>0.032033</td>\n",
       "      <td>0.012232</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.026404</td>\n",
       "      <td>-0.004397</td>\n",
       "      <td>-4.336800e-19</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-0.068379</td>\n",
       "      <td>0.006091</td>\n",
       "      <td>-0.050172</td>\n",
       "      <td>0.056009</td>\n",
       "      <td>0.077894</td>\n",
       "      <td>0.016500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.047201</td>\n",
       "      <td>-0.023249</td>\n",
       "      <td>0.107190</td>\n",
       "      <td>0.117740</td>\n",
       "      <td>-0.010293</td>\n",
       "      <td>-0.040863</td>\n",
       "      <td>-0.098316</td>\n",
       "      <td>-0.047187</td>\n",
       "      <td>-0.101880</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.047042</td>\n",
       "      <td>-0.084535</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-0.095798</td>\n",
       "      <td>-0.073266</td>\n",
       "      <td>-0.094619</td>\n",
       "      <td>0.084386</td>\n",
       "      <td>0.081942</td>\n",
       "      <td>0.105320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.089435</td>\n",
       "      <td>-0.080275</td>\n",
       "      <td>0.001140</td>\n",
       "      <td>-0.014447</td>\n",
       "      <td>0.027198</td>\n",
       "      <td>-0.026102</td>\n",
       "      <td>0.116720</td>\n",
       "      <td>0.049616</td>\n",
       "      <td>0.060910</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.005671</td>\n",
       "      <td>-0.003008</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-0.009444</td>\n",
       "      <td>0.036900</td>\n",
       "      <td>-0.022935</td>\n",
       "      <td>0.029724</td>\n",
       "      <td>-0.020147</td>\n",
       "      <td>-0.023445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.092537</td>\n",
       "      <td>0.003668</td>\n",
       "      <td>-0.129430</td>\n",
       "      <td>-0.107730</td>\n",
       "      <td>0.088690</td>\n",
       "      <td>0.042226</td>\n",
       "      <td>0.059388</td>\n",
       "      <td>0.037930</td>\n",
       "      <td>0.075362</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.015637</td>\n",
       "      <td>0.001023</td>\n",
       "      <td>2.168400e-19</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.038453</td>\n",
       "      <td>0.111860</td>\n",
       "      <td>0.055049</td>\n",
       "      <td>-0.015476</td>\n",
       "      <td>-0.125960</td>\n",
       "      <td>-0.093968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>0.022265</td>\n",
       "      <td>0.048711</td>\n",
       "      <td>0.048122</td>\n",
       "      <td>0.032252</td>\n",
       "      <td>0.037123</td>\n",
       "      <td>-0.059852</td>\n",
       "      <td>0.011789</td>\n",
       "      <td>-0.071290</td>\n",
       "      <td>-0.109800</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.021779</td>\n",
       "      <td>-0.004315</td>\n",
       "      <td>2.710500e-20</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-0.099726</td>\n",
       "      <td>-0.076015</td>\n",
       "      <td>-0.106140</td>\n",
       "      <td>-0.054908</td>\n",
       "      <td>0.038627</td>\n",
       "      <td>0.040091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.111080</td>\n",
       "      <td>-0.023740</td>\n",
       "      <td>-0.027010</td>\n",
       "      <td>-0.011543</td>\n",
       "      <td>0.089719</td>\n",
       "      <td>0.020014</td>\n",
       "      <td>0.013929</td>\n",
       "      <td>0.058090</td>\n",
       "      <td>0.067178</td>\n",
       "      <td>...</td>\n",
       "      <td>0.011984</td>\n",
       "      <td>0.053828</td>\n",
       "      <td>-6.938900e-18</td>\n",
       "      <td>-2.775600e-17</td>\n",
       "      <td>0.059277</td>\n",
       "      <td>0.059997</td>\n",
       "      <td>0.101670</td>\n",
       "      <td>0.027837</td>\n",
       "      <td>0.029670</td>\n",
       "      <td>0.012809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.106100</td>\n",
       "      <td>-0.110970</td>\n",
       "      <td>-0.030248</td>\n",
       "      <td>0.030623</td>\n",
       "      <td>0.060585</td>\n",
       "      <td>-0.005032</td>\n",
       "      <td>-0.020973</td>\n",
       "      <td>-0.019673</td>\n",
       "      <td>0.024242</td>\n",
       "      <td>...</td>\n",
       "      <td>0.062965</td>\n",
       "      <td>0.062940</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.101570</td>\n",
       "      <td>0.085317</td>\n",
       "      <td>0.101270</td>\n",
       "      <td>0.063186</td>\n",
       "      <td>0.042160</td>\n",
       "      <td>0.058404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>0.034145</td>\n",
       "      <td>-0.039078</td>\n",
       "      <td>-0.023830</td>\n",
       "      <td>0.007204</td>\n",
       "      <td>-0.005666</td>\n",
       "      <td>-0.064902</td>\n",
       "      <td>0.085135</td>\n",
       "      <td>-0.042658</td>\n",
       "      <td>0.024541</td>\n",
       "      <td>...</td>\n",
       "      <td>0.061231</td>\n",
       "      <td>0.028997</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-0.069128</td>\n",
       "      <td>-0.077827</td>\n",
       "      <td>-0.086727</td>\n",
       "      <td>-0.001458</td>\n",
       "      <td>0.028661</td>\n",
       "      <td>0.035871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "      <td>0.015845</td>\n",
       "      <td>-0.010190</td>\n",
       "      <td>0.047412</td>\n",
       "      <td>0.037297</td>\n",
       "      <td>-0.003051</td>\n",
       "      <td>-0.042403</td>\n",
       "      <td>0.036934</td>\n",
       "      <td>-0.075555</td>\n",
       "      <td>-0.095181</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009173</td>\n",
       "      <td>0.024759</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000118</td>\n",
       "      <td>-0.034657</td>\n",
       "      <td>-0.012382</td>\n",
       "      <td>-0.021506</td>\n",
       "      <td>0.046270</td>\n",
       "      <td>0.051170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1</td>\n",
       "      <td>0.060620</td>\n",
       "      <td>0.072223</td>\n",
       "      <td>0.024636</td>\n",
       "      <td>0.047925</td>\n",
       "      <td>-0.034810</td>\n",
       "      <td>-0.080044</td>\n",
       "      <td>0.065747</td>\n",
       "      <td>-0.069461</td>\n",
       "      <td>-0.060218</td>\n",
       "      <td>...</td>\n",
       "      <td>0.072504</td>\n",
       "      <td>0.054831</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-0.105420</td>\n",
       "      <td>-0.109090</td>\n",
       "      <td>-0.120680</td>\n",
       "      <td>0.102510</td>\n",
       "      <td>0.030498</td>\n",
       "      <td>0.024234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.065751</td>\n",
       "      <td>-0.060281</td>\n",
       "      <td>-0.032463</td>\n",
       "      <td>-0.013963</td>\n",
       "      <td>0.071757</td>\n",
       "      <td>0.014257</td>\n",
       "      <td>-0.072555</td>\n",
       "      <td>0.018194</td>\n",
       "      <td>0.052000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.044134</td>\n",
       "      <td>-0.021904</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>5.551100e-17</td>\n",
       "      <td>-0.040422</td>\n",
       "      <td>-0.048511</td>\n",
       "      <td>-0.059853</td>\n",
       "      <td>-0.025872</td>\n",
       "      <td>-0.018114</td>\n",
       "      <td>0.004071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1</td>\n",
       "      <td>0.077271</td>\n",
       "      <td>0.046050</td>\n",
       "      <td>0.092528</td>\n",
       "      <td>0.043404</td>\n",
       "      <td>0.071967</td>\n",
       "      <td>-0.061013</td>\n",
       "      <td>-0.033032</td>\n",
       "      <td>-0.022241</td>\n",
       "      <td>0.021110</td>\n",
       "      <td>...</td>\n",
       "      <td>0.024254</td>\n",
       "      <td>0.070240</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.028435</td>\n",
       "      <td>-0.008305</td>\n",
       "      <td>0.058356</td>\n",
       "      <td>0.010474</td>\n",
       "      <td>0.074882</td>\n",
       "      <td>0.065339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1</td>\n",
       "      <td>0.001816</td>\n",
       "      <td>0.000318</td>\n",
       "      <td>-0.095647</td>\n",
       "      <td>-0.043152</td>\n",
       "      <td>-0.006485</td>\n",
       "      <td>-0.028258</td>\n",
       "      <td>0.095140</td>\n",
       "      <td>0.027813</td>\n",
       "      <td>0.032435</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.037356</td>\n",
       "      <td>-0.029204</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-8.673600e-19</td>\n",
       "      <td>0.111630</td>\n",
       "      <td>0.083624</td>\n",
       "      <td>0.074023</td>\n",
       "      <td>-0.076411</td>\n",
       "      <td>-0.071452</td>\n",
       "      <td>-0.099498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1</td>\n",
       "      <td>0.032649</td>\n",
       "      <td>0.059311</td>\n",
       "      <td>-0.093003</td>\n",
       "      <td>-0.073314</td>\n",
       "      <td>-0.050774</td>\n",
       "      <td>-0.057127</td>\n",
       "      <td>0.055778</td>\n",
       "      <td>0.093240</td>\n",
       "      <td>0.068316</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.059713</td>\n",
       "      <td>-0.064066</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.058057</td>\n",
       "      <td>0.064412</td>\n",
       "      <td>0.039438</td>\n",
       "      <td>-0.008334</td>\n",
       "      <td>-0.008848</td>\n",
       "      <td>-0.091850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1</td>\n",
       "      <td>0.147730</td>\n",
       "      <td>0.147670</td>\n",
       "      <td>0.104270</td>\n",
       "      <td>0.031001</td>\n",
       "      <td>0.043729</td>\n",
       "      <td>-0.028454</td>\n",
       "      <td>0.040738</td>\n",
       "      <td>-0.023784</td>\n",
       "      <td>0.067811</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.012005</td>\n",
       "      <td>-0.010442</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-0.104330</td>\n",
       "      <td>-0.082659</td>\n",
       "      <td>-0.101880</td>\n",
       "      <td>0.038813</td>\n",
       "      <td>0.119490</td>\n",
       "      <td>0.069471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.020742</td>\n",
       "      <td>-0.016114</td>\n",
       "      <td>-0.147870</td>\n",
       "      <td>-0.098222</td>\n",
       "      <td>-0.046168</td>\n",
       "      <td>0.009317</td>\n",
       "      <td>0.080326</td>\n",
       "      <td>0.001634</td>\n",
       "      <td>0.132280</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.070365</td>\n",
       "      <td>-0.057702</td>\n",
       "      <td>4.336800e-19</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-0.021462</td>\n",
       "      <td>0.060300</td>\n",
       "      <td>-0.033271</td>\n",
       "      <td>-0.008966</td>\n",
       "      <td>-0.105530</td>\n",
       "      <td>-0.112170</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20 rows × 274 columns</p>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Pull X and y from dataframe"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "X = abs(data_df.iloc[:, 1:]) # take the absolute value\n",
    "y = data_df.iloc[:,0]\n",
    "\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(60, 273)\n",
      "(60,)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Forward Selection"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "source": [
    "# Init model\n",
    "clf = svm.SVC(C=1000, gamma='auto')\n",
    "\n",
    "# Get num features desired\n",
    "num_features = data_df.shape[1] - 1 # get total number of features\n",
    "num_features_del = 5 # number of features to take off\n",
    "final_features = num_features - num_features_del # final number of features in the model\n",
    "print(f'final features: {final_features}')\n",
    "\n",
    "# Call sequential features selector\n",
    "sfs = SequentialFeatureSelector(clf, n_features_to_select=final_features, cv=10, direction='forward')\n",
    "\n",
    "# Fit the model\n",
    "sfs.fit(X,y)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "final features: 268\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "SequentialFeatureSelector(cv=10, estimator=SVC(C=1000, gamma='auto'),\n",
       "                          n_features_to_select=268)"
      ]
     },
     "metadata": {},
     "execution_count": 72
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "source": [
    "sfs.get_support()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True, False,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True, False,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "       False,  True, False,  True,  True,  True, False,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True])"
      ]
     },
     "metadata": {},
     "execution_count": 73
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "source": [
    "# Get index of features that were dropped\n",
    "dropped_features = np.where(sfs.get_support() == False)[0]\n",
    "print(dropped_features)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[185 194 234 236 240]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## View dropped features"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "source": [
    "## Create empty dict for storing results\n",
    "dropped_dict = {}\n",
    "for index in dropped_features:\n",
    "    sample_points = X[index]\n",
    "    dropped_dict[index] = sample_points\n",
    "\n",
    "## Verify this works correctly\n",
    "print(dropped_dict.keys())"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "dict_keys([185, 194, 234, 236, 240])\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "source": [
    "## Create an empty data frame for easy usage\n",
    "pd.DataFrame(dropped_dict).head(60)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "         144       155       194       197       243\n",
       "0   0.009374  0.004708  0.045112  0.025727  0.083662\n",
       "1   0.002818  0.005332  0.028392  0.009401  0.004550\n",
       "2   0.034402  0.028343  0.039744  0.021268  0.082136\n",
       "3   0.038833  0.112050  0.014235  0.023948  0.040527\n",
       "4   0.029390  0.124250  0.073083  0.064858  0.001888\n",
       "5   0.002788  0.012017  0.038674  0.035372  0.058978\n",
       "6   0.010980  0.064797  0.024266  0.039258  0.030792\n",
       "7   0.000276  0.002665  0.045647  0.040691  0.037514\n",
       "8   0.081128  0.061879  0.037151  0.090069  0.067636\n",
       "9   0.031749  0.037143  0.138010  0.000997  0.012898\n",
       "10  0.122860  0.143350  0.000904  0.109400  0.017737\n",
       "11  0.061521  0.031803  0.061165  0.096513  0.033002\n",
       "12  0.093770  0.099894  0.067599  0.059404  0.102470\n",
       "13  0.073760  0.085986  0.039414  0.111420  0.061480\n",
       "14  0.037446  0.012344  0.083252  0.092185  0.047195\n",
       "15  0.047214  0.045350  0.064869  0.011771  0.117620\n",
       "16  0.049739  0.002623  0.031725  0.063142  0.042683\n",
       "17  0.053130  0.060902  0.005388  0.040109  0.012157\n",
       "18  0.010537  0.087256  0.004274  0.088147  0.108290\n",
       "19  0.057224  0.052130  0.071552  0.065242  0.039760\n",
       "20  0.028130  0.028104  0.054202  0.084840  0.033186\n",
       "21  0.006841  0.094776  0.038388  0.085518  0.019898\n",
       "22  0.005971  0.032481  0.013141  0.105180  0.025475\n",
       "23  0.018615  0.033793  0.077183  0.061131  0.001891\n",
       "24  0.018286  0.062214  0.084168  0.040156  0.054821\n",
       "25  0.063384  0.014204  0.074023  0.082981  0.047919\n",
       "26  0.085759  0.023443  0.019348  0.058783  0.032721\n",
       "27  0.010351  0.028587  0.006701  0.034447  0.011970\n",
       "28  0.074959  0.083005  0.073742  0.085666  0.062806\n",
       "29  0.084943  0.028982  0.029603  0.001463  0.025635\n",
       "30  0.025752  0.016323  0.046806  0.039097  0.056663\n",
       "31  0.064237  0.102640  0.078020  0.059600  0.074595\n",
       "32  0.070893  0.012319  0.027306  0.064815  0.058174\n",
       "33  0.010937  0.028137  0.003377  0.076863  0.051056\n",
       "34  0.040801  0.034082  0.004541  0.041781  0.039571\n",
       "35  0.127050  0.126340  0.029473  0.046998  0.015649\n",
       "36  0.138180  0.008807  0.081397  0.067573  0.032865\n",
       "37  0.030338  0.072010  0.094317  0.037831  0.023590\n",
       "38  0.038904  0.064125  0.034925  0.060519  0.031379\n",
       "39  0.062312  0.018367  0.065503  0.077586  0.057668\n",
       "40  0.000817  0.075721  0.055343  0.046788  0.032812\n",
       "41  0.062986  0.090655  0.018184  0.068967  0.057915\n",
       "42  0.104230  0.131640  0.034307  0.038768  0.067635\n",
       "43  0.043968  0.042087  0.038564  0.065275  0.018272\n",
       "44  0.070913  0.028977  0.065236  0.075464  0.042008\n",
       "45  0.025485  0.026218  0.049292  0.031216  0.042171\n",
       "46  0.024508  0.044706  0.010145  0.094825  0.066979\n",
       "47  0.098545  0.037387  0.071422  0.006064  0.020433\n",
       "48  0.094387  0.069987  0.004967  0.011472  0.040818\n",
       "49  0.071711  0.040297  0.046027  0.060420  0.091366\n",
       "50  0.024034  0.043750  0.023908  0.033419  0.041185\n",
       "51  0.088742  0.049511  0.098225  0.025211  0.090284\n",
       "52  0.074492  0.025830  0.041407  0.041174  0.057165\n",
       "53  0.054515  0.028565  0.030539  0.076687  0.020773\n",
       "54  0.017331  0.092784  0.031541  0.066901  0.066410\n",
       "55  0.123290  0.118200  0.049868  0.116170  0.026676\n",
       "56  0.034934  0.063352  0.028195  0.029997  0.060968\n",
       "57  0.060034  0.056963  0.070582  0.052786  0.025229\n",
       "58  0.030980  0.034354  0.065246  0.045543  0.061387\n",
       "59  0.069161  0.004781  0.081710  0.046290  0.006849"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>144</th>\n",
       "      <th>155</th>\n",
       "      <th>194</th>\n",
       "      <th>197</th>\n",
       "      <th>243</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.009374</td>\n",
       "      <td>0.004708</td>\n",
       "      <td>0.045112</td>\n",
       "      <td>0.025727</td>\n",
       "      <td>0.083662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.002818</td>\n",
       "      <td>0.005332</td>\n",
       "      <td>0.028392</td>\n",
       "      <td>0.009401</td>\n",
       "      <td>0.004550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.034402</td>\n",
       "      <td>0.028343</td>\n",
       "      <td>0.039744</td>\n",
       "      <td>0.021268</td>\n",
       "      <td>0.082136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.038833</td>\n",
       "      <td>0.112050</td>\n",
       "      <td>0.014235</td>\n",
       "      <td>0.023948</td>\n",
       "      <td>0.040527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.029390</td>\n",
       "      <td>0.124250</td>\n",
       "      <td>0.073083</td>\n",
       "      <td>0.064858</td>\n",
       "      <td>0.001888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.002788</td>\n",
       "      <td>0.012017</td>\n",
       "      <td>0.038674</td>\n",
       "      <td>0.035372</td>\n",
       "      <td>0.058978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.010980</td>\n",
       "      <td>0.064797</td>\n",
       "      <td>0.024266</td>\n",
       "      <td>0.039258</td>\n",
       "      <td>0.030792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.000276</td>\n",
       "      <td>0.002665</td>\n",
       "      <td>0.045647</td>\n",
       "      <td>0.040691</td>\n",
       "      <td>0.037514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.081128</td>\n",
       "      <td>0.061879</td>\n",
       "      <td>0.037151</td>\n",
       "      <td>0.090069</td>\n",
       "      <td>0.067636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.031749</td>\n",
       "      <td>0.037143</td>\n",
       "      <td>0.138010</td>\n",
       "      <td>0.000997</td>\n",
       "      <td>0.012898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.122860</td>\n",
       "      <td>0.143350</td>\n",
       "      <td>0.000904</td>\n",
       "      <td>0.109400</td>\n",
       "      <td>0.017737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.061521</td>\n",
       "      <td>0.031803</td>\n",
       "      <td>0.061165</td>\n",
       "      <td>0.096513</td>\n",
       "      <td>0.033002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.093770</td>\n",
       "      <td>0.099894</td>\n",
       "      <td>0.067599</td>\n",
       "      <td>0.059404</td>\n",
       "      <td>0.102470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.073760</td>\n",
       "      <td>0.085986</td>\n",
       "      <td>0.039414</td>\n",
       "      <td>0.111420</td>\n",
       "      <td>0.061480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.037446</td>\n",
       "      <td>0.012344</td>\n",
       "      <td>0.083252</td>\n",
       "      <td>0.092185</td>\n",
       "      <td>0.047195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.047214</td>\n",
       "      <td>0.045350</td>\n",
       "      <td>0.064869</td>\n",
       "      <td>0.011771</td>\n",
       "      <td>0.117620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.049739</td>\n",
       "      <td>0.002623</td>\n",
       "      <td>0.031725</td>\n",
       "      <td>0.063142</td>\n",
       "      <td>0.042683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.053130</td>\n",
       "      <td>0.060902</td>\n",
       "      <td>0.005388</td>\n",
       "      <td>0.040109</td>\n",
       "      <td>0.012157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.010537</td>\n",
       "      <td>0.087256</td>\n",
       "      <td>0.004274</td>\n",
       "      <td>0.088147</td>\n",
       "      <td>0.108290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.057224</td>\n",
       "      <td>0.052130</td>\n",
       "      <td>0.071552</td>\n",
       "      <td>0.065242</td>\n",
       "      <td>0.039760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.028130</td>\n",
       "      <td>0.028104</td>\n",
       "      <td>0.054202</td>\n",
       "      <td>0.084840</td>\n",
       "      <td>0.033186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.006841</td>\n",
       "      <td>0.094776</td>\n",
       "      <td>0.038388</td>\n",
       "      <td>0.085518</td>\n",
       "      <td>0.019898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.005971</td>\n",
       "      <td>0.032481</td>\n",
       "      <td>0.013141</td>\n",
       "      <td>0.105180</td>\n",
       "      <td>0.025475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.018615</td>\n",
       "      <td>0.033793</td>\n",
       "      <td>0.077183</td>\n",
       "      <td>0.061131</td>\n",
       "      <td>0.001891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.018286</td>\n",
       "      <td>0.062214</td>\n",
       "      <td>0.084168</td>\n",
       "      <td>0.040156</td>\n",
       "      <td>0.054821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.063384</td>\n",
       "      <td>0.014204</td>\n",
       "      <td>0.074023</td>\n",
       "      <td>0.082981</td>\n",
       "      <td>0.047919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.085759</td>\n",
       "      <td>0.023443</td>\n",
       "      <td>0.019348</td>\n",
       "      <td>0.058783</td>\n",
       "      <td>0.032721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.010351</td>\n",
       "      <td>0.028587</td>\n",
       "      <td>0.006701</td>\n",
       "      <td>0.034447</td>\n",
       "      <td>0.011970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.074959</td>\n",
       "      <td>0.083005</td>\n",
       "      <td>0.073742</td>\n",
       "      <td>0.085666</td>\n",
       "      <td>0.062806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.084943</td>\n",
       "      <td>0.028982</td>\n",
       "      <td>0.029603</td>\n",
       "      <td>0.001463</td>\n",
       "      <td>0.025635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.025752</td>\n",
       "      <td>0.016323</td>\n",
       "      <td>0.046806</td>\n",
       "      <td>0.039097</td>\n",
       "      <td>0.056663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.064237</td>\n",
       "      <td>0.102640</td>\n",
       "      <td>0.078020</td>\n",
       "      <td>0.059600</td>\n",
       "      <td>0.074595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.070893</td>\n",
       "      <td>0.012319</td>\n",
       "      <td>0.027306</td>\n",
       "      <td>0.064815</td>\n",
       "      <td>0.058174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.010937</td>\n",
       "      <td>0.028137</td>\n",
       "      <td>0.003377</td>\n",
       "      <td>0.076863</td>\n",
       "      <td>0.051056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.040801</td>\n",
       "      <td>0.034082</td>\n",
       "      <td>0.004541</td>\n",
       "      <td>0.041781</td>\n",
       "      <td>0.039571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.127050</td>\n",
       "      <td>0.126340</td>\n",
       "      <td>0.029473</td>\n",
       "      <td>0.046998</td>\n",
       "      <td>0.015649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.138180</td>\n",
       "      <td>0.008807</td>\n",
       "      <td>0.081397</td>\n",
       "      <td>0.067573</td>\n",
       "      <td>0.032865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.030338</td>\n",
       "      <td>0.072010</td>\n",
       "      <td>0.094317</td>\n",
       "      <td>0.037831</td>\n",
       "      <td>0.023590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.038904</td>\n",
       "      <td>0.064125</td>\n",
       "      <td>0.034925</td>\n",
       "      <td>0.060519</td>\n",
       "      <td>0.031379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.062312</td>\n",
       "      <td>0.018367</td>\n",
       "      <td>0.065503</td>\n",
       "      <td>0.077586</td>\n",
       "      <td>0.057668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.000817</td>\n",
       "      <td>0.075721</td>\n",
       "      <td>0.055343</td>\n",
       "      <td>0.046788</td>\n",
       "      <td>0.032812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.062986</td>\n",
       "      <td>0.090655</td>\n",
       "      <td>0.018184</td>\n",
       "      <td>0.068967</td>\n",
       "      <td>0.057915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0.104230</td>\n",
       "      <td>0.131640</td>\n",
       "      <td>0.034307</td>\n",
       "      <td>0.038768</td>\n",
       "      <td>0.067635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0.043968</td>\n",
       "      <td>0.042087</td>\n",
       "      <td>0.038564</td>\n",
       "      <td>0.065275</td>\n",
       "      <td>0.018272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0.070913</td>\n",
       "      <td>0.028977</td>\n",
       "      <td>0.065236</td>\n",
       "      <td>0.075464</td>\n",
       "      <td>0.042008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0.025485</td>\n",
       "      <td>0.026218</td>\n",
       "      <td>0.049292</td>\n",
       "      <td>0.031216</td>\n",
       "      <td>0.042171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0.024508</td>\n",
       "      <td>0.044706</td>\n",
       "      <td>0.010145</td>\n",
       "      <td>0.094825</td>\n",
       "      <td>0.066979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0.098545</td>\n",
       "      <td>0.037387</td>\n",
       "      <td>0.071422</td>\n",
       "      <td>0.006064</td>\n",
       "      <td>0.020433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>0.094387</td>\n",
       "      <td>0.069987</td>\n",
       "      <td>0.004967</td>\n",
       "      <td>0.011472</td>\n",
       "      <td>0.040818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>0.071711</td>\n",
       "      <td>0.040297</td>\n",
       "      <td>0.046027</td>\n",
       "      <td>0.060420</td>\n",
       "      <td>0.091366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>0.024034</td>\n",
       "      <td>0.043750</td>\n",
       "      <td>0.023908</td>\n",
       "      <td>0.033419</td>\n",
       "      <td>0.041185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>0.088742</td>\n",
       "      <td>0.049511</td>\n",
       "      <td>0.098225</td>\n",
       "      <td>0.025211</td>\n",
       "      <td>0.090284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>0.074492</td>\n",
       "      <td>0.025830</td>\n",
       "      <td>0.041407</td>\n",
       "      <td>0.041174</td>\n",
       "      <td>0.057165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>0.054515</td>\n",
       "      <td>0.028565</td>\n",
       "      <td>0.030539</td>\n",
       "      <td>0.076687</td>\n",
       "      <td>0.020773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>0.017331</td>\n",
       "      <td>0.092784</td>\n",
       "      <td>0.031541</td>\n",
       "      <td>0.066901</td>\n",
       "      <td>0.066410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>0.123290</td>\n",
       "      <td>0.118200</td>\n",
       "      <td>0.049868</td>\n",
       "      <td>0.116170</td>\n",
       "      <td>0.026676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>0.034934</td>\n",
       "      <td>0.063352</td>\n",
       "      <td>0.028195</td>\n",
       "      <td>0.029997</td>\n",
       "      <td>0.060968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>0.060034</td>\n",
       "      <td>0.056963</td>\n",
       "      <td>0.070582</td>\n",
       "      <td>0.052786</td>\n",
       "      <td>0.025229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>0.030980</td>\n",
       "      <td>0.034354</td>\n",
       "      <td>0.065246</td>\n",
       "      <td>0.045543</td>\n",
       "      <td>0.061387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>0.069161</td>\n",
       "      <td>0.004781</td>\n",
       "      <td>0.081710</td>\n",
       "      <td>0.046290</td>\n",
       "      <td>0.006849</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 56
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Transform data to drop these features"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "source": [
    "## Transform data from sfs\n",
    "X_new = sfs.transform(X)\n",
    "### Verify transformation\n",
    "print(X.shape[1] - len(dropped_features)) # num features that should be left\n",
    "print(X_new.shape[1])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "268\n",
      "268\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Train new model"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "source": [
    "clf = svm.SVC(C=1000, gamma='auto')\n",
    "loo = LeaveOneOut()\n",
    "results_cv = cross_validate(clf, X, y, cv=loo, return_train_score=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "source": [
    "print(np.mean(results_cv['train_score']))\n",
    "print(np.mean(results_cv['test_score']))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.9833333333333333\n",
      "0.5333333333333333\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Function for forward and backwards"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "def feature_selection(X, y, model, direction='forward',\n",
    "                     features_dropped = 10, cv_sfs=10, cv_train=10, notes=None):\n",
    "    print('####################')\n",
    "    print('Begin Feature Selection')\n",
    "    print('####################')\n",
    "\n",
    "    # Create a model for sfs and training\n",
    "    model_sfs = model\n",
    "    model_train = model\n",
    "\n",
    "    # Get length of data for final num features\n",
    "    num_features = X.shape[1] # get total number of features\n",
    "    final_features = num_features - features_dropped # final number of features in the model\n",
    "    print(f'final features: {final_features}')\n",
    "\n",
    "    # Call sequential features selector\n",
    "    sfs = SequentialFeatureSelector(model_sfs, n_features_to_select=final_features, cv=cv_sfs, direction=direction)\n",
    "    sfs.fit(X,y)\n",
    "    \n",
    "    # Get the dropped features\n",
    "    dropped_features = np.where(sfs.get_support() == False)[0]\n",
    "    print(f'Dropped Features: {dropped_features}')\n",
    "\n",
    "    # Transform data and train a model\n",
    "    X_new = sfs.transform(X)\n",
    "\n",
    "    # Train SVM model\n",
    "    print('-----------------')\n",
    "    print(f'{model_train} being used')\n",
    "    results = cross_validate(model_train, X_new, y, cv=cv_train, return_train_score=True)\n",
    "    train_score = results['train_score']\n",
    "    test_score = results['test_score']\n",
    "    test_min = min(test_score)\n",
    "    test_avg = np.mean(test_score)\n",
    "    test_max = max(test_score)\n",
    "    print(f'train scores: {train_score}')\n",
    "    print(f'test scores: {test_score}')\n",
    "    print('-----------------')\n",
    "\n",
    "    ## Create a dict to store results (makes dataframes easier)\n",
    "    results_dict = {\n",
    "                    'model': str(model),\n",
    "                    'direction': direction,\n",
    "                    'features_dropped': [dropped_features],\n",
    "                    'final_num_features': final_features,\n",
    "                    'train_scores': [train_score.round(3)],\n",
    "                    'test_scores': [test_score.round(3)],\n",
    "                    'min_test': test_min,\n",
    "                    'avg_test': test_avg,\n",
    "                    'max_test': test_max,\n",
    "                    'notes': notes,\n",
    "                    }\n",
    "                    \n",
    "    # results_df = pd.DataFrame(results_dict)\n",
    "\n",
    "    return(results_dict)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "one_run = feature_selection(X, y, model=svm.SVC(C=1000, gamma='auto'), features_dropped=90)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "####################\n",
      "Begin Feature Selection\n",
      "####################\n",
      "final features: 243\n",
      "Dropped Features: [ 15 104 113 149 150 152 154 159 168 178 185 188 194 200 202 203 208 211\n",
      " 213 215 221 234 236 237 240 249 258 262 263 270]\n",
      "-----------------\n",
      "SVC(C=1000, gamma='auto') being used\n",
      "train scores: [0.96296296 0.98148148 0.96296296 0.96296296 0.96296296 0.96296296\n",
      " 0.96296296 0.96296296 0.98148148 0.96296296]\n",
      "test scores: [0.66666667 0.5        0.83333333 0.33333333 0.83333333 0.66666667\n",
      " 0.5        0.5        0.66666667 0.66666667]\n",
      "-----------------\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "ValueError",
     "evalue": "All arrays must be of the same length",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/k4/lgyk0lns2bg5fy096kcxrvfc0000gn/T/ipykernel_7585/1973750255.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mone_run\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeature_selection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msvm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSVC\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mC\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgamma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'auto'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures_dropped\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/var/folders/k4/lgyk0lns2bg5fy096kcxrvfc0000gn/T/ipykernel_7585/3246677607.py\u001b[0m in \u001b[0;36mfeature_selection\u001b[0;34m(X, y, model, direction, features_dropped, cv_sfs, cv_train, notes)\u001b[0m\n\u001b[1;32m     52\u001b[0m                     }\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m     \u001b[0mresults_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[0;32mreturn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    612\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    613\u001b[0m             \u001b[0;31m# GH#38939 de facto copy defaults to False only in non-dict cases\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 614\u001b[0;31m             \u001b[0mmgr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict_to_mgr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtyp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmanager\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    615\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMaskedArray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    616\u001b[0m             \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmrecords\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mmrecords\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36mdict_to_mgr\u001b[0;34m(data, index, columns, dtype, typ, copy)\u001b[0m\n\u001b[1;32m    462\u001b[0m         \u001b[0;31m# TODO: can we get rid of the dt64tz special case above?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    463\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 464\u001b[0;31m     return arrays_to_mgr(\n\u001b[0m\u001b[1;32m    465\u001b[0m         \u001b[0marrays\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtyp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtyp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconsolidate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    466\u001b[0m     )\n",
      "\u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36marrays_to_mgr\u001b[0;34m(arrays, arr_names, index, columns, dtype, verify_integrity, typ, consolidate)\u001b[0m\n\u001b[1;32m    117\u001b[0m         \u001b[0;31m# figure out the index, if necessary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m             \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_extract_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mensure_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36m_extract_index\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m    633\u001b[0m             \u001b[0mlengths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_lengths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    634\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 635\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"All arrays must be of the same length\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    637\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhave_dicts\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: All arrays must be of the same length"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "all_results = []\n",
    "for x in [30,60,90]:\n",
    "    results = feature_selection(X, y, model=svm.SVC(C=1000, gamma='auto'), features_dropped=x)\n",
    "    print(results)\n",
    "    all_results.append(results)\n",
    "    "
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "####################\n",
      "Begin Feature Selection\n",
      "####################\n",
      "final features: 243\n",
      "Dropped Features: [ 15 104 113 149 150 152 154 159 168 178 185 188 194 200 202 203 208 211\n",
      " 213 215 221 234 236 237 240 249 258 262 263 270]\n",
      "-----------------\n",
      "SVC(C=1000, gamma='auto') being used\n",
      "train scores: [0.96296296 0.98148148 0.96296296 0.96296296 0.96296296 0.96296296\n",
      " 0.96296296 0.96296296 0.98148148 0.96296296]\n",
      "test scores: [0.66666667 0.5        0.83333333 0.33333333 0.83333333 0.66666667\n",
      " 0.5        0.5        0.66666667 0.66666667]\n",
      "-----------------\n",
      "{'model': \"SVC(C=1000, gamma='auto')\", 'direction': 'forward', 'features_dropped': [array([ 15, 104, 113, 149, 150, 152, 154, 159, 168, 178, 185, 188, 194,\n",
      "       200, 202, 203, 208, 211, 213, 215, 221, 234, 236, 237, 240, 249,\n",
      "       258, 262, 263, 270])], 'final_num_features': 243, 'train_scores': [array([0.963, 0.981, 0.963, 0.963, 0.963, 0.963, 0.963, 0.963, 0.981,\n",
      "       0.963])], 'test_scores': [array([0.667, 0.5  , 0.833, 0.333, 0.833, 0.667, 0.5  , 0.5  , 0.667,\n",
      "       0.667])], 'min_test': 0.3333333333333333, 'avg_test': 0.6166666666666667, 'max_test': 0.8333333333333334, 'notes': None}\n",
      "####################\n",
      "Begin Feature Selection\n",
      "####################\n",
      "final features: 213\n",
      "Dropped Features: [  2  15  30  43  77  82  84  86  90  95 102 104 109 113 115 142 143 149\n",
      " 150 152 154 155 159 168 172 178 185 188 192 193 194 196 200 201 202 203\n",
      " 205 208 211 212 213 215 219 221 222 224 228 234 236 237 240 249 256 258\n",
      " 262 263 264 268 270 271]\n",
      "-----------------\n",
      "SVC(C=1000, gamma='auto') being used\n",
      "train scores: [0.90740741 0.92592593 0.92592593 0.98148148 0.94444444 0.92592593\n",
      " 0.92592593 0.92592593 0.98148148 0.92592593]\n",
      "test scores: [0.66666667 0.33333333 0.83333333 0.33333333 0.83333333 0.66666667\n",
      " 0.5        0.66666667 0.66666667 0.5       ]\n",
      "-----------------\n",
      "{'model': \"SVC(C=1000, gamma='auto')\", 'direction': 'forward', 'features_dropped': [array([  2,  15,  30,  43,  77,  82,  84,  86,  90,  95, 102, 104, 109,\n",
      "       113, 115, 142, 143, 149, 150, 152, 154, 155, 159, 168, 172, 178,\n",
      "       185, 188, 192, 193, 194, 196, 200, 201, 202, 203, 205, 208, 211,\n",
      "       212, 213, 215, 219, 221, 222, 224, 228, 234, 236, 237, 240, 249,\n",
      "       256, 258, 262, 263, 264, 268, 270, 271])], 'final_num_features': 213, 'train_scores': [array([0.907, 0.926, 0.926, 0.981, 0.944, 0.926, 0.926, 0.926, 0.981,\n",
      "       0.926])], 'test_scores': [array([0.667, 0.333, 0.833, 0.333, 0.833, 0.667, 0.5  , 0.667, 0.667,\n",
      "       0.5  ])], 'min_test': 0.3333333333333333, 'avg_test': 0.6000000000000001, 'max_test': 0.8333333333333334, 'notes': None}\n",
      "####################\n",
      "Begin Feature Selection\n",
      "####################\n",
      "final features: 183\n",
      "Dropped Features: [  2   3  11  15  16  30  31  43  51  56  68  70  77  82  84  85  86  90\n",
      "  95  96 102 103 104 109 111 113 115 117 120 121 122 132 141 142 143 144\n",
      " 149 150 152 154 155 159 168 172 178 183 185 188 191 192 193 194 196 197\n",
      " 200 201 202 203 204 205 208 211 212 213 214 215 218 219 221 222 224 226\n",
      " 228 234 236 237 240 249 255 256 258 261 262 263 264 268 269 270 271 272]\n",
      "-----------------\n",
      "SVC(C=1000, gamma='auto') being used\n",
      "train scores: [0.90740741 0.90740741 0.87037037 0.94444444 0.85185185 0.83333333\n",
      " 0.85185185 0.90740741 0.87037037 0.87037037]\n",
      "test scores: [0.66666667 0.16666667 0.5        0.5        0.83333333 0.66666667\n",
      " 0.5        0.66666667 0.5        0.66666667]\n",
      "-----------------\n",
      "{'model': \"SVC(C=1000, gamma='auto')\", 'direction': 'forward', 'features_dropped': [array([  2,   3,  11,  15,  16,  30,  31,  43,  51,  56,  68,  70,  77,\n",
      "        82,  84,  85,  86,  90,  95,  96, 102, 103, 104, 109, 111, 113,\n",
      "       115, 117, 120, 121, 122, 132, 141, 142, 143, 144, 149, 150, 152,\n",
      "       154, 155, 159, 168, 172, 178, 183, 185, 188, 191, 192, 193, 194,\n",
      "       196, 197, 200, 201, 202, 203, 204, 205, 208, 211, 212, 213, 214,\n",
      "       215, 218, 219, 221, 222, 224, 226, 228, 234, 236, 237, 240, 249,\n",
      "       255, 256, 258, 261, 262, 263, 264, 268, 269, 270, 271, 272])], 'final_num_features': 183, 'train_scores': [array([0.907, 0.907, 0.87 , 0.944, 0.852, 0.833, 0.852, 0.907, 0.87 ,\n",
      "       0.87 ])], 'test_scores': [array([0.667, 0.167, 0.5  , 0.5  , 0.833, 0.667, 0.5  , 0.667, 0.5  ,\n",
      "       0.667])], 'min_test': 0.16666666666666666, 'avg_test': 0.5666666666666667, 'max_test': 0.8333333333333334, 'notes': None}\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Experiment with methods needed to do exhaustive training"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "# Iterrate over the data frame for many X and y\n",
    "num_features = data_df.shape[1] - 1 # get total number of features\n",
    "num_features_del = 5 # number of features to take off\n",
    "final_features = num_features - num_features_del # final number of features in the model\n",
    "print(final_features)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "289\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.9.6",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.6 64-bit ('base': conda)"
  },
  "interpreter": {
   "hash": "95ec9ec1504d83f612128e0fb229072f90bbb4cb09d9d5d93b5dd26e0ca2cfd1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}