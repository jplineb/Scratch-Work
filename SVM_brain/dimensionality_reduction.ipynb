{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Import data"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "source": [
    "brain_data = pd.read_csv('./data/eig_centrality.csv', header=None)\n",
    "brain_data.head()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   0         1         2    3    4    5         6         7    8    9    ...  \\\n",
       "0    1 -0.067894 -0.062832    0    0    0 -0.031240 -0.071004    0    0  ...   \n",
       "1    1  0.031793  0.025996    0    0    0  0.122030  0.109220    0    0  ...   \n",
       "2    1 -0.005251 -0.015806    0    0    0 -0.124040 -0.117020    0    0  ...   \n",
       "3    1  0.123150  0.096576    0    0    0 -0.045236 -0.005143    0    0  ...   \n",
       "4    1 -0.059846 -0.024500    0    0    0 -0.022105  0.022153    0    0  ...   \n",
       "\n",
       "        285       286           287           288       289       290  \\\n",
       "0 -0.112760 -0.106070  0.000000e+00  0.000000e+00 -0.028195 -0.024616   \n",
       "1  0.078364  0.049836  0.000000e+00  6.938900e-18 -0.076947 -0.078418   \n",
       "2  0.021125  0.014470  0.000000e+00 -1.734700e-18  0.068705  0.084321   \n",
       "3 -0.043127 -0.024063  5.551100e-17 -1.110200e-16 -0.064510 -0.100380   \n",
       "4 -0.026404 -0.004397 -4.336800e-19  0.000000e+00 -0.068379  0.006091   \n",
       "\n",
       "        291       292       293       294  \n",
       "0 -0.042535 -0.087451  0.003145 -0.047196  \n",
       "1 -0.064815  0.095082  0.054585  0.076347  \n",
       "2  0.047107  0.004649 -0.142760 -0.129450  \n",
       "3 -0.112950 -0.099919 -0.006036 -0.004228  \n",
       "4 -0.050172  0.056009  0.077894  0.016500  \n",
       "\n",
       "[5 rows x 295 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>285</th>\n",
       "      <th>286</th>\n",
       "      <th>287</th>\n",
       "      <th>288</th>\n",
       "      <th>289</th>\n",
       "      <th>290</th>\n",
       "      <th>291</th>\n",
       "      <th>292</th>\n",
       "      <th>293</th>\n",
       "      <th>294</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.067894</td>\n",
       "      <td>-0.062832</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.031240</td>\n",
       "      <td>-0.071004</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.112760</td>\n",
       "      <td>-0.106070</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-0.028195</td>\n",
       "      <td>-0.024616</td>\n",
       "      <td>-0.042535</td>\n",
       "      <td>-0.087451</td>\n",
       "      <td>0.003145</td>\n",
       "      <td>-0.047196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.031793</td>\n",
       "      <td>0.025996</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.122030</td>\n",
       "      <td>0.109220</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.078364</td>\n",
       "      <td>0.049836</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>6.938900e-18</td>\n",
       "      <td>-0.076947</td>\n",
       "      <td>-0.078418</td>\n",
       "      <td>-0.064815</td>\n",
       "      <td>0.095082</td>\n",
       "      <td>0.054585</td>\n",
       "      <td>0.076347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.005251</td>\n",
       "      <td>-0.015806</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.124040</td>\n",
       "      <td>-0.117020</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.021125</td>\n",
       "      <td>0.014470</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-1.734700e-18</td>\n",
       "      <td>0.068705</td>\n",
       "      <td>0.084321</td>\n",
       "      <td>0.047107</td>\n",
       "      <td>0.004649</td>\n",
       "      <td>-0.142760</td>\n",
       "      <td>-0.129450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0.123150</td>\n",
       "      <td>0.096576</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.045236</td>\n",
       "      <td>-0.005143</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.043127</td>\n",
       "      <td>-0.024063</td>\n",
       "      <td>5.551100e-17</td>\n",
       "      <td>-1.110200e-16</td>\n",
       "      <td>-0.064510</td>\n",
       "      <td>-0.100380</td>\n",
       "      <td>-0.112950</td>\n",
       "      <td>-0.099919</td>\n",
       "      <td>-0.006036</td>\n",
       "      <td>-0.004228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.059846</td>\n",
       "      <td>-0.024500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.022105</td>\n",
       "      <td>0.022153</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.026404</td>\n",
       "      <td>-0.004397</td>\n",
       "      <td>-4.336800e-19</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-0.068379</td>\n",
       "      <td>0.006091</td>\n",
       "      <td>-0.050172</td>\n",
       "      <td>0.056009</td>\n",
       "      <td>0.077894</td>\n",
       "      <td>0.016500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 295 columns</p>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 26
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Data preprocessing"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "source": [
    "# Optional: drop zero columns\n",
    "brain_data = brain_data.loc[:, (brain_data != 0).any(axis=0)]\n",
    "brain_data.head()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   0         1         2         6         7         10        12        13   \\\n",
       "0    1 -0.067894 -0.062832 -0.031240 -0.071004 -0.030888  0.009534  0.044660   \n",
       "1    1  0.031793  0.025996  0.122030  0.109220 -0.005733  0.017223 -0.072822   \n",
       "2    1 -0.005251 -0.015806 -0.124040 -0.117020 -0.017355 -0.035984  0.106950   \n",
       "3    1  0.123150  0.096576 -0.045236 -0.005143 -0.017959 -0.060064  0.008232   \n",
       "4    1 -0.059846 -0.024500 -0.022105  0.022153  0.079495 -0.013115  0.019867   \n",
       "\n",
       "        14        15   ...       285       286           287           288  \\\n",
       "0  0.043163  0.025440  ... -0.112760 -0.106070  0.000000e+00  0.000000e+00   \n",
       "1 -0.077072 -0.126650  ...  0.078364  0.049836  0.000000e+00  6.938900e-18   \n",
       "2  0.011851  0.077032  ...  0.021125  0.014470  0.000000e+00 -1.734700e-18   \n",
       "3 -0.076910 -0.042061  ... -0.043127 -0.024063  5.551100e-17 -1.110200e-16   \n",
       "4  0.032033  0.012232  ... -0.026404 -0.004397 -4.336800e-19  0.000000e+00   \n",
       "\n",
       "        289       290       291       292       293       294  \n",
       "0 -0.028195 -0.024616 -0.042535 -0.087451  0.003145 -0.047196  \n",
       "1 -0.076947 -0.078418 -0.064815  0.095082  0.054585  0.076347  \n",
       "2  0.068705  0.084321  0.047107  0.004649 -0.142760 -0.129450  \n",
       "3 -0.064510 -0.100380 -0.112950 -0.099919 -0.006036 -0.004228  \n",
       "4 -0.068379  0.006091 -0.050172  0.056009  0.077894  0.016500  \n",
       "\n",
       "[5 rows x 274 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>10</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>...</th>\n",
       "      <th>285</th>\n",
       "      <th>286</th>\n",
       "      <th>287</th>\n",
       "      <th>288</th>\n",
       "      <th>289</th>\n",
       "      <th>290</th>\n",
       "      <th>291</th>\n",
       "      <th>292</th>\n",
       "      <th>293</th>\n",
       "      <th>294</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.067894</td>\n",
       "      <td>-0.062832</td>\n",
       "      <td>-0.031240</td>\n",
       "      <td>-0.071004</td>\n",
       "      <td>-0.030888</td>\n",
       "      <td>0.009534</td>\n",
       "      <td>0.044660</td>\n",
       "      <td>0.043163</td>\n",
       "      <td>0.025440</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.112760</td>\n",
       "      <td>-0.106070</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-0.028195</td>\n",
       "      <td>-0.024616</td>\n",
       "      <td>-0.042535</td>\n",
       "      <td>-0.087451</td>\n",
       "      <td>0.003145</td>\n",
       "      <td>-0.047196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.031793</td>\n",
       "      <td>0.025996</td>\n",
       "      <td>0.122030</td>\n",
       "      <td>0.109220</td>\n",
       "      <td>-0.005733</td>\n",
       "      <td>0.017223</td>\n",
       "      <td>-0.072822</td>\n",
       "      <td>-0.077072</td>\n",
       "      <td>-0.126650</td>\n",
       "      <td>...</td>\n",
       "      <td>0.078364</td>\n",
       "      <td>0.049836</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>6.938900e-18</td>\n",
       "      <td>-0.076947</td>\n",
       "      <td>-0.078418</td>\n",
       "      <td>-0.064815</td>\n",
       "      <td>0.095082</td>\n",
       "      <td>0.054585</td>\n",
       "      <td>0.076347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.005251</td>\n",
       "      <td>-0.015806</td>\n",
       "      <td>-0.124040</td>\n",
       "      <td>-0.117020</td>\n",
       "      <td>-0.017355</td>\n",
       "      <td>-0.035984</td>\n",
       "      <td>0.106950</td>\n",
       "      <td>0.011851</td>\n",
       "      <td>0.077032</td>\n",
       "      <td>...</td>\n",
       "      <td>0.021125</td>\n",
       "      <td>0.014470</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-1.734700e-18</td>\n",
       "      <td>0.068705</td>\n",
       "      <td>0.084321</td>\n",
       "      <td>0.047107</td>\n",
       "      <td>0.004649</td>\n",
       "      <td>-0.142760</td>\n",
       "      <td>-0.129450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0.123150</td>\n",
       "      <td>0.096576</td>\n",
       "      <td>-0.045236</td>\n",
       "      <td>-0.005143</td>\n",
       "      <td>-0.017959</td>\n",
       "      <td>-0.060064</td>\n",
       "      <td>0.008232</td>\n",
       "      <td>-0.076910</td>\n",
       "      <td>-0.042061</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.043127</td>\n",
       "      <td>-0.024063</td>\n",
       "      <td>5.551100e-17</td>\n",
       "      <td>-1.110200e-16</td>\n",
       "      <td>-0.064510</td>\n",
       "      <td>-0.100380</td>\n",
       "      <td>-0.112950</td>\n",
       "      <td>-0.099919</td>\n",
       "      <td>-0.006036</td>\n",
       "      <td>-0.004228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.059846</td>\n",
       "      <td>-0.024500</td>\n",
       "      <td>-0.022105</td>\n",
       "      <td>0.022153</td>\n",
       "      <td>0.079495</td>\n",
       "      <td>-0.013115</td>\n",
       "      <td>0.019867</td>\n",
       "      <td>0.032033</td>\n",
       "      <td>0.012232</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.026404</td>\n",
       "      <td>-0.004397</td>\n",
       "      <td>-4.336800e-19</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-0.068379</td>\n",
       "      <td>0.006091</td>\n",
       "      <td>-0.050172</td>\n",
       "      <td>0.056009</td>\n",
       "      <td>0.077894</td>\n",
       "      <td>0.016500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 274 columns</p>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 27
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# PCA\n",
    "\n",
    "This might not be the best approach because we have the one hot encoded categorical variable (binary classification)\n",
    "\n",
    "By applying PCA, we lose some of the variance (i.e., information). By reducing the dimensionality of the data, PCA will reduce the size of the data.\n",
    " - This will improve the performance of machine learning algorithms.\n",
    " - This will reduce hardware requirements and speed up the training process.\n",
    " - This will allow us to easily understand the underlying structure of the data.\n",
    " - This will allow us to visualize the data on a 2d or 3d plot (if we choose the number of principal components as 2 or 3)."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Exploratory work"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "source": [
    "# Get feature matrix\n",
    "X = abs(brain_data.iloc[:,1:].values)\n",
    "y = brain_data.iloc[:,0].values\n",
    "print(X)\n",
    "print(y)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[6.7894e-02 6.2832e-02 3.1240e-02 ... 8.7451e-02 3.1445e-03 4.7196e-02]\n",
      " [3.1793e-02 2.5996e-02 1.2203e-01 ... 9.5082e-02 5.4585e-02 7.6347e-02]\n",
      " [5.2506e-03 1.5806e-02 1.2404e-01 ... 4.6495e-03 1.4276e-01 1.2945e-01]\n",
      " ...\n",
      " [2.6920e-03 1.4674e-02 1.0568e-01 ... 3.7322e-02 8.6381e-02 9.1878e-02]\n",
      " [6.3993e-02 2.5404e-02 4.5130e-02 ... 6.4920e-05 5.0832e-03 1.0966e-02]\n",
      " [2.8025e-03 6.5748e-02 1.1062e-01 ... 1.5098e-02 1.2126e-01 8.5409e-02]]\n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "source": [
    "# Optional: Standardize the features\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "## Create object\n",
    "scaler = StandardScaler()\n",
    "## Calculate mean and std\n",
    "scaler.fit(X)\n",
    "## Transform the values\n",
    "X_scaled = scaler.transform(X)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "source": [
    "X_scaled"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[ 0.33139785,  0.39702335, -0.77357546, ...,  1.63585243,\n",
       "        -1.3571693 , -0.08090501],\n",
       "       [-0.62764009, -0.66035769,  1.67550156, ...,  1.90141282,\n",
       "         0.07082187,  0.82105796],\n",
       "       [-1.33274987, -0.95286265,  1.72972168, ..., -1.24565698,\n",
       "         2.51856483,  2.46412129],\n",
       "       ...,\n",
       "       [-1.40072014, -0.98535682,  1.23445729, ..., -0.10864719,\n",
       "         0.95348062,  1.30160362],\n",
       "       [ 0.22776617, -0.67735111, -0.39889015, ..., -1.40520132,\n",
       "        -1.30335088, -1.20189977],\n",
       "       [-1.39778466,  0.48072742,  1.3677147 , ..., -0.88204701,\n",
       "         1.92172362,  1.10144588]])"
      ]
     },
     "metadata": {},
     "execution_count": 30
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "source": [
    "# apply PCA to all dimensions\n",
    "from sklearn.decomposition import PCA\n",
    "pca_60 = PCA(n_components=60, random_state=42)\n",
    "pca_60.fit(X_scaled)\n",
    "X_pca_60 = pca_60.transform(X_scaled)\n",
    "print('Variance explained by all 60 principal components = ', sum(pca_60.explained_variance_ratio_ * 100))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Variance explained by all 60 principal components =  99.99999999999999\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "source": [
    "# The explained_variance_ratio_ attribute of the PCA() class returns\n",
    "# a one-dimensional numpy array which contains the values of the\n",
    "# percentage of variance explained by each of the selected components.\n",
    "pca_60.explained_variance_ratio_ * 100"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([1.05273612e+01, 6.82178775e+00, 5.07210298e+00, 4.52359118e+00,\n",
       "       3.88560783e+00, 3.62770949e+00, 3.36403746e+00, 3.17513446e+00,\n",
       "       2.83080865e+00, 2.67879778e+00, 2.58212715e+00, 2.40692874e+00,\n",
       "       2.25233411e+00, 2.16281659e+00, 2.10075008e+00, 1.98366113e+00,\n",
       "       1.86508047e+00, 1.77206366e+00, 1.73615729e+00, 1.72134258e+00,\n",
       "       1.58304185e+00, 1.53373883e+00, 1.45787391e+00, 1.43967924e+00,\n",
       "       1.38120272e+00, 1.29201104e+00, 1.26163802e+00, 1.19411516e+00,\n",
       "       1.18666371e+00, 1.15415312e+00, 1.10960569e+00, 1.03863321e+00,\n",
       "       1.01646877e+00, 9.59399824e-01, 9.41347050e-01, 8.95542428e-01,\n",
       "       8.82312171e-01, 8.76373491e-01, 8.10738715e-01, 7.84090470e-01,\n",
       "       7.54449714e-01, 7.31236357e-01, 7.06771597e-01, 6.97113597e-01,\n",
       "       6.43095440e-01, 6.16745639e-01, 6.09493359e-01, 5.75715872e-01,\n",
       "       5.54686052e-01, 5.29092474e-01, 5.17675155e-01, 4.77558713e-01,\n",
       "       4.48582802e-01, 4.35654414e-01, 4.03732853e-01, 3.95316402e-01,\n",
       "       3.66051486e-01, 3.43499070e-01, 3.04698969e-01, 2.07615593e-30])"
      ]
     },
     "metadata": {},
     "execution_count": 32
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "source": [
    "# or look at the cumulutive sum as we add more componenets\n",
    "np.cumsum(pca_60.explained_variance_ratio_ * 100)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([ 10.52736124,  17.34914899,  22.42125197,  26.94484315,\n",
       "        30.83045098,  34.45816048,  37.82219794,  40.9973324 ,\n",
       "        43.82814105,  46.50693883,  49.08906598,  51.49599471,\n",
       "        53.74832882,  55.91114541,  58.01189549,  59.99555662,\n",
       "        61.86063709,  63.63270074,  65.36885803,  67.09020062,\n",
       "        68.67324247,  70.20698129,  71.66485521,  73.10453445,\n",
       "        74.48573717,  75.77774821,  77.03938623,  78.23350139,\n",
       "        79.4201651 ,  80.57431822,  81.68392391,  82.72255712,\n",
       "        83.73902589,  84.69842571,  85.63977276,  86.53531519,\n",
       "        87.41762736,  88.29400085,  89.10473957,  89.88883004,\n",
       "        90.64327975,  91.37451611,  92.0812877 ,  92.7784013 ,\n",
       "        93.42149674,  94.03824238,  94.64773574,  95.22345161,\n",
       "        95.77813766,  96.30723014,  96.82490529,  97.302464  ,\n",
       "        97.75104681,  98.18670122,  98.59043407,  98.98575047,\n",
       "        99.35180196,  99.69530103, 100.        , 100.        ])"
      ]
     },
     "metadata": {},
     "execution_count": 33
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "source": [
    "'''\n",
    "It's incorrect to use PCA on the Y variable\n",
    "'''\n",
    "# # Leave X and Y in and don't standardize\n",
    "# X = brain_data.values\n",
    "# print(X.shape)\n",
    "\n",
    "# # apply PCA to all dimensions\n",
    "# pca_60 = PCA(n_components=60, random_state=42)\n",
    "# pca_60.fit(X)\n",
    "# X_pca_60 = pca_60.transform(X)\n",
    "# print('Variance explained by all 60 principal components = ', sum(pca_60.explained_variance_ratio_ * 100))\n",
    "# print(pca_60.explained_variance_ratio_ * 100)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "\"\\nIt's incorrect to use PCA on the Y variable\\n\""
      ]
     },
     "metadata": {},
     "execution_count": 34
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "source": [
    "'''\n",
    "Already Done above\n",
    "'''\n",
    "# # What if we just use the X and leave out the categorical variable?\n",
    "# X = brain_data.iloc[:,1:].values\n",
    "# print(X.shape)\n",
    "# ## Create object\n",
    "# scaler = StandardScaler()\n",
    "# ## Calculate mean and std\n",
    "# scaler.fit(X)\n",
    "# ## Transform the values\n",
    "# X_scaled = scaler.transform(X)\n",
    "\n",
    "# # apply PCA to all dimensions\n",
    "# pca_60_justx = PCA(n_components=60, random_state=42)\n",
    "# pca_60_justx.fit(X_scaled)\n",
    "# X_pca_60 = pca_60_justx.transform(X_scaled)\n",
    "# print('Variance explained by all 60 principal components = ', sum(pca_60_justx.explained_variance_ratio_ * 100))\n",
    "# print(pca_60_justx.explained_variance_ratio_ * 100)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'\\nAlready Done above\\n'"
      ]
     },
     "metadata": {},
     "execution_count": 35
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "source": [
    "# What if we just use the X and not scale \n",
    "X = abs(brain_data.iloc[:,1:].values)\n",
    "print(X.shape)\n",
    "# apply PCA to all dimensions\n",
    "pca_60_justx = PCA(n_components=50, random_state=42)\n",
    "pca_60_justx.fit(X)\n",
    "X_pca_60 = pca_60_justx.transform(X)\n",
    "print('Variance explained by all 60 principal components = ', sum(pca_60_justx.explained_variance_ratio_ * 100))\n",
    "print(pca_60_justx.explained_variance_ratio_ * 100)\n",
    "np.cumsum(pca_60_justx.explained_variance_ratio_ * 100)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(60, 273)\n",
      "Variance explained by all 60 principal components =  99.99999999999994\n",
      "[1.19932837e+01 7.42575957e+00 5.14398802e+00 4.57616288e+00\n",
      " 4.07669235e+00 3.59211023e+00 3.24636824e+00 3.11879270e+00\n",
      " 2.74535022e+00 2.65737339e+00 2.45131018e+00 2.34809712e+00\n",
      " 2.26468060e+00 2.14191706e+00 1.97991024e+00 1.88331988e+00\n",
      " 1.81183305e+00 1.73152014e+00 1.66450988e+00 1.60891658e+00\n",
      " 1.50266484e+00 1.44966240e+00 1.41063921e+00 1.34654720e+00\n",
      " 1.33171741e+00 1.28357341e+00 1.21084324e+00 1.15833305e+00\n",
      " 1.13852216e+00 1.10394652e+00 1.05137440e+00 1.03046040e+00\n",
      " 9.68541924e-01 9.24278696e-01 8.87430837e-01 8.56010069e-01\n",
      " 8.35625765e-01 7.92437143e-01 7.88341566e-01 7.50723013e-01\n",
      " 7.35114007e-01 7.03718215e-01 6.99749304e-01 6.53905725e-01\n",
      " 6.17250147e-01 5.95718779e-01 5.75110473e-01 5.46992786e-01\n",
      " 5.21646073e-01 5.12679757e-01 5.07301551e-01 4.58095062e-01\n",
      " 4.34218851e-01 4.24794155e-01 3.94058935e-01 3.83234834e-01\n",
      " 3.44433886e-01 3.27413476e-01 2.80994727e-01 3.41676289e-30]\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([ 11.99328367,  19.41904323,  24.56303125,  29.13919413,\n",
       "        33.21588648,  36.80799671,  40.05436495,  43.17315765,\n",
       "        45.91850787,  48.57588127,  51.02719145,  53.37528857,\n",
       "        55.63996917,  57.78188623,  59.76179647,  61.64511635,\n",
       "        63.4569494 ,  65.18846953,  66.85297942,  68.461896  ,\n",
       "        69.96456084,  71.41422324,  72.82486245,  74.17140966,\n",
       "        75.50312707,  76.78670048,  77.99754372,  79.15587676,\n",
       "        80.29439892,  81.39834545,  82.44971985,  83.48018025,\n",
       "        84.44872217,  85.37300087,  86.2604317 ,  87.11644177,\n",
       "        87.95206754,  88.74450468,  89.53284625,  90.28356926,\n",
       "        91.01868327,  91.72240148,  92.42215079,  93.07605651,\n",
       "        93.69330666,  94.28902544,  94.86413591,  95.41112869,\n",
       "        95.93277477,  96.44545452,  96.95275608,  97.41085114,\n",
       "        97.84506999,  98.26986414,  98.66392308,  99.04715791,\n",
       "        99.3915918 ,  99.71900527, 100.        , 100.        ])"
      ]
     },
     "metadata": {},
     "execution_count": 42
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Reducing the number of features meaningfully"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "source": [
    "# Get X values\n",
    "X = abs(brain_data.iloc[:,1:].values)\n",
    "\n",
    "pca_95per = PCA(n_components=0.95, random_state=42)\n",
    "pca_95per.fit(X)\n",
    "X_pca_95per = pca_95per.transform(X)\n",
    "print('Number of principal Componenets', len(pca_95per.explained_variance_ratio_))\n",
    "print(pca_95per.explained_variance_ratio_ * 100)\n",
    "np.cumsum(pca_95per.explained_variance_ratio_ * 100)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Number of principal Componenets 48\n",
      "[11.99328367  7.42575957  5.14398802  4.57616288  4.07669235  3.59211023\n",
      "  3.24636824  3.1187927   2.74535022  2.65737339  2.45131018  2.34809712\n",
      "  2.2646806   2.14191706  1.97991024  1.88331988  1.81183305  1.73152014\n",
      "  1.66450988  1.60891658  1.50266484  1.4496624   1.41063921  1.3465472\n",
      "  1.33171741  1.28357341  1.21084324  1.15833305  1.13852216  1.10394652\n",
      "  1.0513744   1.0304604   0.96854192  0.9242787   0.88743084  0.85601007\n",
      "  0.83562577  0.79243714  0.78834157  0.75072301  0.73511401  0.70371822\n",
      "  0.6997493   0.65390572  0.61725015  0.59571878  0.57511047  0.54699279]\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([11.99328367, 19.41904323, 24.56303125, 29.13919413, 33.21588648,\n",
       "       36.80799671, 40.05436495, 43.17315765, 45.91850787, 48.57588127,\n",
       "       51.02719145, 53.37528857, 55.63996917, 57.78188623, 59.76179647,\n",
       "       61.64511635, 63.4569494 , 65.18846953, 66.85297942, 68.461896  ,\n",
       "       69.96456084, 71.41422324, 72.82486245, 74.17140966, 75.50312707,\n",
       "       76.78670048, 77.99754372, 79.15587676, 80.29439892, 81.39834545,\n",
       "       82.44971985, 83.48018025, 84.44872217, 85.37300087, 86.2604317 ,\n",
       "       87.11644177, 87.95206754, 88.74450468, 89.53284625, 90.28356926,\n",
       "       91.01868327, 91.72240148, 92.42215079, 93.07605651, 93.69330666,\n",
       "       94.28902544, 94.86413591, 95.41112869])"
      ]
     },
     "metadata": {},
     "execution_count": 37
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## For Fun: Logistic Regression and SVM\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import svm\n",
    "\n",
    "# Get X and y values\n",
    "X = abs(brain_data.iloc[:,1:].values)\n",
    "y = brain_data.iloc[:,0].values\n",
    "print(X.shape)\n",
    "print(y.shape)\n",
    "\n",
    "# Create train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "## Verify\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "\n",
    "# Initialize pca, logistic regression model, and SVM\n",
    "pca = PCA(n_components=0.99, random_state=42)\n",
    "lr = LogisticRegression(multi_class='auto', solver='liblinear')\n",
    "clf = svm.SVC(kernel='rbf')\n",
    "\n",
    "# Fit and transform data\n",
    "X_train_pca = pca.fit_transform(X_train)\n",
    "X_test_pca = pca.transform(X_test)\n",
    "lr.fit(X_train_pca, y_train)\n",
    "clf.fit(X_train_pca, y_train)\n",
    "\n",
    "# Get Results\n",
    "print('-------------')\n",
    "print('Logistic Regression')\n",
    "train_score = lr.score(X_train_pca, y_train)\n",
    "print(f'Train Accuracy: {train_score}')\n",
    "test_score = lr.score(X_test_pca, y_test)\n",
    "print(f'Test Accuracy: {test_score}')\n",
    "print('-------------')\n",
    "print('SVM')\n",
    "train_score = clf.score(X_train_pca, y_train)\n",
    "print(f'Train Accuracy: {train_score}')\n",
    "test_score = clf.score(X_test_pca, y_test)\n",
    "print(f'Test Accuracy: {test_score}')\n",
    "print('--------------')\n",
    "\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(60, 273)\n",
      "(60,)\n",
      "(48, 273)\n",
      "(48,)\n",
      "-------------\n",
      "Logistic Regression\n",
      "Train Accuracy: 0.6458333333333334\n",
      "Test Accuracy: 0.3333333333333333\n",
      "-------------\n",
      "SVM\n",
      "Train Accuracy: 1.0\n",
      "Test Accuracy: 0.5\n",
      "--------------\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Model Testing"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier, GradientBoostingClassifier, RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import svm\n",
    "import time\n",
    "\n",
    "# Get X and y values\n",
    "X = abs(brain_data.iloc[:,1:].values)\n",
    "y = brain_data.iloc[:,0].values\n",
    "print(X.shape)\n",
    "print(y.shape)\n",
    "\n",
    "# Create train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=2021)\n",
    "## Verify\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "\n",
    "# Initialize pca, logistic regression model, and SVM\n",
    "pca = PCA(n_components=0.95, random_state=42)\n",
    "models = [AdaBoostClassifier(),\n",
    "         GradientBoostingClassifier(),\n",
    "         RandomForestClassifier(), \n",
    "         DecisionTreeClassifier(),\n",
    "         svm.SVC(kernel='rbf')]\n",
    "\n",
    "# Fit and transform data\n",
    "X_train_pca = pca.fit_transform(X_train)\n",
    "X_test_pca = pca.transform(X_test)\n",
    "\n",
    "print('#### PCA Performance ####')\n",
    "for model in models:\n",
    "    print('-----------------')\n",
    "    print(f'{model} being used')\n",
    "    model.fit(X_train_pca, y_train)\n",
    "    train_score = model.score(X_train_pca, y_train)\n",
    "    print(f'Train Accuracy: {train_score}')\n",
    "    test_score = model.score(X_test_pca, y_test)\n",
    "    print(f'Test Accuracy: {test_score}')\n",
    "    time.sleep(3)\n",
    "\n",
    "print('#### Full data Performance ####')\n",
    "for model in models:\n",
    "    print('-----------------')\n",
    "    print(f'{model} being used')\n",
    "    model.fit(X_train, y_train)\n",
    "    train_score = model.score(X_train, y_train)\n",
    "    print(f'Train Accuracy: {train_score}')\n",
    "    test_score = model.score(X_test, y_test)\n",
    "    print(f'Test Accuracy: {test_score}')\n",
    "    time.sleep(3)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(60, 273)\n",
      "(60,)\n",
      "(54, 273)\n",
      "(54,)\n",
      "#### PCA Performance ####\n",
      "-----------------\n",
      "AdaBoostClassifier() being used\n",
      "Train Accuracy: 1.0\n",
      "Test Accuracy: 0.5\n",
      "-----------------\n",
      "GradientBoostingClassifier() being used\n",
      "Train Accuracy: 1.0\n",
      "Test Accuracy: 0.3333333333333333\n",
      "-----------------\n",
      "RandomForestClassifier() being used\n",
      "Train Accuracy: 1.0\n",
      "Test Accuracy: 0.3333333333333333\n",
      "-----------------\n",
      "DecisionTreeClassifier() being used\n",
      "Train Accuracy: 1.0\n",
      "Test Accuracy: 0.3333333333333333\n",
      "-----------------\n",
      "SVC() being used\n",
      "Train Accuracy: 1.0\n",
      "Test Accuracy: 0.5\n",
      "#### Full data Performance ####\n",
      "-----------------\n",
      "AdaBoostClassifier() being used\n",
      "Train Accuracy: 1.0\n",
      "Test Accuracy: 0.3333333333333333\n",
      "-----------------\n",
      "GradientBoostingClassifier() being used\n",
      "Train Accuracy: 1.0\n",
      "Test Accuracy: 0.3333333333333333\n",
      "-----------------\n",
      "RandomForestClassifier() being used\n",
      "Train Accuracy: 1.0\n",
      "Test Accuracy: 0.5\n",
      "-----------------\n",
      "DecisionTreeClassifier() being used\n",
      "Train Accuracy: 1.0\n",
      "Test Accuracy: 0.3333333333333333\n",
      "-----------------\n",
      "SVC() being used\n",
      "Train Accuracy: 1.0\n",
      "Test Accuracy: 0.3333333333333333\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Cross validation"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier, GradientBoostingClassifier, RandomForestClassifier, ExtraTreesClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.model_selection import KFold, cross_validate\n",
    "import time\n",
    "\n",
    "# Get X and y values\n",
    "X = abs(brain_data.iloc[:,1:].values)\n",
    "y = brain_data.iloc[:,0].values\n",
    "print(X.shape)\n",
    "print(y.shape)\n",
    "\n",
    "# Initialize pca, logistic regression model, and SVM\n",
    "pca = PCA(n_components=0.95, random_state=42)\n",
    "models = [AdaBoostClassifier(),\n",
    "         GradientBoostingClassifier(),\n",
    "         RandomForestClassifier(), \n",
    "         DecisionTreeClassifier(),\n",
    "         ExtraTreesClassifier(),\n",
    "         svm.SVC(kernel='rbf'),\n",
    "         SGDClassifier()\n",
    "         ]\n",
    "\n",
    "# Fit and transform data\n",
    "X_pca = pca.fit_transform(X)\n",
    "\n",
    "# Initialize Folds\n",
    "k_fold = KFold( n_splits=10,\n",
    "                shuffle=True,\n",
    "                random_state= 2021)\n",
    "\n",
    "print('#### PCA Performance ####')\n",
    "for model in models:\n",
    "    print('-----------------')\n",
    "    print(f'{model} being used')\n",
    "    results = cross_validate(model, X_pca, y, cv=k_fold, return_train_score=True)\n",
    "    train_score = results['train_score']\n",
    "    test_score = results['test_score']\n",
    "    print(f'train scores: {train_score}')\n",
    "    print(f'test scores: {test_score}')\n",
    "    del results\n",
    "    del model\n",
    "    time.sleep(2)\n",
    "print('---------------------------------')\n",
    "print('#### Full data Performance ####')\n",
    "for model in models:\n",
    "    print('-----------------')\n",
    "    print(f'{model} being used')\n",
    "    results = cross_validate(model, X, y, cv=k_fold, return_train_score=True)\n",
    "    train_score = results['train_score']\n",
    "    test_score = results['test_score']\n",
    "    print(f'train scores: {train_score}')\n",
    "    print(f'test scores: {test_score}')\n",
    "    del results\n",
    "    del model\n",
    "    time.sleep(2)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(60, 273)\n",
      "(60,)\n",
      "#### PCA Performance ####\n",
      "-----------------\n",
      "AdaBoostClassifier() being used\n",
      "train scores: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "test scores: [0.5        0.         0.5        0.5        0.83333333 0.66666667\n",
      " 0.66666667 0.33333333 0.66666667 0.66666667]\n",
      "-----------------\n",
      "GradientBoostingClassifier() being used\n",
      "train scores: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "test scores: [0.5        0.5        0.66666667 0.33333333 0.66666667 0.5\n",
      " 0.33333333 0.5        0.83333333 0.83333333]\n",
      "-----------------\n",
      "RandomForestClassifier() being used\n",
      "train scores: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "test scores: [1.         0.33333333 0.16666667 0.33333333 0.5        0.5\n",
      " 1.         0.5        0.66666667 0.33333333]\n",
      "-----------------\n",
      "DecisionTreeClassifier() being used\n",
      "train scores: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "test scores: [0.5        0.33333333 0.66666667 0.5        0.66666667 0.5\n",
      " 0.5        0.5        0.5        0.83333333]\n",
      "-----------------\n",
      "ExtraTreesClassifier() being used\n",
      "train scores: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "test scores: [0.66666667 0.33333333 0.66666667 0.5        0.83333333 0.5\n",
      " 0.66666667 0.66666667 0.83333333 0.66666667]\n",
      "-----------------\n",
      "SVC() being used\n",
      "train scores: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "test scores: [0.33333333 0.33333333 0.5        0.5        0.83333333 0.16666667\n",
      " 0.33333333 0.16666667 0.66666667 0.66666667]\n",
      "-----------------\n",
      "SGDClassifier() being used\n",
      "train scores: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "test scores: [0.33333333 0.33333333 0.5        0.83333333 0.66666667 0.5\n",
      " 0.5        0.33333333 0.83333333 0.66666667]\n",
      "---------------------------------\n",
      "#### Full data Performance ####\n",
      "-----------------\n",
      "AdaBoostClassifier() being used\n",
      "train scores: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "test scores: [0.33333333 0.5        0.5        0.33333333 0.33333333 0.33333333\n",
      " 0.33333333 0.5        0.5        0.5       ]\n",
      "-----------------\n",
      "GradientBoostingClassifier() being used\n",
      "train scores: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "test scores: [0.33333333 0.83333333 0.66666667 0.33333333 0.5        0.5\n",
      " 0.66666667 0.5        0.5        0.33333333]\n",
      "-----------------\n",
      "RandomForestClassifier() being used\n",
      "train scores: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "test scores: [0.33333333 0.33333333 0.33333333 0.66666667 0.83333333 0.33333333\n",
      " 0.33333333 0.16666667 0.83333333 0.66666667]\n",
      "-----------------\n",
      "DecisionTreeClassifier() being used\n",
      "train scores: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "test scores: [0.5        0.5        0.16666667 0.33333333 0.5        0.33333333\n",
      " 0.16666667 0.5        0.16666667 0.33333333]\n",
      "-----------------\n",
      "ExtraTreesClassifier() being used\n",
      "train scores: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "test scores: [0.5        0.33333333 0.66666667 0.33333333 0.83333333 0.16666667\n",
      " 0.         0.16666667 0.83333333 0.33333333]\n",
      "-----------------\n",
      "SVC() being used\n",
      "train scores: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "test scores: [0.33333333 0.33333333 0.5        0.5        0.83333333 0.16666667\n",
      " 0.33333333 0.16666667 0.66666667 0.33333333]\n",
      "-----------------\n",
      "SGDClassifier() being used\n",
      "train scores: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "test scores: [0.5        0.33333333 0.5        0.5        0.83333333 0.16666667\n",
      " 0.5        0.16666667 0.5        0.66666667]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# PLS"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# LDA"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Random Projection"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Auto Encoder"
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.9.6",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.6 64-bit ('base': conda)"
  },
  "interpreter": {
   "hash": "95ec9ec1504d83f612128e0fb229072f90bbb4cb09d9d5d93b5dd26e0ca2cfd1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}