{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Import data"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "brain_data = pd.read_csv('./data/60x61.csv', header=None)\n",
    "brain_data.head()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   0         1         2         3         4         5         6         7   \\\n",
       "0   1  0.062832  0.097064  0.041652  0.008974  0.093586  0.011168  0.010246   \n",
       "1   1  0.025996  0.056383  0.052404  0.079622  0.070710  0.046787  0.004721   \n",
       "2   1  0.015806  0.099749  0.082649  0.076439  0.045748  0.061168  0.037715   \n",
       "3   1  0.096576  0.021273  0.071937  0.023003  0.051179  0.026095  0.014747   \n",
       "4   1  0.024500  0.038100  0.019063  0.004089  0.023010  0.104540  0.075521   \n",
       "\n",
       "         8         9   ...        51        52        53        54        55  \\\n",
       "0  0.097714  0.093843  ...  0.003632  0.028356  0.066206  0.062532  0.100370   \n",
       "1  0.034333  0.059902  ...  0.068505  0.030921  0.004277  0.059342  0.059611   \n",
       "2  0.105080  0.111370  ...  0.073260  0.008919  0.012060  0.038680  0.013767   \n",
       "3  0.027601  0.011309  ...  0.075601  0.028319  0.004177  0.026253  0.025739   \n",
       "4  0.032552  0.018125  ...  0.061589  0.030194  0.004605  0.041527  0.050398   \n",
       "\n",
       "         56        57        58        59        60  \n",
       "0  0.069072  0.025882  0.054651  0.112760  0.106070  \n",
       "1  0.025914  0.018308  0.102880  0.078364  0.049836  \n",
       "2  0.014770  0.028393  0.088890  0.021125  0.014470  \n",
       "3  0.018103  0.075973  0.057072  0.043127  0.024063  \n",
       "4  0.008049  0.125900  0.101010  0.026404  0.004397  \n",
       "\n",
       "[5 rows x 61 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "      <th>60</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.062832</td>\n",
       "      <td>0.097064</td>\n",
       "      <td>0.041652</td>\n",
       "      <td>0.008974</td>\n",
       "      <td>0.093586</td>\n",
       "      <td>0.011168</td>\n",
       "      <td>0.010246</td>\n",
       "      <td>0.097714</td>\n",
       "      <td>0.093843</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003632</td>\n",
       "      <td>0.028356</td>\n",
       "      <td>0.066206</td>\n",
       "      <td>0.062532</td>\n",
       "      <td>0.100370</td>\n",
       "      <td>0.069072</td>\n",
       "      <td>0.025882</td>\n",
       "      <td>0.054651</td>\n",
       "      <td>0.112760</td>\n",
       "      <td>0.106070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.025996</td>\n",
       "      <td>0.056383</td>\n",
       "      <td>0.052404</td>\n",
       "      <td>0.079622</td>\n",
       "      <td>0.070710</td>\n",
       "      <td>0.046787</td>\n",
       "      <td>0.004721</td>\n",
       "      <td>0.034333</td>\n",
       "      <td>0.059902</td>\n",
       "      <td>...</td>\n",
       "      <td>0.068505</td>\n",
       "      <td>0.030921</td>\n",
       "      <td>0.004277</td>\n",
       "      <td>0.059342</td>\n",
       "      <td>0.059611</td>\n",
       "      <td>0.025914</td>\n",
       "      <td>0.018308</td>\n",
       "      <td>0.102880</td>\n",
       "      <td>0.078364</td>\n",
       "      <td>0.049836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0.015806</td>\n",
       "      <td>0.099749</td>\n",
       "      <td>0.082649</td>\n",
       "      <td>0.076439</td>\n",
       "      <td>0.045748</td>\n",
       "      <td>0.061168</td>\n",
       "      <td>0.037715</td>\n",
       "      <td>0.105080</td>\n",
       "      <td>0.111370</td>\n",
       "      <td>...</td>\n",
       "      <td>0.073260</td>\n",
       "      <td>0.008919</td>\n",
       "      <td>0.012060</td>\n",
       "      <td>0.038680</td>\n",
       "      <td>0.013767</td>\n",
       "      <td>0.014770</td>\n",
       "      <td>0.028393</td>\n",
       "      <td>0.088890</td>\n",
       "      <td>0.021125</td>\n",
       "      <td>0.014470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0.096576</td>\n",
       "      <td>0.021273</td>\n",
       "      <td>0.071937</td>\n",
       "      <td>0.023003</td>\n",
       "      <td>0.051179</td>\n",
       "      <td>0.026095</td>\n",
       "      <td>0.014747</td>\n",
       "      <td>0.027601</td>\n",
       "      <td>0.011309</td>\n",
       "      <td>...</td>\n",
       "      <td>0.075601</td>\n",
       "      <td>0.028319</td>\n",
       "      <td>0.004177</td>\n",
       "      <td>0.026253</td>\n",
       "      <td>0.025739</td>\n",
       "      <td>0.018103</td>\n",
       "      <td>0.075973</td>\n",
       "      <td>0.057072</td>\n",
       "      <td>0.043127</td>\n",
       "      <td>0.024063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0.024500</td>\n",
       "      <td>0.038100</td>\n",
       "      <td>0.019063</td>\n",
       "      <td>0.004089</td>\n",
       "      <td>0.023010</td>\n",
       "      <td>0.104540</td>\n",
       "      <td>0.075521</td>\n",
       "      <td>0.032552</td>\n",
       "      <td>0.018125</td>\n",
       "      <td>...</td>\n",
       "      <td>0.061589</td>\n",
       "      <td>0.030194</td>\n",
       "      <td>0.004605</td>\n",
       "      <td>0.041527</td>\n",
       "      <td>0.050398</td>\n",
       "      <td>0.008049</td>\n",
       "      <td>0.125900</td>\n",
       "      <td>0.101010</td>\n",
       "      <td>0.026404</td>\n",
       "      <td>0.004397</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 61 columns</p>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Data preprocessing"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "# Optional: drop zero columns\n",
    "brain_data = brain_data.loc[:, (brain_data != 0).any(axis=0)]\n",
    "brain_data.head()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   0         1         2         3         4         5         6         7   \\\n",
       "0   1  0.062832  0.097064  0.041652  0.008974  0.093586  0.011168  0.010246   \n",
       "1   1  0.025996  0.056383  0.052404  0.079622  0.070710  0.046787  0.004721   \n",
       "2   1  0.015806  0.099749  0.082649  0.076439  0.045748  0.061168  0.037715   \n",
       "3   1  0.096576  0.021273  0.071937  0.023003  0.051179  0.026095  0.014747   \n",
       "4   1  0.024500  0.038100  0.019063  0.004089  0.023010  0.104540  0.075521   \n",
       "\n",
       "         8         9   ...        51        52        53        54        55  \\\n",
       "0  0.097714  0.093843  ...  0.003632  0.028356  0.066206  0.062532  0.100370   \n",
       "1  0.034333  0.059902  ...  0.068505  0.030921  0.004277  0.059342  0.059611   \n",
       "2  0.105080  0.111370  ...  0.073260  0.008919  0.012060  0.038680  0.013767   \n",
       "3  0.027601  0.011309  ...  0.075601  0.028319  0.004177  0.026253  0.025739   \n",
       "4  0.032552  0.018125  ...  0.061589  0.030194  0.004605  0.041527  0.050398   \n",
       "\n",
       "         56        57        58        59        60  \n",
       "0  0.069072  0.025882  0.054651  0.112760  0.106070  \n",
       "1  0.025914  0.018308  0.102880  0.078364  0.049836  \n",
       "2  0.014770  0.028393  0.088890  0.021125  0.014470  \n",
       "3  0.018103  0.075973  0.057072  0.043127  0.024063  \n",
       "4  0.008049  0.125900  0.101010  0.026404  0.004397  \n",
       "\n",
       "[5 rows x 61 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "      <th>60</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.062832</td>\n",
       "      <td>0.097064</td>\n",
       "      <td>0.041652</td>\n",
       "      <td>0.008974</td>\n",
       "      <td>0.093586</td>\n",
       "      <td>0.011168</td>\n",
       "      <td>0.010246</td>\n",
       "      <td>0.097714</td>\n",
       "      <td>0.093843</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003632</td>\n",
       "      <td>0.028356</td>\n",
       "      <td>0.066206</td>\n",
       "      <td>0.062532</td>\n",
       "      <td>0.100370</td>\n",
       "      <td>0.069072</td>\n",
       "      <td>0.025882</td>\n",
       "      <td>0.054651</td>\n",
       "      <td>0.112760</td>\n",
       "      <td>0.106070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.025996</td>\n",
       "      <td>0.056383</td>\n",
       "      <td>0.052404</td>\n",
       "      <td>0.079622</td>\n",
       "      <td>0.070710</td>\n",
       "      <td>0.046787</td>\n",
       "      <td>0.004721</td>\n",
       "      <td>0.034333</td>\n",
       "      <td>0.059902</td>\n",
       "      <td>...</td>\n",
       "      <td>0.068505</td>\n",
       "      <td>0.030921</td>\n",
       "      <td>0.004277</td>\n",
       "      <td>0.059342</td>\n",
       "      <td>0.059611</td>\n",
       "      <td>0.025914</td>\n",
       "      <td>0.018308</td>\n",
       "      <td>0.102880</td>\n",
       "      <td>0.078364</td>\n",
       "      <td>0.049836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0.015806</td>\n",
       "      <td>0.099749</td>\n",
       "      <td>0.082649</td>\n",
       "      <td>0.076439</td>\n",
       "      <td>0.045748</td>\n",
       "      <td>0.061168</td>\n",
       "      <td>0.037715</td>\n",
       "      <td>0.105080</td>\n",
       "      <td>0.111370</td>\n",
       "      <td>...</td>\n",
       "      <td>0.073260</td>\n",
       "      <td>0.008919</td>\n",
       "      <td>0.012060</td>\n",
       "      <td>0.038680</td>\n",
       "      <td>0.013767</td>\n",
       "      <td>0.014770</td>\n",
       "      <td>0.028393</td>\n",
       "      <td>0.088890</td>\n",
       "      <td>0.021125</td>\n",
       "      <td>0.014470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0.096576</td>\n",
       "      <td>0.021273</td>\n",
       "      <td>0.071937</td>\n",
       "      <td>0.023003</td>\n",
       "      <td>0.051179</td>\n",
       "      <td>0.026095</td>\n",
       "      <td>0.014747</td>\n",
       "      <td>0.027601</td>\n",
       "      <td>0.011309</td>\n",
       "      <td>...</td>\n",
       "      <td>0.075601</td>\n",
       "      <td>0.028319</td>\n",
       "      <td>0.004177</td>\n",
       "      <td>0.026253</td>\n",
       "      <td>0.025739</td>\n",
       "      <td>0.018103</td>\n",
       "      <td>0.075973</td>\n",
       "      <td>0.057072</td>\n",
       "      <td>0.043127</td>\n",
       "      <td>0.024063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0.024500</td>\n",
       "      <td>0.038100</td>\n",
       "      <td>0.019063</td>\n",
       "      <td>0.004089</td>\n",
       "      <td>0.023010</td>\n",
       "      <td>0.104540</td>\n",
       "      <td>0.075521</td>\n",
       "      <td>0.032552</td>\n",
       "      <td>0.018125</td>\n",
       "      <td>...</td>\n",
       "      <td>0.061589</td>\n",
       "      <td>0.030194</td>\n",
       "      <td>0.004605</td>\n",
       "      <td>0.041527</td>\n",
       "      <td>0.050398</td>\n",
       "      <td>0.008049</td>\n",
       "      <td>0.125900</td>\n",
       "      <td>0.101010</td>\n",
       "      <td>0.026404</td>\n",
       "      <td>0.004397</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 61 columns</p>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# PCA\n",
    "\n",
    "This might not be the best approach because we have the one hot encoded categorical variable (binary classification)\n",
    "\n",
    "By applying PCA, we lose some of the variance (i.e., information). By reducing the dimensionality of the data, PCA will reduce the size of the data.\n",
    " - This will improve the performance of machine learning algorithms.\n",
    " - This will reduce hardware requirements and speed up the training process.\n",
    " - This will allow us to easily understand the underlying structure of the data.\n",
    " - This will allow us to visualize the data on a 2d or 3d plot (if we choose the number of principal components as 2 or 3)."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Exploratory work"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "# Get feature matrix\n",
    "X = abs(brain_data.iloc[:,1:].values)\n",
    "y = brain_data.iloc[:,0].values\n",
    "print(X)\n",
    "print(y)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[0.062832  0.097064  0.041652  ... 0.054651  0.11276   0.10607  ]\n",
      " [0.025996  0.056383  0.052404  ... 0.10288   0.078364  0.049836 ]\n",
      " [0.015806  0.099749  0.082649  ... 0.08889   0.021125  0.01447  ]\n",
      " ...\n",
      " [0.014674  0.069059  0.096622  ... 0.071405  0.048224  0.042225 ]\n",
      " [0.025404  0.11456   0.11441   ... 0.098878  0.098325  0.080562 ]\n",
      " [0.065748  0.037909  0.039922  ... 0.0092089 0.083488  0.059128 ]]\n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "# Optional: Standardize the features\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "## Create object\n",
    "scaler = StandardScaler()\n",
    "## Calculate mean and std\n",
    "scaler.fit(X)\n",
    "## Transform the values\n",
    "X_scaled = scaler.transform(X)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "X_scaled"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[ 0.39702335,  0.93343425, -0.9722874 , ...,  0.01572054,\n",
       "         2.32913028,  1.99083708],\n",
       "       [-0.66035769, -0.21680926, -0.6466279 , ...,  1.5579035 ,\n",
       "         1.03017178,  0.01957596],\n",
       "       [-0.95286265,  1.00935185,  0.26944088, ...,  1.11055565,\n",
       "        -1.13144833, -1.22016549],\n",
       "       ...,\n",
       "       [-0.98535682,  0.14160098,  0.6926589 , ...,  0.55145077,\n",
       "        -0.10805967, -0.2472247 ],\n",
       "       [-0.67735111,  1.42812858,  1.23142668, ...,  1.42993451,\n",
       "         1.78399521,  1.096664  ],\n",
       "       [ 0.48072742, -0.73915626, -1.02468611, ..., -1.43734778,\n",
       "         1.22367868,  0.34530342]])"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "# apply PCA to all dimensions\n",
    "from sklearn.decomposition import PCA\n",
    "pca_60 = PCA(n_components=60, random_state=42)\n",
    "pca_60.fit(X_scaled)\n",
    "X_pca_60 = pca_60.transform(X_scaled)\n",
    "print('Variance explained by all 60 principal components = ', sum(pca_60.explained_variance_ratio_ * 100))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Variance explained by all 60 principal components =  100.0\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "# The explained_variance_ratio_ attribute of the PCA() class returns\n",
    "# a one-dimensional numpy array which contains the values of the\n",
    "# percentage of variance explained by each of the selected components.\n",
    "pca_60.explained_variance_ratio_ * 100"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([8.98338751e+00, 7.14459783e+00, 6.11449104e+00, 5.68684757e+00,\n",
       "       5.65137931e+00, 4.63679624e+00, 4.07252995e+00, 3.91698189e+00,\n",
       "       3.68622929e+00, 3.57958794e+00, 3.29675248e+00, 3.25283869e+00,\n",
       "       2.94665306e+00, 2.81196908e+00, 2.65075328e+00, 2.32620581e+00,\n",
       "       2.29538042e+00, 2.14291449e+00, 2.09703678e+00, 1.79459330e+00,\n",
       "       1.71523106e+00, 1.58643201e+00, 1.53638259e+00, 1.42774988e+00,\n",
       "       1.33694205e+00, 1.31550137e+00, 1.16689632e+00, 1.10087574e+00,\n",
       "       1.02221796e+00, 9.81479053e-01, 8.60907856e-01, 8.51774893e-01,\n",
       "       7.15439495e-01, 6.08011467e-01, 5.36219731e-01, 5.24456739e-01,\n",
       "       5.07725295e-01, 4.13924995e-01, 3.84959212e-01, 3.03711176e-01,\n",
       "       2.85331113e-01, 2.65030902e-01, 2.42143642e-01, 2.22479626e-01,\n",
       "       1.88526969e-01, 1.72704982e-01, 1.41591149e-01, 1.05313705e-01,\n",
       "       9.97484752e-02, 7.62377639e-02, 6.81623460e-02, 4.59826771e-02,\n",
       "       3.18456151e-02, 2.65156945e-02, 1.94177648e-02, 1.20891273e-02,\n",
       "       8.03075372e-03, 3.00348977e-03, 1.07937619e-03, 1.25974834e-30])"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "# or look at the cumulutive sum as we add more componenets\n",
    "np.cumsum(pca_60.explained_variance_ratio_ * 100)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([  8.98338751,  16.12798534,  22.24247637,  27.92932394,\n",
       "        33.58070325,  38.21749948,  42.29002943,  46.20701132,\n",
       "        49.8932406 ,  53.47282854,  56.76958102,  60.02241971,\n",
       "        62.96907277,  65.78104186,  68.43179514,  70.75800095,\n",
       "        73.05338137,  75.19629586,  77.29333264,  79.08792593,\n",
       "        80.80315699,  82.389589  ,  83.9259716 ,  85.35372148,\n",
       "        86.69066353,  88.0061649 ,  89.17306122,  90.27393695,\n",
       "        91.29615492,  92.27763397,  93.13854183,  93.99031672,\n",
       "        94.70575621,  95.31376768,  95.84998741,  96.37444415,\n",
       "        96.88216944,  97.29609444,  97.68105365,  97.98476483,\n",
       "        98.27009594,  98.53512684,  98.77727049,  98.99975011,\n",
       "        99.18827708,  99.36098206,  99.50257321,  99.60788692,\n",
       "        99.70763539,  99.78387316,  99.8520355 ,  99.89801818,\n",
       "        99.92986379,  99.95637949,  99.97579725,  99.98788638,\n",
       "        99.99591713,  99.99892062, 100.        , 100.        ])"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "'''\n",
    "It's incorrect to use PCA on the Y variable\n",
    "'''\n",
    "# # Leave X and Y in and don't standardize\n",
    "# X = brain_data.values\n",
    "# print(X.shape)\n",
    "\n",
    "# # apply PCA to all dimensions\n",
    "# pca_60 = PCA(n_components=60, random_state=42)\n",
    "# pca_60.fit(X)\n",
    "# X_pca_60 = pca_60.transform(X)\n",
    "# print('Variance explained by all 60 principal components = ', sum(pca_60.explained_variance_ratio_ * 100))\n",
    "# print(pca_60.explained_variance_ratio_ * 100)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "\"\\nIt's incorrect to use PCA on the Y variable\\n\""
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "'''\n",
    "Already Done above\n",
    "'''\n",
    "# # What if we just use the X and leave out the categorical variable?\n",
    "# X = brain_data.iloc[:,1:].values\n",
    "# print(X.shape)\n",
    "# ## Create object\n",
    "# scaler = StandardScaler()\n",
    "# ## Calculate mean and std\n",
    "# scaler.fit(X)\n",
    "# ## Transform the values\n",
    "# X_scaled = scaler.transform(X)\n",
    "\n",
    "# # apply PCA to all dimensions\n",
    "# pca_60_justx = PCA(n_components=60, random_state=42)\n",
    "# pca_60_justx.fit(X_scaled)\n",
    "# X_pca_60 = pca_60_justx.transform(X_scaled)\n",
    "# print('Variance explained by all 60 principal components = ', sum(pca_60_justx.explained_variance_ratio_ * 100))\n",
    "# print(pca_60_justx.explained_variance_ratio_ * 100)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'\\nAlready Done above\\n'"
      ]
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "# What if we just use the X and not scale \n",
    "X = abs(brain_data.iloc[:,1:].values)\n",
    "print(X.shape)\n",
    "# apply PCA to all dimensions\n",
    "pca_60_justx = PCA(n_components=60, random_state=42)\n",
    "pca_60_justx.fit(X)\n",
    "X_pca_60 = pca_60_justx.transform(X)\n",
    "print('Variance explained by all 60 principal components = ', sum(pca_60_justx.explained_variance_ratio_ * 100))\n",
    "print(pca_60_justx.explained_variance_ratio_ * 100)\n",
    "np.cumsum(pca_60_justx.explained_variance_ratio_ * 100)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(60, 60)\n",
      "Variance explained by all 60 principal components =  99.99999999999999\n",
      "[9.92548425e+00 7.73003285e+00 6.34821656e+00 5.66833783e+00\n",
      " 5.41903278e+00 4.53711909e+00 4.13259814e+00 3.90156489e+00\n",
      " 3.57113715e+00 3.49569519e+00 3.25213095e+00 3.10970842e+00\n",
      " 2.96596256e+00 2.75427428e+00 2.58098777e+00 2.29527321e+00\n",
      " 2.17319840e+00 2.06142329e+00 1.96478594e+00 1.75307194e+00\n",
      " 1.67943924e+00 1.57172074e+00 1.48130404e+00 1.32586185e+00\n",
      " 1.30320352e+00 1.23774798e+00 1.16257224e+00 1.10193056e+00\n",
      " 9.50367628e-01 8.89267418e-01 8.39404865e-01 8.00035393e-01\n",
      " 7.49124999e-01 6.10673601e-01 5.43640944e-01 5.09240920e-01\n",
      " 4.95474778e-01 4.24886206e-01 4.05654722e-01 3.09104001e-01\n",
      " 2.89581999e-01 2.52222238e-01 2.42415526e-01 2.18178317e-01\n",
      " 1.90228687e-01 1.63379380e-01 1.29893015e-01 1.02500391e-01\n",
      " 1.01342832e-01 7.14867925e-02 6.53878941e-02 4.33807837e-02\n",
      " 3.19158176e-02 2.49042454e-02 1.88633218e-02 1.21437086e-02\n",
      " 7.48230723e-03 2.96388324e-03 1.03776852e-03 1.44965572e-30]\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([  9.92548425,  17.6555171 ,  24.00373366,  29.67207149,\n",
       "        35.09110427,  39.62822336,  43.7608215 ,  47.66238638,\n",
       "        51.23352353,  54.72921873,  57.98134968,  61.0910581 ,\n",
       "        64.05702065,  66.81129493,  69.3922827 ,  71.68755591,\n",
       "        73.86075431,  75.92217759,  77.88696353,  79.64003547,\n",
       "        81.31947471,  82.89119545,  84.37249948,  85.69836133,\n",
       "        87.00156485,  88.23931283,  89.40188506,  90.50381562,\n",
       "        91.45418324,  92.34345066,  93.18285553,  93.98289092,\n",
       "        94.73201592,  95.34268952,  95.88633047,  96.39557139,\n",
       "        96.89104616,  97.31593237,  97.72158709,  98.03069109,\n",
       "        98.32027309,  98.57249533,  98.81491086,  99.03308917,\n",
       "        99.22331786,  99.38669724,  99.51659025,  99.61909065,\n",
       "        99.72043348,  99.79192027,  99.85730816,  99.90068895,\n",
       "        99.93260477,  99.95750901,  99.97637233,  99.98851604,\n",
       "        99.99599835,  99.99896223, 100.        , 100.        ])"
      ]
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Reducing the number of features meaningfully"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "# Get X values\n",
    "X = abs(brain_data.iloc[:,1:].values)\n",
    "\n",
    "pca_95per = PCA(n_components=0.95, random_state=42)\n",
    "pca_95per.fit(X)\n",
    "X_pca_95per = pca_95per.transform(X)\n",
    "print('Number of principal Componenets', len(pca_95per.explained_variance_ratio_))\n",
    "print(pca_95per.explained_variance_ratio_ * 100)\n",
    "np.cumsum(pca_95per.explained_variance_ratio_ * 100)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Number of principal Componenets 34\n",
      "[9.92548425 7.73003285 6.34821656 5.66833783 5.41903278 4.53711909\n",
      " 4.13259814 3.90156489 3.57113715 3.49569519 3.25213095 3.10970842\n",
      " 2.96596256 2.75427428 2.58098777 2.29527321 2.1731984  2.06142329\n",
      " 1.96478594 1.75307194 1.67943924 1.57172074 1.48130404 1.32586185\n",
      " 1.30320352 1.23774798 1.16257224 1.10193056 0.95036763 0.88926742\n",
      " 0.83940486 0.80003539 0.749125   0.6106736 ]\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([ 9.92548425, 17.6555171 , 24.00373366, 29.67207149, 35.09110427,\n",
       "       39.62822336, 43.7608215 , 47.66238638, 51.23352353, 54.72921873,\n",
       "       57.98134968, 61.0910581 , 64.05702065, 66.81129493, 69.3922827 ,\n",
       "       71.68755591, 73.86075431, 75.92217759, 77.88696353, 79.64003547,\n",
       "       81.31947471, 82.89119545, 84.37249948, 85.69836133, 87.00156485,\n",
       "       88.23931283, 89.40188506, 90.50381562, 91.45418324, 92.34345066,\n",
       "       93.18285553, 93.98289092, 94.73201592, 95.34268952])"
      ]
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## For Fun: Logistic Regression and SVM\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import svm\n",
    "\n",
    "# Get X and y values\n",
    "X = abs(brain_data.iloc[:,1:].values)\n",
    "y = brain_data.iloc[:,0].values\n",
    "print(X.shape)\n",
    "print(y.shape)\n",
    "\n",
    "# Create train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "## Verify\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "\n",
    "# Initialize pca, logistic regression model, and SVM\n",
    "pca = PCA(n_components=0.99, random_state=42)\n",
    "lr = LogisticRegression(multi_class='auto', solver='liblinear')\n",
    "clf = svm.SVC(kernel='rbf')\n",
    "\n",
    "# Fit and transform data\n",
    "X_train_pca = pca.fit_transform(X_train)\n",
    "X_test_pca = pca.transform(X_test)\n",
    "lr.fit(X_train_pca, y_train)\n",
    "clf.fit(X_train_pca, y_train)\n",
    "\n",
    "# Get Results\n",
    "print('-------------')\n",
    "print('Logistic Regression')\n",
    "train_score = lr.score(X_train_pca, y_train)\n",
    "print(f'Train Accuracy: {train_score}')\n",
    "test_score = lr.score(X_test_pca, y_test)\n",
    "print(f'Test Accuracy: {test_score}')\n",
    "print('-------------')\n",
    "print('SVM')\n",
    "train_score = clf.score(X_train_pca, y_train)\n",
    "print(f'Train Accuracy: {train_score}')\n",
    "test_score = clf.score(X_test_pca, y_test)\n",
    "print(f'Test Accuracy: {test_score}')\n",
    "print('--------------')\n",
    "\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(60, 60)\n",
      "(60,)\n",
      "(48, 60)\n",
      "(48,)\n",
      "-------------\n",
      "Logistic Regression\n",
      "Train Accuracy: 0.5625\n",
      "Test Accuracy: 0.3333333333333333\n",
      "-------------\n",
      "SVM\n",
      "Train Accuracy: 1.0\n",
      "Test Accuracy: 0.9166666666666666\n",
      "--------------\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Model Testing"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier, GradientBoostingClassifier, RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import svm\n",
    "import time\n",
    "\n",
    "# Get X and y values\n",
    "X = abs(brain_data.iloc[:,1:].values)\n",
    "y = brain_data.iloc[:,0].values\n",
    "print(X.shape)\n",
    "print(y.shape)\n",
    "\n",
    "# Create train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=2021)\n",
    "## Verify\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "\n",
    "# Initialize pca, logistic regression model, and SVM\n",
    "pca = PCA(n_components=0.95, random_state=42)\n",
    "models = [AdaBoostClassifier(),\n",
    "         GradientBoostingClassifier(),\n",
    "         RandomForestClassifier(), \n",
    "         DecisionTreeClassifier(),\n",
    "         svm.SVC(kernel='rbf')]\n",
    "\n",
    "# Fit and transform data\n",
    "X_train_pca = pca.fit_transform(X_train)\n",
    "X_test_pca = pca.transform(X_test)\n",
    "\n",
    "print('#### PCA Performance ####')\n",
    "for model in models:\n",
    "    print('-----------------')\n",
    "    print(f'{model} being used')\n",
    "    model.fit(X_train_pca, y_train)\n",
    "    train_score = model.score(X_train_pca, y_train)\n",
    "    print(f'Train Accuracy: {train_score}')\n",
    "    test_score = model.score(X_test_pca, y_test)\n",
    "    print(f'Test Accuracy: {test_score}')\n",
    "    time.sleep(3)\n",
    "\n",
    "print('#### Full data Performance ####')\n",
    "for model in models:\n",
    "    print('-----------------')\n",
    "    print(f'{model} being used')\n",
    "    model.fit(X_train, y_train)\n",
    "    train_score = model.score(X_train, y_train)\n",
    "    print(f'Train Accuracy: {train_score}')\n",
    "    test_score = model.score(X_test, y_test)\n",
    "    print(f'Test Accuracy: {test_score}')\n",
    "    time.sleep(3)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(60, 60)\n",
      "(60,)\n",
      "(54, 60)\n",
      "(54,)\n",
      "#### PCA Performance ####\n",
      "-----------------\n",
      "AdaBoostClassifier() being used\n",
      "Train Accuracy: 1.0\n",
      "Test Accuracy: 0.8333333333333334\n",
      "-----------------\n",
      "GradientBoostingClassifier() being used\n",
      "Train Accuracy: 1.0\n",
      "Test Accuracy: 0.6666666666666666\n",
      "-----------------\n",
      "RandomForestClassifier() being used\n",
      "Train Accuracy: 1.0\n",
      "Test Accuracy: 0.6666666666666666\n",
      "-----------------\n",
      "DecisionTreeClassifier() being used\n",
      "Train Accuracy: 1.0\n",
      "Test Accuracy: 0.3333333333333333\n",
      "-----------------\n",
      "SVC() being used\n",
      "Train Accuracy: 1.0\n",
      "Test Accuracy: 0.8333333333333334\n",
      "#### Full data Performance ####\n",
      "-----------------\n",
      "AdaBoostClassifier() being used\n",
      "Train Accuracy: 1.0\n",
      "Test Accuracy: 0.5\n",
      "-----------------\n",
      "GradientBoostingClassifier() being used\n",
      "Train Accuracy: 1.0\n",
      "Test Accuracy: 0.3333333333333333\n",
      "-----------------\n",
      "RandomForestClassifier() being used\n",
      "Train Accuracy: 1.0\n",
      "Test Accuracy: 0.6666666666666666\n",
      "-----------------\n",
      "DecisionTreeClassifier() being used\n",
      "Train Accuracy: 1.0\n",
      "Test Accuracy: 0.5\n",
      "-----------------\n",
      "SVC() being used\n",
      "Train Accuracy: 1.0\n",
      "Test Accuracy: 0.8333333333333334\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Cross validation"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier, GradientBoostingClassifier, RandomForestClassifier, ExtraTreesClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.model_selection import KFold, cross_validate\n",
    "import time\n",
    "\n",
    "# Get X and y values\n",
    "X = abs(brain_data.iloc[:,1:].values)\n",
    "y = brain_data.iloc[:,0].values\n",
    "print(X.shape)\n",
    "print(y.shape)\n",
    "\n",
    "# Initialize pca, logistic regression model, and SVM\n",
    "pca = PCA(n_components=0.95, random_state=42)\n",
    "models = [AdaBoostClassifier(),\n",
    "         GradientBoostingClassifier(),\n",
    "         RandomForestClassifier(), \n",
    "         DecisionTreeClassifier(),\n",
    "         ExtraTreesClassifier(),\n",
    "         svm.SVC(kernel='rbf'),\n",
    "         SGDClassifier()\n",
    "         ]\n",
    "\n",
    "# Fit and transform data\n",
    "X_pca = pca.fit_transform(X)\n",
    "\n",
    "# Initialize Folds\n",
    "k_fold = KFold( n_splits=10,\n",
    "                shuffle=True,\n",
    "                random_state= 2021)\n",
    "\n",
    "print('#### PCA Performance ####')\n",
    "for model in models:\n",
    "    print('-----------------')\n",
    "    print(f'{model} being used')\n",
    "    results = cross_validate(model, X_pca, y, cv=k_fold, return_train_score=True)\n",
    "    train_score = results['train_score']\n",
    "    test_score = results['test_score']\n",
    "    print(f'train scores: {train_score}')\n",
    "    print(f'test scores: {test_score}')\n",
    "    del model\n",
    "    time.sleep(2)\n",
    "print('---------------------------------')\n",
    "print('#### Full data Performance ####')\n",
    "for model in models:\n",
    "    print('-----------------')\n",
    "    print(f'{model} being used')\n",
    "    results = cross_validate(model, X, y, cv=k_fold, return_train_score=True)\n",
    "    train_score = results['train_score']\n",
    "    test_score = results['test_score']\n",
    "    print(f'train scores: {train_score}')\n",
    "    print(f'test scores: {test_score}')\n",
    "    del model\n",
    "    time.sleep(2)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(60, 60)\n",
      "(60,)\n",
      "#### PCA Performance ####\n",
      "-----------------\n",
      "AdaBoostClassifier() being used\n",
      "train scores: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "test scores: [0.33333333 0.66666667 0.16666667 0.5        0.66666667 0.83333333\n",
      " 0.83333333 0.5        0.66666667 0.5       ]\n",
      "-----------------\n",
      "GradientBoostingClassifier() being used\n",
      "train scores: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "test scores: [0.5        0.33333333 0.66666667 0.66666667 0.83333333 0.5\n",
      " 0.66666667 0.33333333 0.66666667 0.83333333]\n",
      "-----------------\n",
      "RandomForestClassifier() being used\n",
      "train scores: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "test scores: [0.5        0.66666667 0.5        0.66666667 0.83333333 0.33333333\n",
      " 0.66666667 0.66666667 0.66666667 0.83333333]\n",
      "-----------------\n",
      "DecisionTreeClassifier() being used\n",
      "train scores: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "test scores: [0.5        0.66666667 0.5        0.66666667 0.66666667 0.33333333\n",
      " 0.66666667 0.5        0.5        0.66666667]\n",
      "-----------------\n",
      "ExtraTreesClassifier() being used\n",
      "train scores: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "test scores: [0.66666667 0.83333333 0.5        0.5        1.         0.66666667\n",
      " 0.5        0.83333333 0.66666667 0.83333333]\n",
      "-----------------\n",
      "SVC() being used\n",
      "train scores: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "test scores: [0.83333333 0.66666667 1.         1.         1.         1.\n",
      " 0.5        0.66666667 1.         0.83333333]\n",
      "-----------------\n",
      "SGDClassifier() being used\n",
      "train scores: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "test scores: [0.83333333 0.83333333 1.         1.         0.83333333 1.\n",
      " 0.66666667 1.         1.         1.        ]\n",
      "---------------------------------\n",
      "#### Full data Performance ####\n",
      "-----------------\n",
      "AdaBoostClassifier() being used\n",
      "train scores: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "test scores: [0.5        0.5        0.66666667 1.         0.83333333 0.66666667\n",
      " 0.66666667 0.66666667 0.83333333 0.5       ]\n",
      "-----------------\n",
      "GradientBoostingClassifier() being used\n",
      "train scores: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "test scores: [0.5        0.83333333 1.         0.33333333 0.5        0.66666667\n",
      " 0.66666667 0.66666667 0.5        0.33333333]\n",
      "-----------------\n",
      "RandomForestClassifier() being used\n",
      "train scores: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "test scores: [0.83333333 0.66666667 0.83333333 1.         0.66666667 0.83333333\n",
      " 0.5        0.5        0.66666667 0.83333333]\n",
      "-----------------\n",
      "DecisionTreeClassifier() being used\n",
      "train scores: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "test scores: [0.5        0.33333333 0.66666667 0.5        0.5        0.83333333\n",
      " 0.5        0.66666667 0.66666667 0.33333333]\n",
      "-----------------\n",
      "ExtraTreesClassifier() being used\n",
      "train scores: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "test scores: [0.5        0.5        0.83333333 0.66666667 1.         0.33333333\n",
      " 0.5        0.5        0.66666667 0.66666667]\n",
      "-----------------\n",
      "SVC() being used\n",
      "train scores: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "test scores: [0.83333333 0.66666667 1.         0.66666667 1.         1.\n",
      " 0.5        0.83333333 1.         0.83333333]\n",
      "-----------------\n",
      "SGDClassifier() being used\n",
      "train scores: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "test scores: [1.         0.66666667 1.         0.83333333 1.         1.\n",
      " 0.83333333 1.         1.         1.        ]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# PLS"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# LDA"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Random Projection"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Auto Encoder"
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.9.6",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.6 64-bit ('base': conda)"
  },
  "interpreter": {
   "hash": "95ec9ec1504d83f612128e0fb229072f90bbb4cb09d9d5d93b5dd26e0ca2cfd1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}