{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SVM_Demo.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UuDyJj8Rur2K"
      },
      "source": [
        "# Import necessary packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-MCSK91qbMzY"
      },
      "source": [
        "from sklearn import svm\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import KFold, cross_validate\n",
        "from sklearn.neural_network import MLPClassifier"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1oh_InmRx7uT"
      },
      "source": [
        "# Read csv using Pandas"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 328
        },
        "id": "PB2TOAUZbR8u",
        "outputId": "8602e259-68b0-43e7-eba2-52553d1d0d4c"
      },
      "source": [
        "# Read in the data using Pandas\n",
        "df = pd.read_csv('eig_centrality.csv', header=None) # Creates a dataframe\n",
        "df.head() # Prints the dataframe out to look pretty"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "      <th>34</th>\n",
              "      <th>35</th>\n",
              "      <th>36</th>\n",
              "      <th>37</th>\n",
              "      <th>38</th>\n",
              "      <th>39</th>\n",
              "      <th>...</th>\n",
              "      <th>255</th>\n",
              "      <th>256</th>\n",
              "      <th>257</th>\n",
              "      <th>258</th>\n",
              "      <th>259</th>\n",
              "      <th>260</th>\n",
              "      <th>261</th>\n",
              "      <th>262</th>\n",
              "      <th>263</th>\n",
              "      <th>264</th>\n",
              "      <th>265</th>\n",
              "      <th>266</th>\n",
              "      <th>267</th>\n",
              "      <th>268</th>\n",
              "      <th>269</th>\n",
              "      <th>270</th>\n",
              "      <th>271</th>\n",
              "      <th>272</th>\n",
              "      <th>273</th>\n",
              "      <th>274</th>\n",
              "      <th>275</th>\n",
              "      <th>276</th>\n",
              "      <th>277</th>\n",
              "      <th>278</th>\n",
              "      <th>279</th>\n",
              "      <th>280</th>\n",
              "      <th>281</th>\n",
              "      <th>282</th>\n",
              "      <th>283</th>\n",
              "      <th>284</th>\n",
              "      <th>285</th>\n",
              "      <th>286</th>\n",
              "      <th>287</th>\n",
              "      <th>288</th>\n",
              "      <th>289</th>\n",
              "      <th>290</th>\n",
              "      <th>291</th>\n",
              "      <th>292</th>\n",
              "      <th>293</th>\n",
              "      <th>294</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>-0.067894</td>\n",
              "      <td>-0.062832</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.031240</td>\n",
              "      <td>-0.071004</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.030888</td>\n",
              "      <td>0</td>\n",
              "      <td>0.009534</td>\n",
              "      <td>0.044660</td>\n",
              "      <td>0.043163</td>\n",
              "      <td>0.025440</td>\n",
              "      <td>0.017731</td>\n",
              "      <td>0.035212</td>\n",
              "      <td>0.088166</td>\n",
              "      <td>0.003441</td>\n",
              "      <td>0.080688</td>\n",
              "      <td>0.101520</td>\n",
              "      <td>0.077959</td>\n",
              "      <td>0.097064</td>\n",
              "      <td>0.076933</td>\n",
              "      <td>0.094497</td>\n",
              "      <td>0.084009</td>\n",
              "      <td>0.058484</td>\n",
              "      <td>0.055487</td>\n",
              "      <td>0.054127</td>\n",
              "      <td>0.078746</td>\n",
              "      <td>0.096342</td>\n",
              "      <td>0.108900</td>\n",
              "      <td>0.108390</td>\n",
              "      <td>0.075506</td>\n",
              "      <td>0.073203</td>\n",
              "      <td>0.041652</td>\n",
              "      <td>0.008974</td>\n",
              "      <td>0.083625</td>\n",
              "      <td>0.093586</td>\n",
              "      <td>...</td>\n",
              "      <td>0.094845</td>\n",
              "      <td>0.062697</td>\n",
              "      <td>-0.059325</td>\n",
              "      <td>0.069769</td>\n",
              "      <td>0.068181</td>\n",
              "      <td>0.025882</td>\n",
              "      <td>0.061238</td>\n",
              "      <td>-0.019074</td>\n",
              "      <td>0.035774</td>\n",
              "      <td>0.095434</td>\n",
              "      <td>-0.082962</td>\n",
              "      <td>-0.035576</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.112860</td>\n",
              "      <td>-0.127800</td>\n",
              "      <td>-0.139090</td>\n",
              "      <td>-0.089231</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.116870</td>\n",
              "      <td>-0.110560</td>\n",
              "      <td>-0.054651</td>\n",
              "      <td>-0.094422</td>\n",
              "      <td>-0.136430</td>\n",
              "      <td>-0.093386</td>\n",
              "      <td>-0.061698</td>\n",
              "      <td>-0.137690</td>\n",
              "      <td>-0.130130</td>\n",
              "      <td>-0.064658</td>\n",
              "      <td>-0.124140</td>\n",
              "      <td>-0.112760</td>\n",
              "      <td>-0.106070</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>-0.028195</td>\n",
              "      <td>-0.024616</td>\n",
              "      <td>-0.042535</td>\n",
              "      <td>-0.087451</td>\n",
              "      <td>0.003145</td>\n",
              "      <td>-0.047196</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0.031793</td>\n",
              "      <td>0.025996</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.122030</td>\n",
              "      <td>0.109220</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.005733</td>\n",
              "      <td>0</td>\n",
              "      <td>0.017223</td>\n",
              "      <td>-0.072822</td>\n",
              "      <td>-0.077072</td>\n",
              "      <td>-0.126650</td>\n",
              "      <td>-0.075474</td>\n",
              "      <td>-0.054951</td>\n",
              "      <td>-0.071225</td>\n",
              "      <td>-0.069048</td>\n",
              "      <td>-0.019571</td>\n",
              "      <td>-0.011447</td>\n",
              "      <td>-0.052877</td>\n",
              "      <td>-0.056383</td>\n",
              "      <td>-0.103610</td>\n",
              "      <td>-0.055508</td>\n",
              "      <td>-0.048856</td>\n",
              "      <td>-0.075161</td>\n",
              "      <td>-0.080446</td>\n",
              "      <td>-0.076218</td>\n",
              "      <td>-0.014105</td>\n",
              "      <td>-0.080723</td>\n",
              "      <td>-0.036228</td>\n",
              "      <td>-0.017804</td>\n",
              "      <td>-0.092622</td>\n",
              "      <td>-0.061210</td>\n",
              "      <td>-0.052404</td>\n",
              "      <td>-0.079622</td>\n",
              "      <td>-0.007010</td>\n",
              "      <td>-0.070710</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.059486</td>\n",
              "      <td>0.007645</td>\n",
              "      <td>0.012460</td>\n",
              "      <td>-0.002890</td>\n",
              "      <td>-0.011348</td>\n",
              "      <td>0.018308</td>\n",
              "      <td>-0.055966</td>\n",
              "      <td>0.055130</td>\n",
              "      <td>-0.035946</td>\n",
              "      <td>-0.084412</td>\n",
              "      <td>0.079950</td>\n",
              "      <td>0.102600</td>\n",
              "      <td>-9.183500e-41</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.024538</td>\n",
              "      <td>-0.015028</td>\n",
              "      <td>0.092486</td>\n",
              "      <td>0.078047</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.002061</td>\n",
              "      <td>0.010612</td>\n",
              "      <td>0.102880</td>\n",
              "      <td>0.134880</td>\n",
              "      <td>0.080157</td>\n",
              "      <td>0.022855</td>\n",
              "      <td>0.105170</td>\n",
              "      <td>0.000352</td>\n",
              "      <td>0.028527</td>\n",
              "      <td>0.108250</td>\n",
              "      <td>0.116960</td>\n",
              "      <td>0.078364</td>\n",
              "      <td>0.049836</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>6.938900e-18</td>\n",
              "      <td>-0.076947</td>\n",
              "      <td>-0.078418</td>\n",
              "      <td>-0.064815</td>\n",
              "      <td>0.095082</td>\n",
              "      <td>0.054585</td>\n",
              "      <td>0.076347</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>-0.005251</td>\n",
              "      <td>-0.015806</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.124040</td>\n",
              "      <td>-0.117020</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.017355</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.035984</td>\n",
              "      <td>0.106950</td>\n",
              "      <td>0.011851</td>\n",
              "      <td>0.077032</td>\n",
              "      <td>0.097769</td>\n",
              "      <td>0.086296</td>\n",
              "      <td>0.066662</td>\n",
              "      <td>0.073620</td>\n",
              "      <td>0.083824</td>\n",
              "      <td>0.098246</td>\n",
              "      <td>0.077604</td>\n",
              "      <td>0.099749</td>\n",
              "      <td>0.086089</td>\n",
              "      <td>0.089017</td>\n",
              "      <td>0.102960</td>\n",
              "      <td>0.078025</td>\n",
              "      <td>0.092228</td>\n",
              "      <td>0.107700</td>\n",
              "      <td>0.112640</td>\n",
              "      <td>0.082732</td>\n",
              "      <td>0.093102</td>\n",
              "      <td>0.077609</td>\n",
              "      <td>0.113730</td>\n",
              "      <td>0.055680</td>\n",
              "      <td>0.082649</td>\n",
              "      <td>0.076439</td>\n",
              "      <td>0.081579</td>\n",
              "      <td>0.045748</td>\n",
              "      <td>...</td>\n",
              "      <td>0.103580</td>\n",
              "      <td>0.075484</td>\n",
              "      <td>0.001077</td>\n",
              "      <td>0.108460</td>\n",
              "      <td>0.067752</td>\n",
              "      <td>0.028393</td>\n",
              "      <td>0.094205</td>\n",
              "      <td>0.034880</td>\n",
              "      <td>0.098304</td>\n",
              "      <td>0.112640</td>\n",
              "      <td>-0.028600</td>\n",
              "      <td>-0.036377</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.053667</td>\n",
              "      <td>-0.060843</td>\n",
              "      <td>-0.134010</td>\n",
              "      <td>-0.081699</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.049926</td>\n",
              "      <td>-0.059831</td>\n",
              "      <td>-0.088890</td>\n",
              "      <td>-0.126040</td>\n",
              "      <td>-0.094744</td>\n",
              "      <td>-0.068796</td>\n",
              "      <td>-0.129440</td>\n",
              "      <td>-0.028749</td>\n",
              "      <td>-0.061654</td>\n",
              "      <td>-0.102060</td>\n",
              "      <td>-0.123930</td>\n",
              "      <td>0.021125</td>\n",
              "      <td>0.014470</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>-1.734700e-18</td>\n",
              "      <td>0.068705</td>\n",
              "      <td>0.084321</td>\n",
              "      <td>0.047107</td>\n",
              "      <td>0.004649</td>\n",
              "      <td>-0.142760</td>\n",
              "      <td>-0.129450</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>0.123150</td>\n",
              "      <td>0.096576</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.045236</td>\n",
              "      <td>-0.005144</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.017959</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.060064</td>\n",
              "      <td>0.008232</td>\n",
              "      <td>-0.076910</td>\n",
              "      <td>-0.042061</td>\n",
              "      <td>-0.070811</td>\n",
              "      <td>0.004588</td>\n",
              "      <td>-0.022294</td>\n",
              "      <td>0.009102</td>\n",
              "      <td>-0.016151</td>\n",
              "      <td>0.039059</td>\n",
              "      <td>-0.042386</td>\n",
              "      <td>-0.021273</td>\n",
              "      <td>-0.029647</td>\n",
              "      <td>0.045843</td>\n",
              "      <td>-0.008927</td>\n",
              "      <td>-0.010325</td>\n",
              "      <td>0.056369</td>\n",
              "      <td>-0.065302</td>\n",
              "      <td>-0.019544</td>\n",
              "      <td>-0.101130</td>\n",
              "      <td>0.003862</td>\n",
              "      <td>0.027688</td>\n",
              "      <td>0.017441</td>\n",
              "      <td>-0.032492</td>\n",
              "      <td>-0.071937</td>\n",
              "      <td>-0.023003</td>\n",
              "      <td>-0.069430</td>\n",
              "      <td>-0.051179</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.030251</td>\n",
              "      <td>-0.028163</td>\n",
              "      <td>-0.034214</td>\n",
              "      <td>-0.011463</td>\n",
              "      <td>0.051749</td>\n",
              "      <td>0.075973</td>\n",
              "      <td>0.076361</td>\n",
              "      <td>-0.046896</td>\n",
              "      <td>-0.072086</td>\n",
              "      <td>-0.037212</td>\n",
              "      <td>-0.021482</td>\n",
              "      <td>0.058920</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.017652</td>\n",
              "      <td>0.078869</td>\n",
              "      <td>-0.003089</td>\n",
              "      <td>-0.079264</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.086015</td>\n",
              "      <td>-0.085522</td>\n",
              "      <td>-0.057072</td>\n",
              "      <td>-0.043701</td>\n",
              "      <td>0.058082</td>\n",
              "      <td>0.131980</td>\n",
              "      <td>0.072555</td>\n",
              "      <td>0.093190</td>\n",
              "      <td>0.068831</td>\n",
              "      <td>0.057364</td>\n",
              "      <td>0.023296</td>\n",
              "      <td>-0.043127</td>\n",
              "      <td>-0.024063</td>\n",
              "      <td>5.551100e-17</td>\n",
              "      <td>-1.110200e-16</td>\n",
              "      <td>-0.064510</td>\n",
              "      <td>-0.100380</td>\n",
              "      <td>-0.112950</td>\n",
              "      <td>-0.099919</td>\n",
              "      <td>-0.006036</td>\n",
              "      <td>-0.004228</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>-0.059846</td>\n",
              "      <td>-0.024500</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.022105</td>\n",
              "      <td>0.022153</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.079495</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.013115</td>\n",
              "      <td>0.019867</td>\n",
              "      <td>0.032033</td>\n",
              "      <td>0.012232</td>\n",
              "      <td>-0.110770</td>\n",
              "      <td>-0.046852</td>\n",
              "      <td>-0.009582</td>\n",
              "      <td>0.066438</td>\n",
              "      <td>-0.120040</td>\n",
              "      <td>-0.041749</td>\n",
              "      <td>0.030221</td>\n",
              "      <td>-0.038100</td>\n",
              "      <td>0.030946</td>\n",
              "      <td>-0.057344</td>\n",
              "      <td>-0.059953</td>\n",
              "      <td>-0.044087</td>\n",
              "      <td>-0.096188</td>\n",
              "      <td>0.040108</td>\n",
              "      <td>-0.079170</td>\n",
              "      <td>-0.042053</td>\n",
              "      <td>-0.123180</td>\n",
              "      <td>-0.076904</td>\n",
              "      <td>-0.039368</td>\n",
              "      <td>-0.029376</td>\n",
              "      <td>-0.019063</td>\n",
              "      <td>0.004089</td>\n",
              "      <td>0.039264</td>\n",
              "      <td>-0.023010</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.059486</td>\n",
              "      <td>-0.036794</td>\n",
              "      <td>-0.040853</td>\n",
              "      <td>-0.026317</td>\n",
              "      <td>0.070208</td>\n",
              "      <td>0.125900</td>\n",
              "      <td>-0.098118</td>\n",
              "      <td>-0.049597</td>\n",
              "      <td>0.098125</td>\n",
              "      <td>-0.066539</td>\n",
              "      <td>-0.062693</td>\n",
              "      <td>-0.048001</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.074480</td>\n",
              "      <td>0.103110</td>\n",
              "      <td>0.031418</td>\n",
              "      <td>-0.006784</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.017380</td>\n",
              "      <td>0.033752</td>\n",
              "      <td>0.101010</td>\n",
              "      <td>0.112420</td>\n",
              "      <td>0.025864</td>\n",
              "      <td>0.009141</td>\n",
              "      <td>-0.028837</td>\n",
              "      <td>0.096856</td>\n",
              "      <td>0.072896</td>\n",
              "      <td>0.026515</td>\n",
              "      <td>0.027951</td>\n",
              "      <td>-0.026404</td>\n",
              "      <td>-0.004397</td>\n",
              "      <td>-4.336800e-19</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>-0.068379</td>\n",
              "      <td>0.006091</td>\n",
              "      <td>-0.050172</td>\n",
              "      <td>0.056009</td>\n",
              "      <td>0.077894</td>\n",
              "      <td>0.016500</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows Ã— 295 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   0         1         2    3    ...       291       292       293       294\n",
              "0    1 -0.067894 -0.062832    0  ... -0.042535 -0.087451  0.003145 -0.047196\n",
              "1    1  0.031793  0.025996    0  ... -0.064815  0.095082  0.054585  0.076347\n",
              "2    1 -0.005251 -0.015806    0  ...  0.047107  0.004649 -0.142760 -0.129450\n",
              "3    1  0.123150  0.096576    0  ... -0.112950 -0.099919 -0.006036 -0.004228\n",
              "4    1 -0.059846 -0.024500    0  ... -0.050172  0.056009  0.077894  0.016500\n",
              "\n",
              "[5 rows x 295 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mqDZE2kVkytS"
      },
      "source": [
        "# Optional: Drop the rows that have zero for any column\n",
        "df = df.loc[:, (df != 0).any(axis=0)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1_VMZlZtyBvl"
      },
      "source": [
        "# Extract X and y from dataframe"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zUDPpDN6g6Tr",
        "outputId": "b149021b-f17d-4ded-e068-a707c77e87c7"
      },
      "source": [
        "# Retrieve y from the dataframe\n",
        "y = df.iloc[:,0]\n",
        "print(y.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(60,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PMZ7Eeqohb99",
        "outputId": "813b98b3-eeb9-4924-f0c2-fab3a30ad7d5"
      },
      "source": [
        "# Retrieve our feature vector from the dataframe\n",
        "X = df.iloc[:,1:]\n",
        "print(X.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(60, 273)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RaDI72_9yIsq"
      },
      "source": [
        "# Create SVM model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BeG49DvcbPzd"
      },
      "source": [
        "# Initilize the SVM model as 'clf' by calling the constructor\n",
        "clf = svm.SVC(kernel='rbf')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4aMdwScHhviU",
        "outputId": "dd907e24-3491-4fe1-c24e-29b10500518c"
      },
      "source": [
        "# Fit a model on all data to see if an SVM has the ability to learn \n",
        "clf.fit(X,y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
              "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='rbf',\n",
              "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
              "    tol=0.001, verbose=False)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jOLpYLLCh8Zr",
        "outputId": "72bab06a-d8d4-4594-e4f6-2abcacd847c5"
      },
      "source": [
        "# Get the accuracy on all the data\n",
        "clf.score(X,y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "twTKDMybiU3b",
        "outputId": "f0eea4eb-a581-42bb-c0d6-a167671cacf6"
      },
      "source": [
        "# Run cross validation on an svm model\n",
        "clf = svm.SVC(kernel='rbf')\n",
        "k_fold = KFold( n_splits = 60 , \n",
        "                shuffle = True , \n",
        "                random_state = 42)\n",
        "results = cross_validate(clf, X, y, cv=k_fold, return_train_score = True)\n",
        "print(results)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'fit_time': array([0.00759435, 0.00399637, 0.00361705, 0.00359178, 0.00708842,\n",
            "       0.00475335, 0.00491333, 0.00373197, 0.00370383, 0.00355315,\n",
            "       0.00353551, 0.003649  , 0.0036149 , 0.00459003, 0.00441957,\n",
            "       0.00404167, 0.00369334, 0.00361156, 0.00369072, 0.00367022,\n",
            "       0.00484848, 0.01281071, 0.00395632, 0.00385141, 0.00362301,\n",
            "       0.00402522, 0.00350213, 0.00381398, 0.00348759, 0.00346136,\n",
            "       0.00352716, 0.00427461, 0.00454712, 0.00355649, 0.00353336,\n",
            "       0.0034523 , 0.00341702, 0.00364542, 0.00342202, 0.00343895,\n",
            "       0.00522733, 0.00761843, 0.00377893, 0.00363326, 0.00363708,\n",
            "       0.00428271, 0.00351286, 0.00342369, 0.00342584, 0.00415421,\n",
            "       0.00358772, 0.00366759, 0.00356269, 0.00358796, 0.00340986,\n",
            "       0.00342178, 0.00800395, 0.00376296, 0.00366998, 0.00349116]), 'score_time': array([0.00416327, 0.00146246, 0.00119615, 0.00116301, 0.00188041,\n",
            "       0.00162458, 0.00176764, 0.00131345, 0.00114894, 0.00112391,\n",
            "       0.00118089, 0.00150394, 0.00113392, 0.00143313, 0.00122595,\n",
            "       0.00136781, 0.00123692, 0.00137734, 0.00120091, 0.00119615,\n",
            "       0.00178075, 0.00312877, 0.00136995, 0.00127983, 0.00117517,\n",
            "       0.00126243, 0.0011332 , 0.00115252, 0.00139189, 0.00111341,\n",
            "       0.00111485, 0.00118613, 0.00122213, 0.00114417, 0.0010941 ,\n",
            "       0.00109029, 0.00110769, 0.00114655, 0.00106406, 0.00163484,\n",
            "       0.00192165, 0.00136924, 0.00116372, 0.00123501, 0.00111556,\n",
            "       0.00116754, 0.00108862, 0.00111485, 0.00107455, 0.00153303,\n",
            "       0.0011847 , 0.00120497, 0.00113392, 0.00112987, 0.00104427,\n",
            "       0.00133991, 0.00184703, 0.0012238 , 0.00117803, 0.00113893]), 'test_score': array([1., 0., 0., 1., 1., 0., 0., 0., 1., 1., 0., 1., 0., 1., 0., 1., 1.,\n",
            "       0., 1., 0., 1., 1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0.,\n",
            "       1., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 1., 0., 1., 0., 0., 0.,\n",
            "       1., 0., 0., 1., 1., 1., 1., 0., 1.]), 'train_score': array([0.91525424, 0.88135593, 0.89830508, 0.89830508, 0.91525424,\n",
            "       0.88135593, 0.91525424, 0.91525424, 0.91525424, 0.89830508,\n",
            "       0.91525424, 0.89830508, 0.88135593, 0.91525424, 0.89830508,\n",
            "       0.91525424, 0.91525424, 0.93220339, 0.89830508, 0.93220339,\n",
            "       0.89830508, 0.89830508, 0.89830508, 0.88135593, 0.91525424,\n",
            "       0.89830508, 0.89830508, 0.91525424, 0.91525424, 0.94915254,\n",
            "       0.93220339, 0.89830508, 0.93220339, 0.88135593, 0.93220339,\n",
            "       0.89830508, 0.91525424, 0.89830508, 0.89830508, 0.93220339,\n",
            "       0.86440678, 0.89830508, 0.91525424, 0.89830508, 0.89830508,\n",
            "       0.89830508, 0.91525424, 0.93220339, 0.91525424, 0.91525424,\n",
            "       0.89830508, 0.91525424, 0.89830508, 0.93220339, 0.91525424,\n",
            "       0.88135593, 0.93220339, 0.89830508, 0.89830508, 0.89830508])}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MyDBIFVMilBM",
        "outputId": "25e6c998-3e5e-40c4-8dce-b276e693a922"
      },
      "source": [
        "# Calculate mean test accuracy across multiple folds\n",
        "np.mean(results['test_score'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5166666666666667"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VBeiuX6jxKus"
      },
      "source": [
        "# Try \"deep\" learning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7BtNGg2ilpO7"
      },
      "source": [
        "# Initalize deep learning modell\n",
        "deep_net = MLPClassifier()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6FS4oIchlrop",
        "outputId": "2167c9d2-2dec-409c-cc57-f89d4ce63f57"
      },
      "source": [
        "# Run Crossvalidation\n",
        "k_fold = KFold( n_splits = 5 , \n",
        "                shuffle = True , \n",
        "                random_state = 20)\n",
        "results = cross_validate(deep_net, X, y, cv=k_fold, return_train_score = True)\n",
        "print(results)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'fit_time': array([0.38448954, 0.37845063, 0.34416318, 0.33369327, 0.33939147]), 'score_time': array([0.00251627, 0.00246477, 0.00246954, 0.00250125, 0.00256586]), 'test_score': array([0.66666667, 0.58333333, 0.58333333, 0.41666667, 0.5       ]), 'train_score': array([1., 1., 1., 1., 1.])}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bywk6fGYlwwb",
        "outputId": "0edcafad-1c4f-4410-fa65-b2f07a0982fe"
      },
      "source": [
        "# Calculate mean results across multiple folds\n",
        "np.mean(results['test_score'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.55"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    }
  ]
}