{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Import packages"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.ensemble import AdaBoostClassifier, GradientBoostingClassifier, RandomForestClassifier, ExtraTreesClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.model_selection import KFold, cross_validate, LeaveOneOut\n",
    "import time"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Writing a function for our needs:\n",
    "- ~~Handle importing a single or a list of dataframes~~ Handle this with a loop that incorporates the function\n",
    "- Decide whether a dataframe needs to have the zero columns taken out\n",
    "- Possibly allow for PCA inside of the function? TBD\n",
    "- Return results to a dataframe, write them to csv\n",
    "- Allow user to specfiy notes for the runs\n",
    "- Specify models used for training\n",
    "- Cross validation will be on by default, too complicated to have both functionality\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "source": [
    "def train_test_models(file_name, models='ALL', crossval_method='kfold',\n",
    "                        zero_column_delete=True, absolute_value=True, notes=None):\n",
    "    \"\"\"[summary]\n",
    "\n",
    "    Args:\n",
    "        file_name ([type]): file to use for data\n",
    "        models (str, optional): Model to be used for training and testing. Defaults to 'ALL'.\n",
    "                                If all is selected, many different types of classifiers will\n",
    "                                be used for training and testing.\n",
    "        crossval_method (str, optional): Cross validation method used for model training.\n",
    "                                         'kfold' and 'loo' are acceptable inputs.\n",
    "                                         Defaults to 'kfold'.\n",
    "        zero_column_delete (bool, optional): Gets rid of columns with all values=0. Defaults to True.\n",
    "        absolute_value (bool, optional): Takes the absolute value of every datapoint. Defaults to True.\n",
    "        notes ([type], optional): Description of the run. Defaults to None.\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"############################\")\n",
    "    print(\"Begining train_test function\")\n",
    "    print(\"############################\")\n",
    "    print(f'File the data is being pulled from: {file_name}')\n",
    "\n",
    "    # Load in the data using pandas into a dataframe\n",
    "    data_df = pd.read_csv(file_name, header=None)\n",
    "    print(f'Data is of shape {data_df.shape}')\n",
    "\n",
    "    # Delete the zero value columns if argument is provided\n",
    "    if zero_column_delete:\n",
    "        print('Columns with all Zeros are being removed')\n",
    "        data_df = data_df.loc[:, (data_df != 0).any(axis=0)]\n",
    "    \n",
    "    # Get values from dataframe \n",
    "    X = data_df.iloc[:, 1:].values\n",
    "    y = data_df.iloc[:, 0].values\n",
    "\n",
    "    # Set absolute value of X if argument is provided\n",
    "    if absolute_value:\n",
    "        X = abs(X)\n",
    "    \n",
    "    # Initialize models if 'ALL' is selected\n",
    "    if models == 'ALL':\n",
    "        models = [AdaBoostClassifier(),\n",
    "                GradientBoostingClassifier(),\n",
    "                RandomForestClassifier(), \n",
    "                DecisionTreeClassifier(),\n",
    "                ExtraTreesClassifier(),\n",
    "                svm.SVC(kernel='rbf'),\n",
    "                SGDClassifier(random_state=2021)]\n",
    "\n",
    "    ## Check to see if model is in list or not\n",
    "    elif type(models) is not list:\n",
    "        print(f'{models} is not given in list format')\n",
    "        raise\n",
    "\n",
    "    # Initialize cross validation\n",
    "    if crossval_method == 'kfold':\n",
    "        cross_val = KFold(n_splits=10,\n",
    "                          shuffle=True,\n",
    "                          random_state = 42)\n",
    "    elif crossval_method == 'loo':\n",
    "        cross_val = LeaveOneOut()\n",
    "    else:\n",
    "        print('crossval_method neither kfold or loo')\n",
    "\n",
    "    # Initiailze dataframe to store results\n",
    "    results_df = pd.DataFrame([], columns = ['filename',\n",
    "                                                'model',\n",
    "                                                'train_scores',\n",
    "                                                'test_scores',\n",
    "                                                'min_test',\n",
    "                                                'avg_test',\n",
    "                                                'max_test',\n",
    "                                                'notes'])\n",
    "    \n",
    "    # Model training testing loop\n",
    "    for model in models:\n",
    "        print('-----------------')\n",
    "        print(f'{model} being used')\n",
    "        results = cross_validate(model, X, y, cv=cross_val, return_train_score=True)\n",
    "        train_score = results['train_score']\n",
    "        test_score = results['test_score']\n",
    "        test_min = min(test_score)\n",
    "        test_avg = np.mean(test_score)\n",
    "        test_max = max(test_score)\n",
    "        print(f'train scores: {train_score}')\n",
    "        print(f'test scores: {test_score}')\n",
    "        ## Create a dict to store results (makes dataframes easier)\n",
    "        results_dict = {'filename': file_name,\n",
    "                        'model': str(model),\n",
    "                        'train_scores': [train_score.round(3)],\n",
    "                        'test_scores': [test_score.round(3)],\n",
    "                        'min_test': test_min,\n",
    "                        'avg_test': test_avg,\n",
    "                        'max_test': test_max,\n",
    "                        'notes': notes,\n",
    "                        }\n",
    "        temp_df = pd.DataFrame(results_dict, index=[0])\n",
    "        results_df = results_df.append(temp_df, ignore_index=True)\n",
    "        del results\n",
    "        del model\n",
    "        time.sleep(2)\n",
    "        print('---------------------------------')\n",
    "\n",
    "    return(results_df)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Test function"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "source": [
    "# test_file = './data/eig_centrality.csv'\n",
    "# results = train_test_models(test_file)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "source": [
    "# results"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Question about how absolute value affects results"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "source": [
    "# # Create a dataframe to store all results from all tests\n",
    "# master_results = pd.DataFrame(None)\n",
    "\n",
    "# # Raw data with negatives and zeros\n",
    "# notes = 'raw data, has negatives, has zeros'\n",
    "# raw_data_results = train_test_models('./data/eig_centrality.csv', zero_column_delete=False, absolute_value=False,\n",
    "#                                     notes=notes)\n",
    "\n",
    "# # Raw data with negatives and zeros taken out\n",
    "# notes = 'raw data, has negatives, zeros are removed'\n",
    "# noZeros_Negatives_data_results = train_test_models('./data/eig_centrality.csv', zero_column_delete=True, absolute_value=False,\n",
    "#                                     notes=notes)\n",
    "\n",
    "# # Raw data with no negatives and no zeros\n",
    "# notes = 'raw data, no negatives(absolute values only), zeros are removed'\n",
    "# noZeros_noNegatives_raw_data_results = train_test_models('./data/eig_centrality.csv', zero_column_delete=True, absolute_value=True,\n",
    "#                                     notes=notes)\n",
    "\n",
    "# # Elasticnet results\n",
    "# notes = 'Elasticnet Used as dimensionality reduction'\n",
    "# notes = 'Dimensionality reduction using elasticnet'\n",
    "# elastic_net_results = train_test_models('./data/60x61.csv', zero_column_delete=False, absolute_value=False,\n",
    "#                                         notes=notes)\n",
    "\n",
    "# master_results = master_results.append(raw_data_results, ignore_index=True)\n",
    "# master_results = master_results.append(noZeros_Negatives_data_results, ignore_index=True)\n",
    "# master_results = master_results.append(noZeros_noNegatives_raw_data_results, ignore_index=True)\n",
    "# master_results = master_results.append(elastic_net_results, ignore_index=True)\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "source": [
    "# master_results.head(15)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "source": [
    "# master_results.to_csv('models_results.csv',index=False)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Multiple data files\n",
    "Upload a zip file containing all your data\n",
    "You can use the unix command line interface through the jupyter notebook by using **\"!\"**"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "source": [
    "# unzip data folder\n",
    "'''\n",
    "Use the folder icon on the left side to open the running directory.\n",
    "You must be connected to a run time for the directory to be shown.\n",
    "Before you run the following cells\n",
    "'''\n",
    "!unzip ./data.zip"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "unzip:  cannot find or open ./data.zip, ./data.zip.zip or ./data.zip.ZIP.\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "source": [
    "# use os to get files in the said directory\n",
    "data_directory = './data' # Specify the data folder ## This is necessary ##\n",
    "data_files = [] # create an empty list object to store the file paths\n",
    "for x in os.listdir('./data'):\n",
    "    if x.endswith('.csv'): # get only files that are csv\n",
    "        data_files.append(f'{data_directory}/{x}') # get direct path\n",
    "print(data_files)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['./data/60x61.csv', './data/eig_centrality.csv']\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "source": [
    "# loop over the files to train models and get results\n",
    "master_df = pd.DataFrame(None) # create a dataframe to store model training results\n",
    "for data_file in data_files:\n",
    "    # Run our function uisng \"loo\" cross validation\n",
    "    # If you want kfold change the crossval_method='kfold'\n",
    "    run_results = train_test_models(data_file, models='ALL', crossval_method='loo')\n",
    "    master_df = master_df.append(run_results, ignore_index=True)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "############################\n",
      "Begining train_test function\n",
      "############################\n",
      "File the data is being pulled from: ./data/60x61.csv\n",
      "Data is of shape (60, 61)\n",
      "Columns with all Zeros are being removed\n",
      "-----------------\n",
      "AdaBoostClassifier() being used\n",
      "train scores: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "test scores: [1. 1. 1. 0. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 0. 0. 0. 0. 1. 1.\n",
      " 0. 0. 0. 0. 1. 1. 1. 1. 1. 0. 0. 1. 1. 0. 1. 0. 1. 0. 0. 1. 1. 0. 1. 0.\n",
      " 1. 1. 1. 1. 0. 1. 1. 1. 0. 1. 1. 1.]\n",
      "---------------------------------\n",
      "-----------------\n",
      "GradientBoostingClassifier() being used\n",
      "train scores: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "test scores: [0. 1. 1. 0. 0. 1. 0. 0. 0. 1. 0. 1. 0. 1. 1. 1. 1. 1. 1. 0. 0. 0. 1. 1.\n",
      " 0. 0. 0. 1. 1. 0. 0. 1. 0. 1. 0. 1. 1. 0. 1. 0. 1. 0. 0. 1. 0. 1. 1. 0.\n",
      " 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 1. 1.]\n",
      "---------------------------------\n",
      "-----------------\n",
      "RandomForestClassifier() being used\n",
      "train scores: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "test scores: [0. 1. 0. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 0. 0. 1. 1. 1.\n",
      " 1. 0. 0. 1. 1. 0. 1. 1. 1. 0. 0. 1. 1. 0. 1. 1. 1. 0. 0. 1. 0. 1. 1. 0.\n",
      " 0. 1. 1. 0. 1. 1. 0. 1. 0. 1. 1. 1.]\n",
      "---------------------------------\n",
      "-----------------\n",
      "DecisionTreeClassifier() being used\n",
      "train scores: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "test scores: [0. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 0. 1. 1. 0. 0. 1. 1. 0. 1. 0. 1. 0.\n",
      " 0. 0. 0. 0. 1. 0. 1. 1. 0. 0. 0. 0. 1. 1. 1. 1. 0. 0. 1. 1. 1. 1. 1. 0.\n",
      " 1. 1. 1. 0. 0. 0. 1. 1. 1. 0. 1. 0.]\n",
      "---------------------------------\n",
      "-----------------\n",
      "ExtraTreesClassifier() being used\n",
      "train scores: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "test scores: [0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 0. 1. 0. 1. 1. 1. 1.\n",
      " 1. 1. 0. 1. 1. 0. 1. 1. 1. 0. 0. 1. 0. 0. 1. 0. 0. 1. 0. 1. 1. 1. 0. 0.\n",
      " 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1.]\n",
      "---------------------------------\n",
      "-----------------\n",
      "SVC() being used\n",
      "train scores: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "test scores: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1.\n",
      " 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0.\n",
      " 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1.]\n",
      "---------------------------------\n",
      "-----------------\n",
      "SGDClassifier(random_state=2021) being used\n",
      "train scores: [1.         1.         0.49152542 1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         0.50847458 1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         0.47457627 1.         1.         0.47457627 1.\n",
      " 1.         0.47457627 1.         0.47457627 1.         1.        ]\n",
      "test scores: [1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 0. 1. 1. 1. 1. 0. 1. 1. 1. 1. 0.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0.]\n",
      "---------------------------------\n",
      "############################\n",
      "Begining train_test function\n",
      "############################\n",
      "File the data is being pulled from: ./data/eig_centrality.csv\n",
      "Data is of shape (60, 295)\n",
      "Columns with all Zeros are being removed\n",
      "-----------------\n",
      "AdaBoostClassifier() being used\n",
      "train scores: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "test scores: [1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 0. 0. 0. 1. 0. 1. 0. 0. 0. 1. 0. 0. 0.\n",
      " 0. 0. 0. 1. 1. 0. 1. 0. 0. 1. 0. 1. 0. 0. 1. 0. 1. 0. 1. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 1. 1. 1. 0. 0. 0. 1. 1.]\n",
      "---------------------------------\n",
      "-----------------\n",
      "GradientBoostingClassifier() being used\n",
      "train scores: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "test scores: [0. 1. 0. 0. 0. 1. 1. 1. 0. 1. 1. 0. 0. 1. 1. 0. 1. 0. 1. 0. 0. 0. 1. 0.\n",
      " 0. 0. 0. 1. 1. 0. 1. 0. 0. 0. 0. 1. 1. 0. 1. 0. 1. 0. 1. 1. 1. 1. 0. 0.\n",
      " 0. 0. 1. 0. 1. 0. 1. 0. 0. 1. 0. 1.]\n",
      "---------------------------------\n",
      "-----------------\n",
      "RandomForestClassifier() being used\n",
      "train scores: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "test scores: [0. 1. 0. 1. 0. 1. 0. 1. 1. 1. 1. 1. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 1. 1. 0. 1. 1. 0. 0. 1. 0. 0. 1. 0. 0. 1. 1. 0. 1. 0. 0. 1. 1. 1. 0. 0.\n",
      " 0. 0. 1. 0. 0. 0. 1. 0. 0. 1. 0. 1.]\n",
      "---------------------------------\n",
      "-----------------\n",
      "DecisionTreeClassifier() being used\n",
      "train scores: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "test scores: [1. 0. 0. 1. 1. 1. 0. 0. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0.\n",
      " 1. 0. 0. 0. 1. 0. 1. 0. 0. 1. 0. 0. 1. 0. 1. 0. 1. 0. 0. 1. 1. 1. 0. 0.\n",
      " 0. 1. 0. 0. 0. 0. 1. 0. 0. 1. 1. 0.]\n",
      "---------------------------------\n",
      "-----------------\n",
      "ExtraTreesClassifier() being used\n",
      "train scores: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "test scores: [0. 1. 1. 1. 0. 1. 0. 1. 0. 1. 1. 1. 0. 1. 1. 1. 1. 0. 1. 0. 0. 0. 1. 0.\n",
      " 0. 1. 0. 1. 1. 0. 1. 1. 0. 0. 0. 0. 1. 0. 1. 0. 1. 0. 0. 0. 1. 1. 0. 0.\n",
      " 0. 1. 1. 0. 1. 0. 1. 0. 0. 1. 0. 0.]\n",
      "---------------------------------\n",
      "-----------------\n",
      "SVC() being used\n",
      "train scores: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "test scores: [0. 1. 0. 1. 1. 1. 0. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 0. 1. 0. 0. 0. 1. 0.\n",
      " 0. 1. 0. 1. 1. 0. 1. 1. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 1. 1. 1. 0. 0.\n",
      " 0. 0. 1. 0. 1. 0. 1. 0. 0. 1. 1. 0.]\n",
      "---------------------------------\n",
      "-----------------\n",
      "SGDClassifier(random_state=2021) being used\n",
      "train scores: [1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         0.52542373 1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         0.52542373 1.         1.        ]\n",
      "test scores: [0. 1. 0. 1. 0. 1. 0. 1. 0. 1. 1. 0. 0. 1. 1. 0. 1. 0. 1. 0. 0. 0. 0. 0.\n",
      " 0. 1. 0. 0. 1. 0. 0. 1. 0. 1. 0. 1. 1. 0. 1. 0. 0. 0. 1. 1. 1. 1. 0. 0.\n",
      " 1. 1. 1. 0. 1. 0. 1. 0. 0. 0. 1. 0.]\n",
      "---------------------------------\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "source": [
    "# view results\n",
    "master_df.head(40)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                     filename                             model  \\\n",
       "0            ./data/60x61.csv              AdaBoostClassifier()   \n",
       "1            ./data/60x61.csv      GradientBoostingClassifier()   \n",
       "2            ./data/60x61.csv          RandomForestClassifier()   \n",
       "3            ./data/60x61.csv          DecisionTreeClassifier()   \n",
       "4            ./data/60x61.csv            ExtraTreesClassifier()   \n",
       "5            ./data/60x61.csv                             SVC()   \n",
       "6            ./data/60x61.csv  SGDClassifier(random_state=2021)   \n",
       "7   ./data/eig_centrality.csv              AdaBoostClassifier()   \n",
       "8   ./data/eig_centrality.csv      GradientBoostingClassifier()   \n",
       "9   ./data/eig_centrality.csv          RandomForestClassifier()   \n",
       "10  ./data/eig_centrality.csv          DecisionTreeClassifier()   \n",
       "11  ./data/eig_centrality.csv            ExtraTreesClassifier()   \n",
       "12  ./data/eig_centrality.csv                             SVC()   \n",
       "13  ./data/eig_centrality.csv  SGDClassifier(random_state=2021)   \n",
       "\n",
       "                                         train_scores  \\\n",
       "0   [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...   \n",
       "1   [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...   \n",
       "2   [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...   \n",
       "3   [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...   \n",
       "4   [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...   \n",
       "5   [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...   \n",
       "6   [1.0, 1.0, 0.492, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0...   \n",
       "7   [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...   \n",
       "8   [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...   \n",
       "9   [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...   \n",
       "10  [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...   \n",
       "11  [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...   \n",
       "12  [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...   \n",
       "13  [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...   \n",
       "\n",
       "                                          test_scores  min_test  avg_test  \\\n",
       "0   [1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, ...       0.0  0.650000   \n",
       "1   [0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, ...       0.0  0.466667   \n",
       "2   [0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, ...       0.0  0.666667   \n",
       "3   [0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, ...       0.0  0.583333   \n",
       "4   [0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...       0.0  0.733333   \n",
       "5   [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...       0.0  0.900000   \n",
       "6   [1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...       0.0  0.900000   \n",
       "7   [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, ...       0.0  0.433333   \n",
       "8   [0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, ...       0.0  0.450000   \n",
       "9   [0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, ...       0.0  0.450000   \n",
       "10  [1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, ...       0.0  0.450000   \n",
       "11  [0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, ...       0.0  0.483333   \n",
       "12  [0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, ...       0.0  0.500000   \n",
       "13  [0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, ...       0.0  0.450000   \n",
       "\n",
       "    max_test notes  \n",
       "0        1.0  None  \n",
       "1        1.0  None  \n",
       "2        1.0  None  \n",
       "3        1.0  None  \n",
       "4        1.0  None  \n",
       "5        1.0  None  \n",
       "6        1.0  None  \n",
       "7        1.0  None  \n",
       "8        1.0  None  \n",
       "9        1.0  None  \n",
       "10       1.0  None  \n",
       "11       1.0  None  \n",
       "12       1.0  None  \n",
       "13       1.0  None  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>model</th>\n",
       "      <th>train_scores</th>\n",
       "      <th>test_scores</th>\n",
       "      <th>min_test</th>\n",
       "      <th>avg_test</th>\n",
       "      <th>max_test</th>\n",
       "      <th>notes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>./data/60x61.csv</td>\n",
       "      <td>AdaBoostClassifier()</td>\n",
       "      <td>[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...</td>\n",
       "      <td>[1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.650000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>./data/60x61.csv</td>\n",
       "      <td>GradientBoostingClassifier()</td>\n",
       "      <td>[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...</td>\n",
       "      <td>[0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>./data/60x61.csv</td>\n",
       "      <td>RandomForestClassifier()</td>\n",
       "      <td>[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...</td>\n",
       "      <td>[0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>./data/60x61.csv</td>\n",
       "      <td>DecisionTreeClassifier()</td>\n",
       "      <td>[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...</td>\n",
       "      <td>[0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>./data/60x61.csv</td>\n",
       "      <td>ExtraTreesClassifier()</td>\n",
       "      <td>[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...</td>\n",
       "      <td>[0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>./data/60x61.csv</td>\n",
       "      <td>SVC()</td>\n",
       "      <td>[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...</td>\n",
       "      <td>[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>./data/60x61.csv</td>\n",
       "      <td>SGDClassifier(random_state=2021)</td>\n",
       "      <td>[1.0, 1.0, 0.492, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0...</td>\n",
       "      <td>[1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>./data/eig_centrality.csv</td>\n",
       "      <td>AdaBoostClassifier()</td>\n",
       "      <td>[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...</td>\n",
       "      <td>[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.433333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>./data/eig_centrality.csv</td>\n",
       "      <td>GradientBoostingClassifier()</td>\n",
       "      <td>[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...</td>\n",
       "      <td>[0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.450000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>./data/eig_centrality.csv</td>\n",
       "      <td>RandomForestClassifier()</td>\n",
       "      <td>[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...</td>\n",
       "      <td>[0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.450000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>./data/eig_centrality.csv</td>\n",
       "      <td>DecisionTreeClassifier()</td>\n",
       "      <td>[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...</td>\n",
       "      <td>[1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.450000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>./data/eig_centrality.csv</td>\n",
       "      <td>ExtraTreesClassifier()</td>\n",
       "      <td>[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...</td>\n",
       "      <td>[0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.483333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>./data/eig_centrality.csv</td>\n",
       "      <td>SVC()</td>\n",
       "      <td>[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...</td>\n",
       "      <td>[0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>./data/eig_centrality.csv</td>\n",
       "      <td>SGDClassifier(random_state=2021)</td>\n",
       "      <td>[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...</td>\n",
       "      <td>[0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.450000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 149
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "source": [
    "# Sort values by average test value\n",
    "master_df.sort_values(by=['avg_test'],axis=0, ascending=False)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                     filename                             model  \\\n",
       "5            ./data/60x61.csv                             SVC()   \n",
       "6            ./data/60x61.csv  SGDClassifier(random_state=2021)   \n",
       "4            ./data/60x61.csv            ExtraTreesClassifier()   \n",
       "2            ./data/60x61.csv          RandomForestClassifier()   \n",
       "0            ./data/60x61.csv              AdaBoostClassifier()   \n",
       "3            ./data/60x61.csv          DecisionTreeClassifier()   \n",
       "12  ./data/eig_centrality.csv                             SVC()   \n",
       "11  ./data/eig_centrality.csv            ExtraTreesClassifier()   \n",
       "1            ./data/60x61.csv      GradientBoostingClassifier()   \n",
       "8   ./data/eig_centrality.csv      GradientBoostingClassifier()   \n",
       "9   ./data/eig_centrality.csv          RandomForestClassifier()   \n",
       "10  ./data/eig_centrality.csv          DecisionTreeClassifier()   \n",
       "13  ./data/eig_centrality.csv  SGDClassifier(random_state=2021)   \n",
       "7   ./data/eig_centrality.csv              AdaBoostClassifier()   \n",
       "\n",
       "                                         train_scores  \\\n",
       "5   [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...   \n",
       "6   [1.0, 1.0, 0.492, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0...   \n",
       "4   [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...   \n",
       "2   [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...   \n",
       "0   [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...   \n",
       "3   [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...   \n",
       "12  [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...   \n",
       "11  [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...   \n",
       "1   [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...   \n",
       "8   [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...   \n",
       "9   [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...   \n",
       "10  [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...   \n",
       "13  [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...   \n",
       "7   [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...   \n",
       "\n",
       "                                          test_scores  min_test  avg_test  \\\n",
       "5   [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...       0.0  0.900000   \n",
       "6   [1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...       0.0  0.900000   \n",
       "4   [0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...       0.0  0.733333   \n",
       "2   [0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, ...       0.0  0.666667   \n",
       "0   [1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, ...       0.0  0.650000   \n",
       "3   [0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, ...       0.0  0.583333   \n",
       "12  [0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, ...       0.0  0.500000   \n",
       "11  [0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, ...       0.0  0.483333   \n",
       "1   [0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, ...       0.0  0.466667   \n",
       "8   [0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, ...       0.0  0.450000   \n",
       "9   [0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, ...       0.0  0.450000   \n",
       "10  [1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, ...       0.0  0.450000   \n",
       "13  [0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, ...       0.0  0.450000   \n",
       "7   [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, ...       0.0  0.433333   \n",
       "\n",
       "    max_test notes  \n",
       "5        1.0  None  \n",
       "6        1.0  None  \n",
       "4        1.0  None  \n",
       "2        1.0  None  \n",
       "0        1.0  None  \n",
       "3        1.0  None  \n",
       "12       1.0  None  \n",
       "11       1.0  None  \n",
       "1        1.0  None  \n",
       "8        1.0  None  \n",
       "9        1.0  None  \n",
       "10       1.0  None  \n",
       "13       1.0  None  \n",
       "7        1.0  None  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>model</th>\n",
       "      <th>train_scores</th>\n",
       "      <th>test_scores</th>\n",
       "      <th>min_test</th>\n",
       "      <th>avg_test</th>\n",
       "      <th>max_test</th>\n",
       "      <th>notes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>./data/60x61.csv</td>\n",
       "      <td>SVC()</td>\n",
       "      <td>[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...</td>\n",
       "      <td>[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>./data/60x61.csv</td>\n",
       "      <td>SGDClassifier(random_state=2021)</td>\n",
       "      <td>[1.0, 1.0, 0.492, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0...</td>\n",
       "      <td>[1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>./data/60x61.csv</td>\n",
       "      <td>ExtraTreesClassifier()</td>\n",
       "      <td>[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...</td>\n",
       "      <td>[0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>./data/60x61.csv</td>\n",
       "      <td>RandomForestClassifier()</td>\n",
       "      <td>[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...</td>\n",
       "      <td>[0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>./data/60x61.csv</td>\n",
       "      <td>AdaBoostClassifier()</td>\n",
       "      <td>[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...</td>\n",
       "      <td>[1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.650000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>./data/60x61.csv</td>\n",
       "      <td>DecisionTreeClassifier()</td>\n",
       "      <td>[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...</td>\n",
       "      <td>[0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>./data/eig_centrality.csv</td>\n",
       "      <td>SVC()</td>\n",
       "      <td>[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...</td>\n",
       "      <td>[0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>./data/eig_centrality.csv</td>\n",
       "      <td>ExtraTreesClassifier()</td>\n",
       "      <td>[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...</td>\n",
       "      <td>[0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.483333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>./data/60x61.csv</td>\n",
       "      <td>GradientBoostingClassifier()</td>\n",
       "      <td>[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...</td>\n",
       "      <td>[0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>./data/eig_centrality.csv</td>\n",
       "      <td>GradientBoostingClassifier()</td>\n",
       "      <td>[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...</td>\n",
       "      <td>[0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.450000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>./data/eig_centrality.csv</td>\n",
       "      <td>RandomForestClassifier()</td>\n",
       "      <td>[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...</td>\n",
       "      <td>[0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.450000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>./data/eig_centrality.csv</td>\n",
       "      <td>DecisionTreeClassifier()</td>\n",
       "      <td>[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...</td>\n",
       "      <td>[1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.450000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>./data/eig_centrality.csv</td>\n",
       "      <td>SGDClassifier(random_state=2021)</td>\n",
       "      <td>[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...</td>\n",
       "      <td>[0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.450000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>./data/eig_centrality.csv</td>\n",
       "      <td>AdaBoostClassifier()</td>\n",
       "      <td>[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...</td>\n",
       "      <td>[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.433333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 150
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "source": [
    "# Save the results to disk\n",
    "master_df.to_csv('./all_data_files_results.csv')"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.9.6",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.6 64-bit ('base': conda)"
  },
  "interpreter": {
   "hash": "95ec9ec1504d83f612128e0fb229072f90bbb4cb09d9d5d93b5dd26e0ca2cfd1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}