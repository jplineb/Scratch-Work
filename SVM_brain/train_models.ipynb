{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Import packages"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.ensemble import AdaBoostClassifier, GradientBoostingClassifier, RandomForestClassifier, ExtraTreesClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.model_selection import KFold, cross_validate, LeaveOneOut\n",
    "import time\n",
    "import seaborn as sns"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Writing a function for our needs:\n",
    "- ~~Handle importing a single or a list of dataframes~~ Handle this with a loop that incorporates the function\n",
    "- Decide whether a dataframe needs to have the zero columns taken out\n",
    "- Possibly allow for PCA inside of the function? TBD\n",
    "- Return results to a dataframe, write them to csv\n",
    "- Allow user to specfiy notes for the runs\n",
    "- Specify models used for training\n",
    "- Cross validation will be on by default, too complicated to have both functionality\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "def train_test_models(file_name, models='ALL', crossval_method='kfold',\n",
    "                        zero_column_delete=True, absolute_value=True, notes=None, random=True, random_drop_num=5):\n",
    "    \"\"\"[summary]\n",
    "\n",
    "    Args:\n",
    "        file_name ([type]): file to use for data\n",
    "        models (str, optional): Model to be used for training and testing. Defaults to 'ALL'.\n",
    "                                If all is selected, many different types of classifiers will\n",
    "                                be used for training and testing.\n",
    "        crossval_method (str, optional): Cross validation method used for model training.\n",
    "                                         'kfold' and 'loo' are acceptable inputs.\n",
    "                                         Defaults to 'kfold'.\n",
    "        zero_column_delete (bool, optional): Gets rid of columns with all values=0. Defaults to True.\n",
    "        absolute_value (bool, optional): Takes the absolute value of every datapoint. Defaults to True.\n",
    "        notes ([type], optional): Description of the run. Defaults to None.\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"############################\")\n",
    "    print(\"Begining train_test function\")\n",
    "    print(\"############################\")\n",
    "    print(f'File the data is being pulled from: {file_name}')\n",
    "\n",
    "    # Load in the data using pandas into a dataframe\n",
    "    data_df = pd.read_csv(file_name, header=None)\n",
    "    print(f'Data is of shape {data_df.shape}')\n",
    "\n",
    "    # Delete the zero value columns if argument is provided\n",
    "    if zero_column_delete:\n",
    "        print('Columns with all Zeros are being removed')\n",
    "        data_df = data_df.loc[:, (data_df != 0).any(axis=0)]\n",
    "    \n",
    "    # Get values from dataframe \n",
    "    X = data_df.iloc[:, 1:].values\n",
    "    y = data_df.iloc[:, 0].values\n",
    "\n",
    "    # Set absolute value of X if argument is provided\n",
    "    if absolute_value:\n",
    "        X = abs(X)\n",
    "    \n",
    "    # Initialize models if 'ALL' is selected\n",
    "    if models == 'ALL':\n",
    "        models = [AdaBoostClassifier(),\n",
    "                GradientBoostingClassifier(),\n",
    "                RandomForestClassifier(), \n",
    "                DecisionTreeClassifier(),\n",
    "                ExtraTreesClassifier(),\n",
    "                svm.SVC(C=1000, gamma='auto'),\n",
    "                SGDClassifier(random_state=2021)]\n",
    "\n",
    "    ## Check to see if model is in list or not\n",
    "    elif type(models) is not list:\n",
    "        print(f'{models} is not given in list format')\n",
    "        raise\n",
    "\n",
    "    # Initialize cross validation\n",
    "    if crossval_method == 'kfold':\n",
    "        cross_val = KFold(n_splits=10,\n",
    "                          shuffle=True,\n",
    "                          random_state = 42)\n",
    "    elif crossval_method == 'loo':\n",
    "        cross_val = LeaveOneOut()\n",
    "    else:\n",
    "        print('crossval_method neither kfold or loo')\n",
    "\n",
    "    ## add random drop out\n",
    "    columns_zeroed = []\n",
    "    if random_drop_num:\n",
    "        for x in range(random_drop_num):\n",
    "            drop_col = np.random.randint(X.shape[1])\n",
    "            X[:,drop_col] = 0\n",
    "            columns_zeroed.append(drop_col)\n",
    "    \n",
    "    columns_zeroed = set(columns_zeroed)\n",
    "    columns_left = X.shape[1] - len(columns_zeroed)\n",
    "\n",
    "    # Initiailze dataframe to store results\n",
    "    results_df = pd.DataFrame([], columns = ['filename',\n",
    "                                                'model',\n",
    "                                                'train_scores',\n",
    "                                                'test_scores',\n",
    "                                                'min_test',\n",
    "                                                'avg_test',\n",
    "                                                'max_test',\n",
    "                                                'col_num_zeroed',\n",
    "                                                'len_col_num_zeroed',\n",
    "                                                'len_col_left',\n",
    "                                                'notes',\n",
    "                                                ])\n",
    "    \n",
    "    # Model training testing loop\n",
    "    for model in models:\n",
    "        print('-----------------')\n",
    "        print(f'{model} being used')\n",
    "        results = cross_validate(model, X, y, cv=cross_val, return_train_score=True)\n",
    "        train_score = results['train_score']\n",
    "        test_score = results['test_score']\n",
    "        test_min = min(test_score)\n",
    "        test_avg = np.mean(test_score)\n",
    "        test_max = max(test_score)\n",
    "        print(f'train scores: {train_score}')\n",
    "        print(f'test scores: {test_score}')\n",
    "        ## Create a dict to store results (makes dataframes easier)\n",
    "        results_dict = {'filename': file_name,\n",
    "                        'col_num_zeroed': [columns_zeroed],\n",
    "                        'len_col_num_zeroed': len(columns_zeroed),\n",
    "                        'len_col_left': columns_left,\n",
    "                        'model': str(model),\n",
    "                        'train_scores': [train_score.round(3)],\n",
    "                        'test_scores': [test_score.round(3)],\n",
    "                        'min_test': test_min,\n",
    "                        'avg_test': test_avg,\n",
    "                        'max_test': test_max,\n",
    "                        'notes': notes,\n",
    "                        }\n",
    "        temp_df = pd.DataFrame(results_dict, index=[0])\n",
    "        results_df = results_df.append(temp_df, ignore_index=True)\n",
    "        del results\n",
    "        del model\n",
    "        time.sleep(2)\n",
    "        print('---------------------------------')\n",
    "\n",
    "    return(results_df, X)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Test function"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "# test_file = './data/eig_centrality.csv'\n",
    "# results = train_test_models(test_file)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "# results"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Question about how absolute value affects results"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "# # Create a dataframe to store all results from all tests\n",
    "# master_results = pd.DataFrame(None)\n",
    "\n",
    "# # Raw data with negatives and zeros\n",
    "# notes = 'raw data, has negatives, has zeros'\n",
    "# raw_data_results = train_test_models('./data/eig_centrality.csv', zero_column_delete=False, absolute_value=False,\n",
    "#                                     notes=notes)\n",
    "\n",
    "# # Raw data with negatives and zeros taken out\n",
    "# notes = 'raw data, has negatives, zeros are removed'\n",
    "# noZeros_Negatives_data_results = train_test_models('./data/eig_centrality.csv', zero_column_delete=True, absolute_value=False,\n",
    "#                                     notes=notes)\n",
    "\n",
    "# # Raw data with no negatives and no zeros\n",
    "# notes = 'raw data, no negatives(absolute values only), zeros are removed'\n",
    "# noZeros_noNegatives_raw_data_results = train_test_models('./data/eig_centrality.csv', zero_column_delete=True, absolute_value=True,\n",
    "#                                     notes=notes)\n",
    "\n",
    "# # Elasticnet results\n",
    "# notes = 'Elasticnet Used as dimensionality reduction'\n",
    "# notes = 'Dimensionality reduction using elasticnet'\n",
    "# elastic_net_results = train_test_models('./data/60x61.csv', zero_column_delete=False, absolute_value=False,\n",
    "#                                         notes=notes)\n",
    "\n",
    "# master_results = master_results.append(raw_data_results, ignore_index=True)\n",
    "# master_results = master_results.append(noZeros_Negatives_data_results, ignore_index=True)\n",
    "# master_results = master_results.append(noZeros_noNegatives_raw_data_results, ignore_index=True)\n",
    "# master_results = master_results.append(elastic_net_results, ignore_index=True)\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "# master_results.head(15)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "# master_results.to_csv('models_results.csv',index=False)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Multiple data files\n",
    "Upload a zip file containing all your data\n",
    "You can use the unix command line interface through the jupyter notebook by using **\"!\"**"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "# unzip data folder\n",
    "'''\n",
    "Use the folder icon on the left side to open the running directory.\n",
    "You must be connected to a run time for the directory to be shown.\n",
    "before you run the following cells.\n",
    "\n",
    "CHANGE THE BELOW FILE NAME TO YOUR ZIP FILE NAME\n",
    "'''\n",
    "# !unzip ./data.zip"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'\\nUse the folder icon on the left side to open the running directory.\\nYou must be connected to a run time for the directory to be shown.\\nbefore you run the following cells.\\n\\nCHANGE THE BELOW FILE NAME TO YOUR ZIP FILE NAME\\n'"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "# use os to get files in the said directory\n",
    "'''\n",
    "MODIFY THE 'data_directory' VARIABLE TO THE PATH TO YOUR DATA\n",
    "'''\n",
    "data_directory = './variable_check' # Specify the data folder ## This is necessary ##\n",
    "data_files = [] # create an empty list object to store the file paths\n",
    "for x in os.listdir(data_directory):\n",
    "    if x.endswith('.csv'): # get only files that are csv\n",
    "        data_files.append(f'{data_directory}/{x}') # get direct path\n",
    "print(data_files)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['./variable_check/eig_centrality_65.csv', './variable_check/eig_centrality_75.csv', './variable_check/eig_centrality_10.csv', './variable_check/eig_centrality_3.csv', './variable_check/eig_centrality_160.csv', './variable_check/eig_centrality_1.csv', './variable_check/eig_centrality_166.csv', './variable_check/60x61.csv', './variable_check/eig_centrality_7.csv', './variable_check/eig_centrality_24.csv', './variable_check/eig_centrality_34.csv', './variable_check/eig_centrality_85.csv', './variable_check/eig_centrality_268.csv', './variable_check/eig_centrality_122.csv', './variable_check/eig_centrality_92.csv', './variable_check/eig_centrality_108.csv', './variable_check/eig_centrality_44.csv', './variable_check/eig_centrality.csv']\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "# loop over the files to train models and get results\n",
    "master_df = pd.DataFrame(None) # create a dataframe to store model training results\n",
    "models = [svm.SVC(C=1000, gamma='auto')]\n",
    "for data_file in data_files:\n",
    "    # Run our function uisng \"loo\" cross validation\n",
    "    # If you want kfold change the crossval_method='kfold'\n",
    "    run_results, X_used = train_test_models(data_file, models='ALL', crossval_method='loo', random_drop_num=False)\n",
    "    master_df = master_df.append(run_results, ignore_index=True)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "############################\n",
      "Begining train_test function\n",
      "############################\n",
      "File the data is being pulled from: ./variable_check/eig_centrality_65.csv\n",
      "Data is of shape (60, 66)\n",
      "Columns with all Zeros are being removed\n",
      "-----------------\n",
      "AdaBoostClassifier() being used\n",
      "train scores: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "test scores: [1. 1. 1. 0. 1. 1. 0. 1. 1. 1. 1. 0. 1. 1. 1. 0. 1. 1. 0. 0. 1. 1. 1. 0.\n",
      " 1. 0. 0. 1. 1. 0. 1. 1. 1. 0. 0. 1. 0. 0. 1. 1. 1. 0. 0. 1. 1. 1. 1. 0.\n",
      " 0. 0. 1. 0. 0. 1. 1. 1. 0. 1. 1. 1.]\n",
      "---------------------------------\n",
      "-----------------\n",
      "GradientBoostingClassifier() being used\n",
      "train scores: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "test scores: [0. 1. 1. 0. 0. 1. 1. 0. 1. 1. 1. 1. 0. 1. 1. 1. 0. 0. 1. 0. 1. 0. 1. 1.\n",
      " 0. 0. 0. 1. 1. 0. 1. 1. 0. 1. 0. 1. 1. 0. 1. 0. 1. 0. 1. 1. 1. 1. 1. 0.\n",
      " 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 1. 1.]\n",
      "---------------------------------\n",
      "-----------------\n",
      "RandomForestClassifier() being used\n",
      "train scores: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "test scores: [0. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 0. 1. 1. 1. 0.\n",
      " 1. 0. 0. 1. 1. 1. 1. 1. 1. 0. 1. 1. 0. 1. 1. 0. 1. 0. 0. 1. 1. 1. 0. 0.\n",
      " 0. 0. 1. 0. 1. 1. 1. 0. 0. 1. 1. 1.]\n",
      "---------------------------------\n",
      "-----------------\n",
      "DecisionTreeClassifier() being used\n",
      "train scores: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "test scores: [0. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 0. 1. 1. 0. 0. 1. 1. 0. 1. 0. 1. 0.\n",
      " 0. 0. 0. 1. 1. 0. 1. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 0. 0.\n",
      " 0. 1. 0. 0. 0. 0. 1. 0. 1. 0. 1. 0.]\n",
      "---------------------------------\n",
      "-----------------\n",
      "ExtraTreesClassifier() being used\n",
      "train scores: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "test scores: [0. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 0. 1. 0. 1. 1.\n",
      " 1. 1. 0. 1. 1. 0. 1. 1. 1. 0. 0. 1. 1. 1. 1. 0. 1. 0. 1. 1. 1. 1. 0. 0.\n",
      " 0. 1. 1. 0. 1. 1. 1. 0. 1. 1. 1. 1.]\n",
      "---------------------------------\n",
      "-----------------\n",
      "SVC(C=1000, gamma='auto') being used\n",
      "train scores: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "test scores: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "---------------------------------\n",
      "-----------------\n",
      "SGDClassifier(random_state=2021) being used\n",
      "train scores: [0.49152542 1.         1.         1.         1.         1.\n",
      " 1.         0.49152542 1.         1.         0.49152542 1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         0.49152542\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 0.49152542 1.         1.         1.         1.         1.\n",
      " 1.         0.47457627 1.         0.47457627 1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         0.47457627 1.\n",
      " 1.         1.         1.         0.52542373 1.         1.        ]\n",
      "test scores: [0. 1. 1. 1. 1. 1. 1. 0. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0.\n",
      " 1. 1. 0. 1. 1. 1. 0. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1.]\n",
      "---------------------------------\n",
      "############################\n",
      "Begining train_test function\n",
      "############################\n",
      "File the data is being pulled from: ./variable_check/eig_centrality_75.csv\n",
      "Data is of shape (60, 76)\n",
      "Columns with all Zeros are being removed\n",
      "-----------------\n",
      "AdaBoostClassifier() being used\n",
      "train scores: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "test scores: [1. 1. 1. 0. 1. 1. 0. 1. 1. 1. 1. 0. 0. 1. 1. 0. 0. 1. 0. 0. 1. 1. 1. 0.\n",
      " 1. 0. 0. 1. 1. 0. 1. 1. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 1. 1. 1. 1. 0.\n",
      " 0. 1. 1. 0. 0. 1. 1. 1. 0. 0. 1. 1.]\n",
      "---------------------------------\n",
      "-----------------\n",
      "GradientBoostingClassifier() being used\n",
      "train scores: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "test scores: [0. 1. 0. 1. 0. 1. 1. 0. 1. 1. 1. 1. 0. 1. 1. 1. 0. 0. 0. 0. 1. 0. 1. 1.\n",
      " 0. 0. 1. 1. 1. 0. 1. 1. 0. 1. 0. 1. 1. 0. 1. 0. 1. 0. 0. 1. 0. 1. 1. 0.\n",
      " 0. 0. 1. 0. 1. 0. 1. 0. 0. 1. 0. 1.]\n",
      "---------------------------------\n",
      "-----------------\n",
      "RandomForestClassifier() being used\n",
      "train scores: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "test scores: [0. 1. 0. 0. 1. 1. 1. 0. 1. 1. 0. 1. 1. 1. 1. 1. 1. 0. 1. 0. 1. 0. 1. 1.\n",
      " 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 0. 1. 1. 0. 1. 1. 1. 0. 0.\n",
      " 0. 1. 1. 0. 0. 1. 0. 0. 0. 1. 1. 0.]\n",
      "---------------------------------\n",
      "-----------------\n",
      "DecisionTreeClassifier() being used\n",
      "train scores: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "test scores: [0. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 0. 1. 1. 0. 0. 0. 1. 0. 1. 0. 1. 0.\n",
      " 0. 0. 0. 0. 1. 1. 1. 1. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 1. 1. 0. 1. 1. 0.\n",
      " 0. 1. 1. 0. 0. 0. 1. 1. 1. 0. 1. 0.]\n",
      "---------------------------------\n",
      "-----------------\n",
      "ExtraTreesClassifier() being used\n",
      "train scores: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "test scores: [1. 1. 1. 0. 1. 1. 0. 1. 0. 1. 1. 1. 0. 0. 1. 0. 1. 0. 1. 0. 0. 0. 1. 1.\n",
      " 1. 0. 0. 1. 1. 0. 1. 1. 0. 0. 0. 1. 0. 1. 1. 0. 0. 0. 0. 1. 1. 1. 0. 0.\n",
      " 0. 1. 1. 0. 1. 0. 0. 0. 1. 1. 1. 1.]\n",
      "---------------------------------\n",
      "-----------------\n",
      "SVC(C=1000, gamma='auto') being used\n",
      "train scores: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "test scores: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "---------------------------------\n",
      "-----------------\n",
      "SGDClassifier(random_state=2021) being used\n",
      "train scores: [1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         0.49152542 1.         1.         1.         1.\n",
      " 1.         0.49152542 1.         1.         1.         0.49152542\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         0.47457627 1.         1.         1.\n",
      " 0.47457627 0.47457627 1.         1.         0.47457627 1.\n",
      " 1.         1.         1.         0.47457627 1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         0.47457627 1.         1.        ]\n",
      "test scores: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 0. 1. 1. 1. 0.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "---------------------------------\n",
      "############################\n",
      "Begining train_test function\n",
      "############################\n",
      "File the data is being pulled from: ./variable_check/eig_centrality_10.csv\n",
      "Data is of shape (60, 11)\n",
      "Columns with all Zeros are being removed\n",
      "-----------------\n",
      "AdaBoostClassifier() being used\n",
      "train scores: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "test scores: [0. 1. 0. 0. 1. 1. 1. 0. 1. 1. 0. 1. 0. 1. 1. 1. 1. 0. 1. 0. 1. 1. 1. 0.\n",
      " 0. 0. 0. 1. 1. 0. 1. 1. 0. 0. 1. 0. 1. 0. 1. 0. 1. 0. 1. 1. 1. 0. 1. 0.\n",
      " 0. 1. 1. 0. 1. 0. 0. 1. 0. 0. 1. 1.]\n",
      "---------------------------------\n",
      "-----------------\n",
      "GradientBoostingClassifier() being used\n",
      "train scores: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "test scores: [0. 1. 0. 0. 1. 1. 0. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 0. 1. 1. 1. 0. 0. 0.\n",
      " 0. 0. 0. 1. 1. 0. 1. 1. 0. 0. 1. 1. 1. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 0.\n",
      " 0. 1. 1. 0. 0. 0. 0. 0. 0. 1. 1. 1.]\n",
      "---------------------------------\n",
      "-----------------\n",
      "RandomForestClassifier() being used\n",
      "train scores: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "test scores: [0. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 0. 1. 1. 1. 0. 1. 0.\n",
      " 1. 0. 0. 1. 1. 0. 1. 1. 1. 0. 0. 1. 1. 0. 1. 0. 1. 0. 1. 1. 1. 1. 1. 0.\n",
      " 1. 1. 1. 0. 1. 0. 1. 0. 0. 1. 1. 1.]\n",
      "---------------------------------\n",
      "-----------------\n",
      "DecisionTreeClassifier() being used\n",
      "train scores: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "test scores: [0. 1. 0. 0. 1. 1. 0. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 0. 1. 1. 0. 0. 0. 0.\n",
      " 0. 0. 0. 1. 1. 0. 1. 1. 0. 0. 0. 1. 1. 0. 1. 0. 0. 1. 1. 1. 1. 1. 1. 0.\n",
      " 0. 1. 1. 0. 0. 0. 1. 0. 0. 1. 1. 0.]\n",
      "---------------------------------\n",
      "-----------------\n",
      "ExtraTreesClassifier() being used\n",
      "train scores: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "test scores: [0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 0. 1. 0. 1. 0. 1. 0.\n",
      " 1. 0. 0. 1. 1. 0. 1. 1. 0. 1. 0. 1. 1. 0. 1. 0. 1. 0. 1. 1. 1. 1. 1. 0.\n",
      " 0. 1. 1. 0. 1. 0. 1. 1. 0. 1. 1. 1.]\n",
      "---------------------------------\n",
      "-----------------\n",
      "SVC(C=1000, gamma='auto') being used\n",
      "train scores: [0.84745763 0.84745763 0.84745763 0.84745763 0.84745763 0.84745763\n",
      " 0.84745763 0.84745763 0.84745763 0.84745763 0.84745763 0.84745763\n",
      " 0.88135593 0.84745763 0.84745763 0.84745763 0.84745763 0.84745763\n",
      " 0.84745763 0.84745763 0.84745763 0.84745763 0.83050847 0.86440678\n",
      " 0.84745763 0.86440678 0.86440678 0.84745763 0.84745763 0.84745763\n",
      " 0.84745763 0.84745763 0.84745763 0.86440678 0.83050847 0.84745763\n",
      " 0.84745763 0.84745763 0.84745763 0.86440678 0.84745763 0.84745763\n",
      " 0.84745763 0.84745763 0.84745763 0.84745763 0.83050847 0.88135593\n",
      " 0.84745763 0.84745763 0.83050847 0.86440678 0.84745763 0.88135593\n",
      " 0.84745763 0.84745763 0.84745763 0.84745763 0.84745763 0.84745763]\n",
      "test scores: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 0.\n",
      " 1. 0. 0. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 1. 1. 1. 1. 1. 0.\n",
      " 1. 1. 1. 1. 1. 0. 1. 1. 0. 1. 1. 1.]\n",
      "---------------------------------\n",
      "-----------------\n",
      "SGDClassifier(random_state=2021) being used\n",
      "train scores: [0.81355932 0.81355932 0.83050847 0.49152542 0.83050847 0.79661017\n",
      " 0.81355932 0.81355932 0.81355932 0.81355932 0.81355932 0.81355932\n",
      " 0.84745763 0.79661017 0.81355932 0.81355932 0.81355932 0.81355932\n",
      " 0.79661017 0.83050847 0.79661017 0.81355932 0.83050847 0.81355932\n",
      " 0.77966102 0.81355932 0.81355932 0.79661017 0.79661017 0.84745763\n",
      " 0.81355932 0.79661017 0.77966102 0.81355932 0.79661017 0.77966102\n",
      " 0.77966102 0.81355932 0.77966102 0.79661017 0.79661017 0.81355932\n",
      " 0.77966102 0.77966102 0.77966102 0.77966102 0.74576271 0.76271186\n",
      " 0.77966102 0.76271186 0.77966102 0.79661017 0.77966102 0.81355932\n",
      " 0.79661017 0.77966102 0.66101695 0.83050847 0.79661017 0.81355932]\n",
      "test scores: [1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0.\n",
      " 1. 1. 0. 1. 1. 0. 1. 1. 1. 0. 0. 1. 1. 0. 1. 0. 1. 0. 1. 1. 1. 1. 1. 0.\n",
      " 0. 1. 1. 0. 1. 0. 1. 1. 1. 1. 1. 1.]\n",
      "---------------------------------\n",
      "############################\n",
      "Begining train_test function\n",
      "############################\n",
      "File the data is being pulled from: ./variable_check/eig_centrality_3.csv\n",
      "Data is of shape (60, 4)\n",
      "Columns with all Zeros are being removed\n",
      "-----------------\n",
      "AdaBoostClassifier() being used\n",
      "train scores: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "test scores: [0. 1. 0. 1. 1. 1. 0. 0. 1. 1. 1. 1. 0. 0. 1. 0. 0. 0. 0. 1. 1. 1. 1. 0.\n",
      " 1. 0. 0. 1. 1. 0. 1. 1. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 1. 1. 1. 0.\n",
      " 0. 0. 1. 0. 1. 1. 1. 1. 0. 0. 1. 1.]\n",
      "---------------------------------\n",
      "-----------------\n",
      "GradientBoostingClassifier() being used\n",
      "train scores: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "test scores: [0. 1. 1. 1. 1. 1. 0. 0. 1. 1. 1. 1. 0. 0. 1. 0. 0. 0. 0. 1. 1. 1. 1. 0.\n",
      " 1. 0. 0. 1. 1. 1. 1. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 0.\n",
      " 0. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1.]\n",
      "---------------------------------\n",
      "-----------------\n",
      "RandomForestClassifier() being used\n",
      "train scores: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "test scores: [0. 1. 1. 1. 1. 1. 0. 0. 1. 1. 1. 1. 0. 1. 0. 0. 0. 0. 0. 1. 1. 0. 1. 0.\n",
      " 1. 0. 0. 1. 1. 0. 1. 1. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 1. 1. 1. 0.\n",
      " 0. 1. 1. 1. 1. 1. 1. 0. 1. 1. 0. 1.]\n",
      "---------------------------------\n",
      "-----------------\n",
      "DecisionTreeClassifier() being used\n",
      "train scores: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "test scores: [0. 1. 1. 1. 1. 1. 0. 0. 1. 1. 0. 1. 1. 0. 0. 1. 0. 0. 1. 1. 1. 1. 1. 0.\n",
      " 0. 1. 0. 1. 1. 0. 1. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 0. 0.\n",
      " 0. 1. 1. 1. 1. 0. 1. 1. 1. 1. 0. 1.]\n",
      "---------------------------------\n",
      "-----------------\n",
      "ExtraTreesClassifier() being used\n",
      "train scores: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "test scores: [0. 1. 1. 1. 1. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 1. 1. 1. 1. 1. 0.\n",
      " 1. 1. 0. 1. 1. 0. 1. 1. 0. 1. 0. 0. 1. 0. 1. 0. 1. 0. 0. 1. 1. 1. 1. 0.\n",
      " 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1.]\n",
      "---------------------------------\n",
      "-----------------\n",
      "SVC(C=1000, gamma='auto') being used\n",
      "train scores: [0.66101695 0.71186441 0.6779661  0.71186441 0.71186441 0.71186441\n",
      " 0.69491525 0.6779661  0.71186441 0.71186441 0.6779661  0.71186441\n",
      " 0.69491525 0.71186441 0.66101695 0.69491525 0.72881356 0.71186441\n",
      " 0.71186441 0.6779661  0.71186441 0.69491525 0.6779661  0.71186441\n",
      " 0.6779661  0.71186441 0.6779661  0.71186441 0.71186441 0.6779661\n",
      " 0.66101695 0.71186441 0.74576271 0.71186441 0.71186441 0.76271186\n",
      " 0.71186441 0.69491525 0.71186441 0.71186441 0.69491525 0.71186441\n",
      " 0.71186441 0.71186441 0.69491525 0.69491525 0.6779661  0.71186441\n",
      " 0.71186441 0.71186441 0.69491525 0.69491525 0.69491525 0.69491525\n",
      " 0.71186441 0.71186441 0.69491525 0.71186441 0.69491525 0.71186441]\n",
      "test scores: [1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 1. 1. 0. 1. 1. 0. 0. 0. 0. 1. 1. 0. 1. 0.\n",
      " 0. 0. 0. 1. 1. 0. 1. 1. 0. 1. 0. 0. 0. 1. 1. 0. 1. 0. 0. 1. 1. 1. 1. 0.\n",
      " 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "---------------------------------\n",
      "-----------------\n",
      "SGDClassifier(random_state=2021) being used\n",
      "train scores: [0.66101695 0.6440678  0.6440678  0.6440678  0.66101695 0.54237288\n",
      " 0.55932203 0.57627119 0.54237288 0.57627119 0.59322034 0.57627119\n",
      " 0.55932203 0.54237288 0.55932203 0.55932203 0.55932203 0.50847458\n",
      " 0.50847458 0.50847458 0.50847458 0.50847458 0.50847458 0.50847458\n",
      " 0.50847458 0.50847458 0.49152542 0.50847458 0.50847458 0.50847458\n",
      " 0.50847458 0.47457627 0.49152542 0.6440678  0.49152542 0.49152542\n",
      " 0.6440678  0.6440678  0.49152542 0.49152542 0.49152542 0.49152542\n",
      " 0.49152542 0.49152542 0.49152542 0.49152542 0.49152542 0.49152542\n",
      " 0.49152542 0.49152542 0.49152542 0.49152542 0.49152542 0.49152542\n",
      " 0.49152542 0.49152542 0.49152542 0.49152542 0.49152542 0.62711864]\n",
      "test scores: [1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 0. 1. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 0. 1. 1. 1. 1. 1. 1. 0. 1. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "---------------------------------\n",
      "############################\n",
      "Begining train_test function\n",
      "############################\n",
      "File the data is being pulled from: ./variable_check/eig_centrality_160.csv\n",
      "Data is of shape (60, 161)\n",
      "Columns with all Zeros are being removed\n",
      "-----------------\n",
      "AdaBoostClassifier() being used\n",
      "train scores: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "test scores: [1. 1. 0. 0. 1. 1. 1. 0. 1. 1. 1. 0. 0. 1. 1. 0. 1. 0. 0. 0. 1. 0. 0. 1.\n",
      " 0. 0. 0. 1. 1. 0. 1. 1. 1. 0. 0. 1. 0. 1. 1. 0. 1. 0. 0. 1. 1. 1. 1. 0.\n",
      " 1. 1. 0. 0. 0. 0. 1. 1. 0. 0. 1. 0.]\n",
      "---------------------------------\n",
      "-----------------\n",
      "GradientBoostingClassifier() being used\n",
      "train scores: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "test scores: [0. 1. 0. 0. 1. 0. 1. 1. 1. 1. 1. 1. 0. 1. 1. 0. 1. 0. 0. 0. 1. 0. 1. 1.\n",
      " 1. 0. 0. 1. 0. 0. 1. 1. 0. 1. 1. 0. 1. 0. 1. 0. 0. 1. 0. 1. 1. 0. 0. 0.\n",
      " 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 1. 1.]\n",
      "---------------------------------\n",
      "-----------------\n",
      "RandomForestClassifier() being used\n",
      "train scores: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "test scores: [0. 1. 0. 1. 1. 1. 0. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 0. 1. 0. 0. 1. 1. 0.\n",
      " 1. 1. 0. 1. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 1. 1. 1. 0. 0.\n",
      " 1. 0. 1. 0. 1. 0. 0. 0. 0. 1. 1. 0.]\n",
      "---------------------------------\n",
      "-----------------\n",
      "DecisionTreeClassifier() being used\n",
      "train scores: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "test scores: [0. 1. 1. 1. 1. 1. 0. 0. 1. 1. 1. 1. 0. 1. 1. 1. 0. 1. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 1. 0. 1. 1. 0. 1. 0. 0. 1. 0. 1. 0. 1. 0. 0. 0. 0. 1. 1. 0.\n",
      " 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 1. 0.]\n",
      "---------------------------------\n",
      "-----------------\n",
      "ExtraTreesClassifier() being used\n",
      "train scores: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "test scores: [0. 1. 0. 1. 1. 1. 0. 1. 1. 1. 1. 1. 0. 1. 1. 1. 0. 0. 1. 0. 1. 0. 1. 1.\n",
      " 1. 1. 0. 1. 1. 0. 1. 1. 0. 0. 0. 1. 1. 0. 1. 0. 1. 0. 0. 1. 1. 1. 0. 0.\n",
      " 0. 1. 1. 0. 1. 1. 0. 0. 0. 1. 1. 1.]\n",
      "---------------------------------\n",
      "-----------------\n",
      "SVC(C=1000, gamma='auto') being used\n",
      "train scores: [1.         0.98305085 1.         1.         1.         1.\n",
      " 1.         1.         0.98305085 1.         1.         1.\n",
      " 1.         0.98305085 1.         1.         1.         1.\n",
      " 1.         1.         0.98305085 1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         0.98305085 0.98305085\n",
      " 1.         0.98305085 1.         1.         0.98305085 1.        ]\n",
      "test scores: [0. 1. 1. 1. 0. 1. 0. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 0. 1. 0. 1. 1. 1. 1.\n",
      " 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 0. 1. 0. 1. 0. 1. 1. 1. 1. 1. 0.\n",
      " 1. 1. 1. 1. 1. 0. 1. 0. 1. 1. 1. 0.]\n",
      "---------------------------------\n",
      "-----------------\n",
      "SGDClassifier(random_state=2021) being used\n",
      "train scores: [1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         0.49152542 1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         0.47457627 1.\n",
      " 1.         1.         1.         1.         1.         0.47457627\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         0.94915254 1.         1.         1.\n",
      " 1.         1.         1.         0.57627119 1.         1.        ]\n",
      "test scores: [0. 1. 1. 1. 0. 1. 0. 1. 1. 1. 1. 0. 0. 1. 1. 0. 1. 0. 1. 0. 1. 0. 0. 0.\n",
      " 0. 1. 0. 1. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 0. 0.\n",
      " 1. 1. 1. 1. 1. 0. 1. 0. 1. 0. 1. 0.]\n",
      "---------------------------------\n",
      "############################\n",
      "Begining train_test function\n",
      "############################\n",
      "File the data is being pulled from: ./variable_check/eig_centrality_1.csv\n",
      "Data is of shape (60, 2)\n",
      "Columns with all Zeros are being removed\n",
      "-----------------\n",
      "AdaBoostClassifier() being used\n",
      "train scores: [0.93220339 0.89830508 0.89830508 0.89830508 0.88135593 0.88135593\n",
      " 0.89830508 0.91525424 0.89830508 0.93220339 0.89830508 0.89830508\n",
      " 0.91525424 0.93220339 0.89830508 0.89830508 0.89830508 0.93220339\n",
      " 0.91525424 0.89830508 0.88135593 0.89830508 0.88135593 0.89830508\n",
      " 0.89830508 0.91525424 0.91525424 0.89830508 0.89830508 0.89830508\n",
      " 0.91525424 0.91525424 0.91525424 0.91525424 0.89830508 0.91525424\n",
      " 0.89830508 0.91525424 0.89830508 0.91525424 0.89830508 0.93220339\n",
      " 0.89830508 0.89830508 0.93220339 0.89830508 0.91525424 0.89830508\n",
      " 0.91525424 0.89830508 0.91525424 0.89830508 0.93220339 0.91525424\n",
      " 0.89830508 0.89830508 0.91525424 0.89830508 0.89830508 0.89830508]\n",
      "test scores: [0. 1. 0. 1. 1. 1. 0. 0. 1. 0. 1. 1. 0. 0. 1. 1. 1. 0. 0. 1. 1. 0. 1. 0.\n",
      " 1. 0. 0. 1. 1. 1. 0. 0. 0. 1. 1. 0. 0. 1. 0. 0. 1. 0. 1. 1. 0. 1. 1. 1.\n",
      " 0. 0. 1. 0. 0. 1. 1. 1. 1. 0. 1. 1.]\n",
      "---------------------------------\n",
      "-----------------\n",
      "GradientBoostingClassifier() being used\n",
      "train scores: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "test scores: [0. 1. 0. 1. 1. 1. 0. 0. 1. 0. 1. 1. 0. 0. 1. 1. 1. 0. 0. 1. 1. 0. 1. 0.\n",
      " 1. 0. 0. 1. 1. 1. 0. 0. 0. 1. 1. 0. 0. 1. 0. 0. 1. 0. 1. 1. 0. 1. 1. 1.\n",
      " 0. 0. 1. 0. 0. 1. 1. 1. 1. 0. 1. 1.]\n",
      "---------------------------------\n",
      "-----------------\n",
      "RandomForestClassifier() being used\n",
      "train scores: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "test scores: [0. 1. 0. 1. 1. 1. 0. 0. 1. 0. 1. 1. 0. 0. 1. 1. 1. 0. 0. 1. 1. 0. 1. 0.\n",
      " 1. 0. 0. 1. 1. 1. 0. 0. 0. 1. 1. 0. 0. 1. 0. 0. 1. 0. 1. 1. 0. 1. 1. 1.\n",
      " 0. 0. 1. 0. 0. 1. 1. 1. 1. 0. 1. 1.]\n",
      "---------------------------------\n",
      "-----------------\n",
      "DecisionTreeClassifier() being used\n",
      "train scores: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "test scores: [0. 1. 0. 1. 1. 1. 0. 0. 1. 0. 1. 1. 0. 0. 1. 1. 1. 0. 0. 1. 1. 0. 1. 0.\n",
      " 1. 0. 0. 1. 1. 1. 0. 0. 0. 1. 1. 0. 0. 1. 0. 0. 1. 0. 1. 1. 0. 1. 1. 1.\n",
      " 0. 0. 1. 0. 0. 1. 1. 1. 1. 0. 1. 1.]\n",
      "---------------------------------\n",
      "-----------------\n",
      "ExtraTreesClassifier() being used\n",
      "train scores: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "test scores: [0. 1. 0. 1. 1. 1. 0. 0. 1. 0. 1. 1. 0. 0. 1. 1. 1. 0. 0. 1. 1. 0. 1. 0.\n",
      " 1. 0. 0. 1. 1. 1. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 1. 0. 1. 1. 0. 1. 1. 1.\n",
      " 0. 0. 1. 0. 0. 1. 1. 1. 1. 0. 1. 1.]\n",
      "---------------------------------\n",
      "-----------------\n",
      "SVC(C=1000, gamma='auto') being used\n",
      "train scores: [0.6440678  0.62711864 0.62711864 0.62711864 0.62711864 0.62711864\n",
      " 0.62711864 0.6440678  0.62711864 0.62711864 0.62711864 0.62711864\n",
      " 0.62711864 0.62711864 0.6440678  0.62711864 0.6440678  0.6440678\n",
      " 0.6440678  0.62711864 0.62711864 0.62711864 0.62711864 0.62711864\n",
      " 0.6440678  0.6440678  0.6440678  0.62711864 0.62711864 0.6440678\n",
      " 0.62711864 0.62711864 0.6440678  0.6440678  0.62711864 0.62711864\n",
      " 0.62711864 0.6440678  0.62711864 0.6440678  0.62711864 0.6440678\n",
      " 0.62711864 0.62711864 0.6440678  0.62711864 0.6440678  0.62711864\n",
      " 0.6440678  0.62711864 0.6440678  0.6440678  0.6440678  0.62711864\n",
      " 0.62711864 0.62711864 0.6440678  0.62711864 0.62711864 0.62711864]\n",
      "test scores: [0. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1.\n",
      " 0. 0. 0. 1. 1. 0. 1. 1. 0. 0. 1. 1. 1. 0. 1. 0. 1. 0. 1. 1. 0. 1. 0. 1.\n",
      " 0. 1. 0. 0. 0. 1. 1. 1. 0. 1. 1. 1.]\n",
      "---------------------------------\n",
      "-----------------\n",
      "SGDClassifier(random_state=2021) being used\n",
      "train scores: [0.50847458 0.50847458 0.50847458 0.50847458 0.50847458 0.50847458\n",
      " 0.50847458 0.50847458 0.50847458 0.49152542 0.49152542 0.49152542\n",
      " 0.50847458 0.50847458 0.50847458 0.50847458 0.50847458 0.50847458\n",
      " 0.50847458 0.49152542 0.49152542 0.49152542 0.50847458 0.49152542\n",
      " 0.49152542 0.49152542 0.49152542 0.50847458 0.50847458 0.49152542\n",
      " 0.50847458 0.47457627 0.47457627 0.47457627 0.47457627 0.47457627\n",
      " 0.47457627 0.47457627 0.47457627 0.47457627 0.47457627 0.47457627\n",
      " 0.47457627 0.47457627 0.47457627 0.47457627 0.47457627 0.47457627\n",
      " 0.47457627 0.47457627 0.47457627 0.47457627 0.47457627 0.47457627\n",
      " 0.47457627 0.47457627 0.47457627 0.47457627 0.47457627 0.47457627]\n",
      "test scores: [1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 1. 0.\n",
      " 0. 0. 0. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "---------------------------------\n",
      "############################\n",
      "Begining train_test function\n",
      "############################\n",
      "File the data is being pulled from: ./variable_check/eig_centrality_166.csv\n",
      "Data is of shape (60, 167)\n",
      "Columns with all Zeros are being removed\n",
      "-----------------\n",
      "AdaBoostClassifier() being used\n",
      "train scores: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "test scores: [0. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 0. 1. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 1. 1. 0. 1. 1. 1. 1. 0. 1. 0. 0. 1. 0. 1. 1. 0. 1. 1. 0. 0. 0.\n",
      " 0. 1. 0. 1. 1. 0. 1. 0. 0. 0. 0. 1.]\n",
      "---------------------------------\n",
      "-----------------\n",
      "GradientBoostingClassifier() being used\n",
      "train scores: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "test scores: [0. 1. 0. 1. 0. 1. 1. 1. 0. 0. 1. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 1. 0. 1. 0. 0. 1. 1. 0. 1. 0. 1. 1. 0. 1. 0. 0. 1. 0. 1. 1. 1. 0. 0.\n",
      " 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 1.]\n",
      "---------------------------------\n",
      "-----------------\n",
      "RandomForestClassifier() being used\n",
      "train scores: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "test scores: [0. 1. 0. 0. 0. 1. 0. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 0. 1. 0. 1. 1. 0. 1.\n",
      " 0. 1. 0. 1. 1. 0. 1. 1. 0. 0. 0. 0. 1. 0. 1. 0. 1. 0. 0. 1. 1. 1. 0. 0.\n",
      " 0. 0. 1. 0. 1. 0. 1. 0. 0. 1. 1. 1.]\n",
      "---------------------------------\n",
      "-----------------\n",
      "DecisionTreeClassifier() being used\n",
      "train scores: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "test scores: [0. 0. 1. 1. 1. 1. 0. 0. 1. 1. 1. 1. 0. 1. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 1. 0. 1. 1. 0. 1. 0. 0. 1. 0. 1. 0. 1. 0. 0. 1. 0. 1. 0. 0.\n",
      " 0. 0. 0. 0. 0. 1. 1. 1. 1. 0. 1. 0.]\n",
      "---------------------------------\n",
      "-----------------\n",
      "ExtraTreesClassifier() being used\n",
      "train scores: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "test scores: [0. 1. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 0. 1. 1. 0. 0. 0. 1. 0. 1. 0. 1. 1.\n",
      " 0. 1. 0. 1. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 1. 1. 1. 0. 0.\n",
      " 0. 1. 1. 1. 0. 0. 1. 0. 0. 1. 1. 1.]\n",
      "---------------------------------\n",
      "-----------------\n",
      "SVC(C=1000, gamma='auto') being used\n",
      "train scores: [1.         0.98305085 0.98305085 0.98305085 0.98305085 0.98305085\n",
      " 0.98305085 0.98305085 0.98305085 0.98305085 0.98305085 0.98305085\n",
      " 1.         0.98305085 0.98305085 0.98305085 0.98305085 0.98305085\n",
      " 0.98305085 0.98305085 0.98305085 0.98305085 0.98305085 0.98305085\n",
      " 0.98305085 0.98305085 0.98305085 0.98305085 0.98305085 0.98305085\n",
      " 0.98305085 0.98305085 0.98305085 0.98305085 0.98305085 0.98305085\n",
      " 1.         0.98305085 0.98305085 0.98305085 0.98305085 0.98305085\n",
      " 0.98305085 0.98305085 0.98305085 0.98305085 0.98305085 0.98305085\n",
      " 0.98305085 1.         0.98305085 0.98305085 0.98305085 0.98305085\n",
      " 0.98305085 0.98305085 1.         0.98305085 0.98305085 0.98305085]\n",
      "test scores: [0. 1. 1. 1. 0. 1. 0. 1. 1. 1. 1. 1. 0. 1. 1. 0. 1. 0. 1. 0. 1. 1. 1. 1.\n",
      " 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 0. 1. 1. 1. 0. 1. 1. 1. 1. 1. 0.\n",
      " 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1.]\n",
      "---------------------------------\n",
      "-----------------\n",
      "SGDClassifier(random_state=2021) being used\n",
      "train scores: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "test scores: [0. 1. 1. 1. 0. 1. 0. 1. 1. 1. 1. 0. 0. 1. 1. 1. 1. 0. 1. 0. 0. 0. 0. 0.\n",
      " 1. 1. 0. 1. 1. 0. 1. 1. 1. 1. 0. 1. 1. 0. 1. 0. 1. 0. 0. 1. 1. 1. 1. 1.\n",
      " 0. 1. 1. 1. 1. 0. 1. 0. 1. 1. 1. 0.]\n",
      "---------------------------------\n",
      "############################\n",
      "Begining train_test function\n",
      "############################\n",
      "File the data is being pulled from: ./variable_check/60x61.csv\n",
      "Data is of shape (60, 61)\n",
      "Columns with all Zeros are being removed\n",
      "-----------------\n",
      "AdaBoostClassifier() being used\n",
      "train scores: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "test scores: [1. 1. 1. 0. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 0. 0. 0. 0. 1. 1.\n",
      " 0. 0. 0. 0. 1. 1. 1. 1. 1. 0. 0. 1. 1. 0. 1. 0. 1. 0. 0. 1. 1. 0. 1. 0.\n",
      " 1. 1. 1. 1. 0. 1. 1. 1. 0. 1. 1. 1.]\n",
      "---------------------------------\n",
      "-----------------\n",
      "GradientBoostingClassifier() being used\n",
      "train scores: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "test scores: [0. 1. 0. 0. 0. 1. 0. 0. 1. 1. 0. 1. 0. 1. 1. 1. 1. 1. 1. 0. 0. 0. 1. 1.\n",
      " 0. 0. 0. 1. 1. 0. 0. 1. 0. 0. 0. 1. 1. 0. 1. 0. 1. 0. 1. 1. 1. 1. 1. 0.\n",
      " 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 1. 1.]\n",
      "---------------------------------\n",
      "-----------------\n",
      "RandomForestClassifier() being used\n",
      "train scores: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "test scores: [0. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 0. 1. 1. 0. 1. 0. 1. 0. 0. 1. 1. 1.\n",
      " 1. 1. 0. 1. 1. 0. 0. 1. 1. 0. 0. 1. 0. 0. 1. 1. 1. 0. 0. 1. 1. 1. 0. 0.\n",
      " 0. 1. 1. 0. 1. 1. 1. 1. 1. 0. 1. 1.]\n",
      "---------------------------------\n",
      "-----------------\n",
      "DecisionTreeClassifier() being used\n",
      "train scores: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "test scores: [0. 1. 1. 1. 1. 1. 0. 0. 1. 1. 1. 1. 0. 1. 1. 0. 0. 0. 1. 0. 1. 0. 1. 0.\n",
      " 0. 0. 0. 1. 1. 0. 1. 1. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 1. 1. 0. 1. 1. 0.\n",
      " 0. 1. 1. 0. 0. 0. 1. 0. 0. 0. 1. 0.]\n",
      "---------------------------------\n",
      "-----------------\n",
      "ExtraTreesClassifier() being used\n",
      "train scores: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "test scores: [0. 1. 0. 0. 1. 1. 0. 1. 0. 1. 1. 1. 0. 1. 1. 1. 1. 0. 1. 0. 1. 0. 1. 1.\n",
      " 1. 1. 0. 1. 1. 0. 1. 1. 0. 0. 0. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0.\n",
      " 0. 1. 1. 0. 1. 1. 1. 0. 1. 1. 1. 1.]\n",
      "---------------------------------\n",
      "-----------------\n",
      "SVC(C=1000, gamma='auto') being used\n",
      "train scores: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "test scores: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "---------------------------------\n",
      "-----------------\n",
      "SGDClassifier(random_state=2021) being used\n",
      "train scores: [1.         1.         0.49152542 1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         0.50847458 1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         0.47457627 1.         1.         0.47457627 1.\n",
      " 1.         0.47457627 1.         0.47457627 1.         1.        ]\n",
      "test scores: [1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 0. 1. 1. 1. 1. 0. 1. 1. 1. 1. 0.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0.]\n",
      "---------------------------------\n",
      "############################\n",
      "Begining train_test function\n",
      "############################\n",
      "File the data is being pulled from: ./variable_check/eig_centrality_7.csv\n",
      "Data is of shape (60, 8)\n",
      "Columns with all Zeros are being removed\n",
      "-----------------\n",
      "AdaBoostClassifier() being used\n",
      "train scores: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "test scores: [0. 1. 1. 1. 1. 1. 0. 1. 1. 1. 0. 1. 0. 0. 1. 0. 0. 0. 1. 0. 1. 1. 1. 0.\n",
      " 1. 0. 0. 1. 1. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 1. 1. 0. 1. 1. 0.\n",
      " 0. 1. 1. 0. 1. 0. 1. 0. 0. 1. 1. 1.]\n",
      "---------------------------------\n",
      "-----------------\n",
      "GradientBoostingClassifier() being used\n",
      "train scores: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "test scores: [0. 1. 0. 1. 1. 1. 0. 1. 1. 1. 0. 0. 0. 1. 1. 1. 1. 0. 0. 1. 1. 0. 1. 0.\n",
      " 1. 0. 0. 1. 1. 0. 1. 1. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 0.\n",
      " 0. 1. 1. 0. 1. 0. 1. 1. 0. 1. 1. 1.]\n",
      "---------------------------------\n",
      "-----------------\n",
      "RandomForestClassifier() being used\n",
      "train scores: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "test scores: [0. 1. 0. 1. 1. 1. 0. 1. 1. 1. 0. 0. 0. 0. 1. 1. 1. 0. 1. 1. 1. 1. 1. 0.\n",
      " 1. 0. 0. 1. 1. 0. 1. 1. 0. 0. 0. 0. 1. 0. 1. 0. 1. 0. 1. 1. 1. 1. 1. 0.\n",
      " 0. 1. 1. 0. 1. 0. 1. 1. 1. 1. 1. 1.]\n",
      "---------------------------------\n",
      "-----------------\n",
      "DecisionTreeClassifier() being used\n",
      "train scores: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "test scores: [0. 1. 1. 1. 1. 1. 0. 1. 1. 1. 0. 1. 0. 1. 0. 1. 1. 0. 1. 1. 0. 0. 1. 1.\n",
      " 1. 1. 0. 1. 0. 0. 1. 1. 0. 0. 0. 1. 1. 0. 1. 1. 0. 0. 0. 1. 1. 1. 1. 0.\n",
      " 0. 1. 1. 0. 1. 1. 1. 1. 0. 1. 0. 1.]\n",
      "---------------------------------\n",
      "-----------------\n",
      "ExtraTreesClassifier() being used\n",
      "train scores: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "test scores: [0. 1. 0. 1. 1. 1. 1. 1. 1. 1. 0. 1. 0. 1. 1. 1. 1. 0. 1. 0. 1. 1. 1. 0.\n",
      " 1. 0. 0. 1. 1. 0. 1. 1. 0. 0. 0. 0. 1. 0. 1. 0. 1. 0. 1. 1. 1. 1. 1. 0.\n",
      " 0. 1. 1. 0. 1. 0. 1. 1. 1. 1. 1. 1.]\n",
      "---------------------------------\n",
      "-----------------\n",
      "SVC(C=1000, gamma='auto') being used\n",
      "train scores: [0.81355932 0.81355932 0.79661017 0.81355932 0.81355932 0.81355932\n",
      " 0.81355932 0.81355932 0.81355932 0.81355932 0.81355932 0.79661017\n",
      " 0.83050847 0.81355932 0.81355932 0.81355932 0.83050847 0.83050847\n",
      " 0.79661017 0.83050847 0.81355932 0.79661017 0.81355932 0.81355932\n",
      " 0.81355932 0.84745763 0.81355932 0.81355932 0.81355932 0.84745763\n",
      " 0.81355932 0.81355932 0.81355932 0.81355932 0.83050847 0.83050847\n",
      " 0.81355932 0.84745763 0.81355932 0.79661017 0.83050847 0.83050847\n",
      " 0.81355932 0.81355932 0.81355932 0.81355932 0.83050847 0.83050847\n",
      " 0.79661017 0.81355932 0.83050847 0.76271186 0.81355932 0.81355932\n",
      " 0.81355932 0.81355932 0.79661017 0.81355932 0.83050847 0.81355932]\n",
      "test scores: [0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 0.\n",
      " 1. 0. 0. 1. 1. 0. 1. 1. 0. 0. 0. 1. 1. 0. 1. 0. 1. 0. 1. 1. 1. 1. 0. 0.\n",
      " 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "---------------------------------\n",
      "-----------------\n",
      "SGDClassifier(random_state=2021) being used\n",
      "train scores: [0.77966102 0.57627119 0.79661017 0.76271186 0.76271186 0.77966102\n",
      " 0.83050847 0.77966102 0.81355932 0.76271186 0.86440678 0.77966102\n",
      " 0.79661017 0.76271186 0.76271186 0.79661017 0.74576271 0.77966102\n",
      " 0.72881356 0.76271186 0.76271186 0.76271186 0.76271186 0.76271186\n",
      " 0.77966102 0.74576271 0.79661017 0.76271186 0.76271186 0.79661017\n",
      " 0.76271186 0.77966102 0.74576271 0.79661017 0.77966102 0.74576271\n",
      " 0.76271186 0.76271186 0.74576271 0.76271186 0.59322034 0.77966102\n",
      " 0.76271186 0.76271186 0.76271186 0.76271186 0.76271186 0.76271186\n",
      " 0.74576271 0.76271186 0.76271186 0.74576271 0.76271186 0.76271186\n",
      " 0.74576271 0.76271186 0.49152542 0.49152542 0.49152542 0.49152542]\n",
      "test scores: [0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 0. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 0.\n",
      " 1. 1. 0. 1. 1. 0. 1. 1. 0. 0. 0. 1. 1. 0. 1. 0. 1. 0. 1. 1. 1. 1. 1. 0.\n",
      " 0. 1. 1. 0. 1. 0. 1. 1. 1. 1. 1. 1.]\n",
      "---------------------------------\n",
      "############################\n",
      "Begining train_test function\n",
      "############################\n",
      "File the data is being pulled from: ./variable_check/eig_centrality_24.csv\n",
      "Data is of shape (60, 25)\n",
      "Columns with all Zeros are being removed\n",
      "-----------------\n",
      "AdaBoostClassifier() being used\n",
      "train scores: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "test scores: [0. 1. 1. 1. 1. 1. 0. 1. 0. 1. 1. 1. 1. 1. 1. 0. 1. 0. 1. 0. 0. 1. 1. 1.\n",
      " 1. 0. 0. 1. 1. 0. 1. 1. 0. 1. 1. 1. 0. 1. 1. 0. 0. 0. 1. 1. 1. 1. 0. 0.\n",
      " 0. 0. 1. 1. 1. 0. 1. 1. 0. 1. 0. 1.]\n",
      "---------------------------------\n",
      "-----------------\n",
      "GradientBoostingClassifier() being used\n",
      "train scores: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "test scores: [0. 1. 1. 1. 0. 1. 0. 1. 0. 1. 1. 1. 0. 1. 1. 1. 0. 1. 1. 0. 1. 0. 1. 1.\n",
      " 0. 0. 0. 1. 1. 0. 1. 1. 1. 1. 0. 1. 1. 0. 1. 0. 0. 0. 1. 1. 1. 1. 0. 0.\n",
      " 0. 1. 1. 0. 0. 0. 1. 0. 1. 1. 1. 1.]\n",
      "---------------------------------\n",
      "-----------------\n",
      "RandomForestClassifier() being used\n",
      "train scores: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "test scores: [0. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 0. 1. 1. 1. 0. 0. 1. 0. 1. 0. 1. 1.\n",
      " 1. 0. 0. 1. 1. 0. 1. 1. 1. 1. 0. 1. 0. 0. 1. 0. 0. 1. 1. 1. 1. 1. 1. 0.\n",
      " 1. 1. 1. 1. 1. 0. 1. 0. 0. 1. 1. 1.]\n",
      "---------------------------------\n",
      "-----------------\n",
      "DecisionTreeClassifier() being used\n",
      "train scores: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "test scores: [0. 1. 1. 1. 0. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 0. 1. 0. 1. 1.\n",
      " 0. 1. 0. 0. 1. 0. 1. 1. 1. 1. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 1. 1. 1. 0.\n",
      " 1. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1.]\n",
      "---------------------------------\n",
      "-----------------\n",
      "ExtraTreesClassifier() being used\n",
      "train scores: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "test scores: [0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1.\n",
      " 1. 0. 0. 1. 1. 0. 1. 1. 1. 1. 0. 1. 1. 0. 1. 1. 0. 0. 1. 1. 1. 1. 1. 0.\n",
      " 0. 1. 1. 1. 1. 0. 1. 0. 1. 1. 1. 1.]\n",
      "---------------------------------\n",
      "-----------------\n",
      "SVC(C=1000, gamma='auto') being used\n",
      "train scores: [0.98305085 0.98305085 0.98305085 0.98305085 1.         0.98305085\n",
      " 1.         0.98305085 0.98305085 0.98305085 0.98305085 0.98305085\n",
      " 0.98305085 0.98305085 0.98305085 0.98305085 0.98305085 0.98305085\n",
      " 0.98305085 0.96610169 0.98305085 0.98305085 0.98305085 0.98305085\n",
      " 0.98305085 0.98305085 1.         0.98305085 0.98305085 0.98305085\n",
      " 0.98305085 0.98305085 0.98305085 1.         1.         0.98305085\n",
      " 0.98305085 0.98305085 0.98305085 1.         1.         0.98305085\n",
      " 0.98305085 0.98305085 0.98305085 0.98305085 0.98305085 0.98305085\n",
      " 0.98305085 0.98305085 0.98305085 0.98305085 0.98305085 1.\n",
      " 0.98305085 0.98305085 1.         0.98305085 0.98305085 1.        ]\n",
      "test scores: [0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1.]\n",
      "---------------------------------\n",
      "-----------------\n",
      "SGDClassifier(random_state=2021) being used\n",
      "train scores: [0.89830508 0.89830508 0.86440678 0.89830508 0.86440678 0.84745763\n",
      " 0.91525424 0.89830508 0.79661017 0.79661017 0.88135593 0.93220339\n",
      " 0.93220339 0.94915254 0.88135593 0.86440678 0.91525424 0.83050847\n",
      " 0.89830508 0.77966102 0.93220339 0.94915254 0.76271186 0.84745763\n",
      " 0.76271186 0.91525424 0.96610169 0.88135593 0.93220339 0.91525424\n",
      " 0.88135593 0.86440678 0.72881356 0.89830508 0.84745763 0.88135593\n",
      " 0.86440678 0.98305085 0.88135593 0.89830508 0.89830508 0.91525424\n",
      " 0.86440678 0.89830508 0.89830508 0.86440678 0.89830508 0.84745763\n",
      " 0.86440678 0.86440678 0.84745763 0.94915254 0.94915254 0.72881356\n",
      " 0.72881356 0.83050847 0.83050847 0.86440678 0.91525424 0.91525424]\n",
      "test scores: [1. 1. 1. 1. 0. 1. 0. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 0. 1. 0. 1. 1. 1. 1.\n",
      " 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 0. 1. 0. 0. 1. 0. 1. 1. 0. 1. 0.\n",
      " 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1.]\n",
      "---------------------------------\n",
      "############################\n",
      "Begining train_test function\n",
      "############################\n",
      "File the data is being pulled from: ./variable_check/eig_centrality_34.csv\n",
      "Data is of shape (60, 35)\n",
      "Columns with all Zeros are being removed\n",
      "-----------------\n",
      "AdaBoostClassifier() being used\n",
      "train scores: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "test scores: [1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 0. 1. 1. 0. 1. 0. 1. 0. 0. 1. 1. 1.\n",
      " 1. 0. 0. 1. 1. 0. 1. 1. 1. 0. 0. 0. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1.\n",
      " 0. 0. 1. 1. 0. 0. 1. 0. 0. 1. 0. 1.]\n",
      "---------------------------------\n",
      "-----------------\n",
      "GradientBoostingClassifier() being used\n",
      "train scores: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "test scores: [0. 1. 1. 1. 0. 1. 1. 0. 0. 1. 1. 1. 0. 1. 1. 0. 0. 1. 1. 0. 1. 0. 1. 1.\n",
      " 0. 0. 0. 1. 1. 0. 1. 1. 0. 1. 0. 0. 1. 1. 1. 0. 1. 0. 1. 1. 1. 1. 1. 0.\n",
      " 0. 0. 1. 1. 0. 0. 1. 0. 0. 1. 1. 1.]\n",
      "---------------------------------\n",
      "-----------------\n",
      "RandomForestClassifier() being used\n",
      "train scores: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "test scores: [1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 0. 1. 0. 1. 0. 0. 1. 1. 1.\n",
      " 1. 1. 0. 1. 1. 0. 1. 1. 1. 1. 1. 0. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0.\n",
      " 1. 1. 1. 0. 1. 1. 1. 0. 0. 1. 1. 1.]\n",
      "---------------------------------\n",
      "-----------------\n",
      "DecisionTreeClassifier() being used\n",
      "train scores: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "test scores: [0. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 0. 1. 0. 1. 1. 0. 1. 0. 1. 1.\n",
      " 0. 1. 0. 1. 1. 0. 1. 1. 0. 1. 0. 0. 0. 1. 1. 0. 0. 0. 1. 1. 1. 1. 1. 0.\n",
      " 1. 1. 0. 0. 0. 1. 1. 0. 1. 1. 1. 1.]\n",
      "---------------------------------\n",
      "-----------------\n",
      "ExtraTreesClassifier() being used\n",
      "train scores: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "test scores: [0. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 0. 1. 0. 1. 1. 1. 1.\n",
      " 1. 1. 0. 1. 1. 0. 1. 1. 0. 1. 0. 0. 1. 0. 1. 0. 1. 1. 0. 1. 1. 1. 1. 0.\n",
      " 0. 1. 1. 1. 1. 0. 1. 0. 1. 1. 1. 1.]\n",
      "---------------------------------\n",
      "-----------------\n",
      "SVC(C=1000, gamma='auto') being used\n",
      "train scores: [0.98305085 0.98305085 0.98305085 0.98305085 0.98305085 0.98305085\n",
      " 0.98305085 0.98305085 0.98305085 0.98305085 0.98305085 0.98305085\n",
      " 1.         0.98305085 0.98305085 0.98305085 1.         0.98305085\n",
      " 0.98305085 0.98305085 0.98305085 1.         0.98305085 0.98305085\n",
      " 0.98305085 0.98305085 0.98305085 0.98305085 0.98305085 0.98305085\n",
      " 0.98305085 0.98305085 0.98305085 0.98305085 1.         0.98305085\n",
      " 0.98305085 0.98305085 0.98305085 1.         0.98305085 0.98305085\n",
      " 0.98305085 0.98305085 0.98305085 0.98305085 0.98305085 0.98305085\n",
      " 0.98305085 0.98305085 0.98305085 0.98305085 0.98305085 0.98305085\n",
      " 0.98305085 0.98305085 0.98305085 0.98305085 0.98305085 0.98305085]\n",
      "test scores: [1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 0. 1. 1. 1. 0. 1. 1. 1. 1. 0. 1. 1.\n",
      " 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 0.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "---------------------------------\n",
      "-----------------\n",
      "SGDClassifier(random_state=2021) being used\n",
      "train scores: [0.54237288 1.         1.         1.         0.52542373 0.96610169\n",
      " 0.54237288 0.49152542 0.49152542 0.57627119 1.         0.98305085\n",
      " 1.         1.         0.96610169 1.         1.         0.52542373\n",
      " 0.50847458 0.98305085 1.         1.         0.76271186 1.\n",
      " 1.         1.         0.98305085 1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         0.69491525 1.         1.         1.\n",
      " 1.         1.         0.54237288 1.         1.         0.98305085\n",
      " 0.94915254 0.72881356 0.47457627 1.         0.98305085 1.\n",
      " 1.         1.         0.98305085 1.         1.         1.        ]\n",
      "test scores: [0. 1. 1. 1. 0. 1. 1. 0. 0. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 0. 1. 0. 0. 1.\n",
      " 1. 1. 0. 1. 1. 0. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 0.\n",
      " 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1.]\n",
      "---------------------------------\n",
      "############################\n",
      "Begining train_test function\n",
      "############################\n",
      "File the data is being pulled from: ./variable_check/eig_centrality_85.csv\n",
      "Data is of shape (60, 86)\n",
      "Columns with all Zeros are being removed\n",
      "-----------------\n",
      "AdaBoostClassifier() being used\n",
      "train scores: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "test scores: [1. 0. 1. 0. 1. 1. 0. 1. 1. 1. 1. 0. 0. 1. 1. 0. 0. 1. 0. 0. 1. 1. 1. 0.\n",
      " 1. 0. 0. 1. 1. 0. 0. 1. 0. 1. 0. 1. 0. 0. 1. 1. 1. 0. 0. 1. 1. 1. 0. 0.\n",
      " 0. 1. 1. 0. 0. 1. 1. 0. 0. 1. 1. 0.]\n",
      "---------------------------------\n",
      "-----------------\n",
      "GradientBoostingClassifier() being used\n",
      "train scores: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "test scores: [0. 1. 0. 1. 1. 1. 1. 0. 1. 1. 1. 1. 0. 1. 1. 1. 0. 1. 1. 0. 1. 0. 1. 0.\n",
      " 0. 0. 1. 1. 1. 0. 1. 1. 0. 0. 0. 1. 1. 0. 1. 0. 1. 0. 1. 1. 0. 1. 1. 0.\n",
      " 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 1. 0.]\n",
      "---------------------------------\n",
      "-----------------\n",
      "RandomForestClassifier() being used\n",
      "train scores: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "test scores: [0. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 0. 1. 0. 1. 1. 1. 1.\n",
      " 1. 1. 0. 0. 1. 1. 0. 1. 1. 1. 0. 1. 1. 1. 1. 0. 1. 0. 0. 1. 1. 1. 0. 0.\n",
      " 0. 1. 1. 0. 1. 1. 0. 0. 0. 1. 1. 1.]\n",
      "---------------------------------\n",
      "-----------------\n",
      "DecisionTreeClassifier() being used\n",
      "train scores: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "test scores: [0. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 0. 1. 1. 0. 0. 0. 1. 0. 1. 0. 1. 0.\n",
      " 0. 0. 0. 1. 1. 0. 1. 1. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 0. 1. 1. 0.\n",
      " 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0.]\n",
      "---------------------------------\n",
      "-----------------\n",
      "ExtraTreesClassifier() being used\n",
      "train scores: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "test scores: [0. 1. 0. 0. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 0. 0. 0. 1. 1.\n",
      " 1. 1. 0. 1. 1. 0. 1. 1. 1. 1. 0. 1. 0. 0. 1. 1. 1. 0. 1. 1. 1. 1. 0. 0.\n",
      " 0. 1. 1. 0. 1. 0. 0. 0. 0. 1. 1. 1.]\n",
      "---------------------------------\n",
      "-----------------\n",
      "SVC(C=1000, gamma='auto') being used\n",
      "train scores: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "test scores: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "---------------------------------\n",
      "-----------------\n",
      "SGDClassifier(random_state=2021) being used\n",
      "train scores: [1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         0.47457627 1.         1.\n",
      " 1.         1.         1.         0.47457627 1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         0.47457627 1.         1.         1.         1.        ]\n",
      "test scores: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1.\n",
      " 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "---------------------------------\n",
      "############################\n",
      "Begining train_test function\n",
      "############################\n",
      "File the data is being pulled from: ./variable_check/eig_centrality_268.csv\n",
      "Data is of shape (60, 269)\n",
      "Columns with all Zeros are being removed\n",
      "-----------------\n",
      "AdaBoostClassifier() being used\n",
      "train scores: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "test scores: [1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 0. 0. 0. 1. 0. 1. 0. 0. 0. 1. 0. 0. 0.\n",
      " 0. 0. 0. 1. 1. 0. 1. 0. 0. 1. 0. 1. 0. 0. 1. 0. 1. 0. 1. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 1. 1. 1. 0. 0. 0. 1. 1.]\n",
      "---------------------------------\n",
      "-----------------\n",
      "GradientBoostingClassifier() being used\n",
      "train scores: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "test scores: [0. 1. 0. 0. 0. 1. 1. 1. 0. 1. 1. 0. 0. 1. 1. 0. 1. 0. 1. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 1. 1. 0. 1. 1. 0. 0. 0. 1. 1. 0. 1. 0. 1. 0. 1. 1. 1. 1. 0. 0.\n",
      " 0. 0. 1. 0. 1. 0. 1. 0. 0. 1. 0. 1.]\n",
      "---------------------------------\n",
      "-----------------\n",
      "RandomForestClassifier() being used\n",
      "train scores: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "test scores: [0. 0. 0. 1. 1. 0. 0. 1. 1. 1. 1. 0. 0. 1. 0. 0. 1. 0. 1. 0. 1. 0. 0. 0.\n",
      " 0. 1. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 1. 0. 1. 0. 0. 1. 1. 1. 0. 0.\n",
      " 0. 1. 1. 0. 1. 0. 1. 0. 0. 1. 1. 0.]\n",
      "---------------------------------\n",
      "-----------------\n",
      "DecisionTreeClassifier() being used\n",
      "train scores: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "test scores: [0. 0. 0. 1. 1. 1. 0. 1. 0. 1. 1. 1. 0. 1. 1. 1. 0. 1. 0. 0. 0. 0. 0. 0.\n",
      " 1. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 1. 1. 1. 0. 0. 1. 1. 1. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 1. 0. 1. 1. 1. 0.]\n",
      "---------------------------------\n",
      "-----------------\n",
      "ExtraTreesClassifier() being used\n",
      "train scores: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "test scores: [0. 1. 0. 1. 0. 0. 0. 1. 1. 1. 1. 0. 0. 1. 1. 0. 1. 0. 1. 0. 0. 0. 1. 1.\n",
      " 1. 1. 0. 1. 1. 0. 1. 1. 0. 0. 0. 0. 0. 1. 1. 0. 1. 0. 0. 0. 1. 1. 0. 0.\n",
      " 0. 1. 1. 1. 1. 0. 1. 0. 0. 1. 1. 0.]\n",
      "---------------------------------\n",
      "-----------------\n",
      "SVC(C=1000, gamma='auto') being used\n",
      "train scores: [0.98305085 0.98305085 0.98305085 0.98305085 0.98305085 0.98305085\n",
      " 0.98305085 0.98305085 0.98305085 0.98305085 0.98305085 0.98305085\n",
      " 1.         0.98305085 0.98305085 0.98305085 0.98305085 0.98305085\n",
      " 0.98305085 0.96610169 0.98305085 0.98305085 0.98305085 0.98305085\n",
      " 0.98305085 0.98305085 0.98305085 0.98305085 0.98305085 0.98305085\n",
      " 0.98305085 0.98305085 0.98305085 0.98305085 0.98305085 0.98305085\n",
      " 0.98305085 0.98305085 0.98305085 1.         0.98305085 0.98305085\n",
      " 0.98305085 0.98305085 0.98305085 0.98305085 0.98305085 0.98305085\n",
      " 0.98305085 0.98305085 0.98305085 0.98305085 0.98305085 0.98305085\n",
      " 0.98305085 0.98305085 0.98305085 0.98305085 0.98305085 0.98305085]\n",
      "test scores: [0. 1. 1. 1. 0. 1. 0. 1. 0. 1. 1. 0. 0. 1. 1. 0. 1. 0. 1. 0. 0. 0. 1. 0.\n",
      " 0. 1. 0. 1. 1. 0. 1. 1. 0. 0. 0. 1. 0. 0. 1. 0. 1. 0. 1. 1. 1. 1. 0. 0.\n",
      " 1. 1. 1. 1. 1. 0. 1. 0. 0. 1. 1. 0.]\n",
      "---------------------------------\n",
      "-----------------\n",
      "SGDClassifier(random_state=2021) being used\n",
      "train scores: [1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         0.52542373 1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         0.52542373 1.         1.        ]\n",
      "test scores: [0. 1. 0. 1. 0. 1. 0. 1. 0. 1. 1. 0. 0. 1. 1. 0. 1. 0. 1. 0. 0. 0. 0. 0.\n",
      " 0. 1. 0. 0. 1. 0. 0. 1. 0. 1. 0. 1. 1. 0. 1. 0. 0. 0. 1. 1. 1. 1. 0. 0.\n",
      " 1. 1. 1. 0. 1. 0. 1. 0. 0. 0. 1. 0.]\n",
      "---------------------------------\n",
      "############################\n",
      "Begining train_test function\n",
      "############################\n",
      "File the data is being pulled from: ./variable_check/eig_centrality_122.csv\n",
      "Data is of shape (60, 123)\n",
      "Columns with all Zeros are being removed\n",
      "-----------------\n",
      "AdaBoostClassifier() being used\n",
      "train scores: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "test scores: [0. 1. 1. 1. 1. 0. 0. 0. 1. 1. 1. 1. 0. 0. 1. 1. 0. 0. 1. 0. 1. 1. 0. 0.\n",
      " 0. 0. 0. 0. 1. 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 0.\n",
      " 0. 1. 1. 1. 1. 0. 1. 0. 1. 0. 1. 1.]\n",
      "---------------------------------\n",
      "-----------------\n",
      "GradientBoostingClassifier() being used\n",
      "train scores: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "test scores: [0. 1. 1. 0. 1. 1. 0. 0. 0. 1. 1. 1. 0. 1. 1. 1. 1. 0. 1. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 1. 1. 0. 1. 1. 0. 0. 0. 1. 1. 0. 1. 0. 1. 0. 0. 0. 0. 1. 1. 0.\n",
      " 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 1. 0.]\n",
      "---------------------------------\n",
      "-----------------\n",
      "RandomForestClassifier() being used\n",
      "train scores: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "test scores: [0. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 0. 1. 1. 1. 0. 0. 1. 0. 0. 1. 0. 1.\n",
      " 1. 1. 0. 1. 1. 0. 0. 0. 0. 1. 0. 1. 0. 0. 1. 0. 1. 0. 0. 0. 1. 1. 0. 0.\n",
      " 0. 1. 1. 0. 1. 1. 1. 0. 0. 1. 1. 1.]\n",
      "---------------------------------\n",
      "-----------------\n",
      "DecisionTreeClassifier() being used\n",
      "train scores: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "test scores: [0. 1. 1. 1. 1. 1. 0. 1. 0. 1. 1. 1. 0. 1. 1. 1. 0. 1. 1. 0. 1. 0. 0. 0.\n",
      " 0. 0. 0. 0. 1. 0. 1. 1. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 0.\n",
      " 1. 1. 0. 0. 0. 1. 1. 0. 1. 0. 1. 0.]\n",
      "---------------------------------\n",
      "-----------------\n",
      "ExtraTreesClassifier() being used\n",
      "train scores: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "test scores: [0. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 0. 1. 1. 0. 0. 0. 1. 0. 1. 1. 1. 1.\n",
      " 0. 1. 0. 1. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 1. 1. 0. 0.\n",
      " 0. 1. 1. 0. 1. 0. 1. 0. 1. 0. 1. 1.]\n",
      "---------------------------------\n",
      "-----------------\n",
      "SVC(C=1000, gamma='auto') being used\n",
      "train scores: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "test scores: [0. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 0. 1. 1. 0. 1. 0. 1. 0. 0. 1. 1. 1.\n",
      " 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 0. 1. 1. 0. 0. 1. 1. 1. 1. 1. 0.\n",
      " 1. 1. 1. 1. 1. 0. 1. 0. 1. 1. 1. 0.]\n",
      "---------------------------------\n",
      "-----------------\n",
      "SGDClassifier(random_state=2021) being used\n",
      "train scores: [1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         0.49152542 1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         0.47457627\n",
      " 0.52542373 1.         1.         1.         1.         1.\n",
      " 1.         0.47457627 1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.        ]\n",
      "test scores: [0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 0. 1. 0. 0. 1. 1. 1. 1. 0. 1. 1. 0. 1. 0. 1. 1. 0. 1. 1. 1. 1. 0.\n",
      " 1. 1. 1. 1. 1. 0. 1. 0. 0. 1. 1. 0.]\n",
      "---------------------------------\n",
      "############################\n",
      "Begining train_test function\n",
      "############################\n",
      "File the data is being pulled from: ./variable_check/eig_centrality_92.csv\n",
      "Data is of shape (60, 93)\n",
      "Columns with all Zeros are being removed\n",
      "-----------------\n",
      "AdaBoostClassifier() being used\n",
      "train scores: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "test scores: [1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 0. 1. 0. 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0.\n",
      " 1. 1. 0. 1. 1. 0. 1. 1. 1. 0. 0. 1. 1. 0. 0. 0. 0. 0. 1. 1. 1. 1. 0. 0.\n",
      " 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 0. 1.]\n",
      "---------------------------------\n",
      "-----------------\n",
      "GradientBoostingClassifier() being used\n",
      "train scores: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "test scores: [0. 1. 0. 1. 0. 1. 1. 0. 0. 1. 1. 1. 0. 1. 1. 0. 1. 0. 1. 0. 1. 0. 0. 0.\n",
      " 0. 0. 0. 1. 1. 0. 1. 1. 0. 0. 0. 1. 1. 0. 1. 0. 1. 0. 1. 1. 0. 1. 1. 0.\n",
      " 0. 0. 1. 0. 0. 0. 1. 1. 0. 1. 0. 1.]\n",
      "---------------------------------\n",
      "-----------------\n",
      "RandomForestClassifier() being used\n",
      "train scores: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "test scores: [0. 1. 0. 1. 1. 1. 0. 0. 1. 1. 1. 1. 0. 1. 1. 0. 0. 0. 1. 0. 1. 1. 1. 1.\n",
      " 1. 1. 0. 1. 1. 0. 1. 1. 0. 1. 0. 1. 0. 0. 1. 0. 1. 0. 0. 1. 1. 1. 0. 0.\n",
      " 1. 0. 1. 0. 1. 0. 1. 0. 0. 0. 1. 0.]\n",
      "---------------------------------\n",
      "-----------------\n",
      "DecisionTreeClassifier() being used\n",
      "train scores: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "test scores: [0. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 0. 1. 1. 0. 0. 0. 1. 0. 1. 0. 0. 0.\n",
      " 0. 0. 0. 1. 1. 0. 1. 1. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 0. 1. 1. 0.\n",
      " 0. 1. 0. 0. 0. 1. 1. 0. 0. 0. 1. 0.]\n",
      "---------------------------------\n",
      "-----------------\n",
      "ExtraTreesClassifier() being used\n",
      "train scores: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "test scores: [0. 1. 1. 1. 1. 1. 0. 1. 1. 1. 0. 1. 0. 0. 1. 1. 0. 0. 1. 0. 1. 1. 1. 1.\n",
      " 1. 1. 0. 0. 1. 1. 1. 0. 1. 0. 0. 1. 1. 0. 1. 1. 1. 0. 0. 1. 1. 1. 0. 0.\n",
      " 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 0.]\n",
      "---------------------------------\n",
      "-----------------\n",
      "SVC(C=1000, gamma='auto') being used\n",
      "train scores: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "test scores: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "---------------------------------\n",
      "-----------------\n",
      "SGDClassifier(random_state=2021) being used\n",
      "train scores: [1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         0.49152542 1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         0.47457627 1.         1.         1.         1.\n",
      " 1.         0.52542373 1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         0.52542373 1.         1.         1.         0.47457627]\n",
      "test scores: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 0. 1. 0. 1. 1. 1. 1.\n",
      " 1. 0. 0. 1. 1. 0. 0. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 0.\n",
      " 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1.]\n",
      "---------------------------------\n",
      "############################\n",
      "Begining train_test function\n",
      "############################\n",
      "File the data is being pulled from: ./variable_check/eig_centrality_108.csv\n",
      "Data is of shape (60, 109)\n",
      "Columns with all Zeros are being removed\n",
      "-----------------\n",
      "AdaBoostClassifier() being used\n",
      "train scores: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "test scores: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 1. 1. 0. 1. 1. 0. 0. 1. 0. 0. 0. 1. 1. 0. 0. 1. 1. 0. 1. 1. 1. 1. 0. 0.\n",
      " 1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 0. 1.]\n",
      "---------------------------------\n",
      "-----------------\n",
      "GradientBoostingClassifier() being used\n",
      "train scores: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "test scores: [0. 1. 0. 1. 1. 1. 1. 0. 0. 1. 1. 1. 0. 1. 1. 0. 1. 0. 1. 0. 1. 0. 0. 0.\n",
      " 0. 0. 0. 1. 1. 0. 1. 1. 0. 0. 0. 1. 1. 0. 1. 0. 1. 0. 1. 1. 0. 1. 1. 0.\n",
      " 0. 0. 1. 0. 1. 0. 1. 0. 0. 0. 0. 0.]\n",
      "---------------------------------\n",
      "-----------------\n",
      "RandomForestClassifier() being used\n",
      "train scores: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "test scores: [0. 1. 0. 1. 1. 1. 0. 1. 0. 1. 1. 1. 0. 1. 1. 1. 0. 0. 1. 0. 1. 0. 0. 0.\n",
      " 1. 1. 0. 1. 1. 0. 1. 1. 0. 1. 0. 0. 1. 0. 1. 0. 1. 0. 0. 1. 1. 1. 0. 0.\n",
      " 1. 1. 1. 0. 1. 0. 1. 0. 0. 1. 1. 0.]\n",
      "---------------------------------\n",
      "-----------------\n",
      "DecisionTreeClassifier() being used\n",
      "train scores: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "test scores: [0. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 0. 1. 1. 0. 0. 1. 1. 0. 1. 0. 0. 0.\n",
      " 0. 0. 0. 1. 1. 0. 1. 1. 0. 1. 0. 0. 0. 1. 1. 0. 0. 0. 1. 0. 0. 1. 1. 0.\n",
      " 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0.]\n",
      "---------------------------------\n",
      "-----------------\n",
      "ExtraTreesClassifier() being used\n",
      "train scores: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "test scores: [1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 0. 1. 0. 1. 0. 1. 0. 1. 1.\n",
      " 1. 1. 0. 1. 1. 0. 1. 1. 1. 1. 0. 1. 0. 0. 1. 0. 0. 0. 0. 1. 1. 1. 0. 0.\n",
      " 1. 0. 1. 0. 1. 1. 1. 0. 0. 0. 1. 0.]\n",
      "---------------------------------\n",
      "-----------------\n",
      "SVC(C=1000, gamma='auto') being used\n",
      "train scores: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "test scores: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 0. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "---------------------------------\n",
      "-----------------\n",
      "SGDClassifier(random_state=2021) being used\n",
      "train scores: [1.         1.         0.50847458 0.49152542 1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         0.49152542 1.\n",
      " 1.         1.         1.         1.         1.         0.50847458\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         0.47457627 1.         1.\n",
      " 1.         1.         1.         1.         1.         1.        ]\n",
      "test scores: [1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 1. 0. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 0. 1. 0. 1. 1. 0. 1. 1. 0. 1. 1. 1. 0. 1. 1. 1. 1. 1. 0.\n",
      " 1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 1.]\n",
      "---------------------------------\n",
      "############################\n",
      "Begining train_test function\n",
      "############################\n",
      "File the data is being pulled from: ./variable_check/eig_centrality_44.csv\n",
      "Data is of shape (60, 45)\n",
      "Columns with all Zeros are being removed\n",
      "-----------------\n",
      "AdaBoostClassifier() being used\n",
      "train scores: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "test scores: [1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1.\n",
      " 1. 0. 0. 0. 1. 0. 1. 1. 1. 0. 0. 1. 1. 0. 1. 1. 1. 0. 1. 1. 0. 1. 0. 0.\n",
      " 0. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 1.]\n",
      "---------------------------------\n",
      "-----------------\n",
      "GradientBoostingClassifier() being used\n",
      "train scores: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "test scores: [0. 0. 1. 1. 0. 1. 0. 0. 0. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 0. 1. 0. 0. 1.\n",
      " 0. 0. 0. 1. 1. 0. 1. 1. 0. 1. 0. 0. 1. 0. 1. 0. 1. 0. 0. 1. 1. 1. 0. 0.\n",
      " 0. 0. 1. 0. 1. 0. 1. 0. 0. 1. 1. 1.]\n",
      "---------------------------------\n",
      "-----------------\n",
      "RandomForestClassifier() being used\n",
      "train scores: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "test scores: [0. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 0. 1. 1. 0. 0. 0. 1. 0. 1. 1. 1. 1.\n",
      " 1. 1. 0. 0. 1. 0. 1. 1. 1. 1. 0. 1. 1. 1. 1. 0. 1. 0. 1. 1. 1. 1. 1. 0.\n",
      " 0. 0. 1. 0. 1. 0. 1. 1. 0. 1. 1. 1.]\n",
      "---------------------------------\n",
      "-----------------\n",
      "DecisionTreeClassifier() being used\n",
      "train scores: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "test scores: [0. 1. 1. 1. 1. 1. 0. 1. 0. 1. 1. 1. 0. 1. 1. 1. 0. 1. 1. 0. 1. 0. 1. 0.\n",
      " 0. 0. 0. 0. 1. 0. 1. 1. 0. 1. 0. 0. 0. 1. 1. 0. 0. 0. 1. 1. 1. 1. 0. 0.\n",
      " 1. 1. 0. 0. 0. 0. 1. 0. 1. 1. 1. 1.]\n",
      "---------------------------------\n",
      "-----------------\n",
      "ExtraTreesClassifier() being used\n",
      "train scores: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "test scores: [0. 1. 1. 1. 1. 1. 0. 1. 0. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1.\n",
      " 1. 1. 0. 1. 1. 0. 1. 1. 0. 1. 0. 0. 1. 1. 1. 1. 0. 0. 0. 1. 1. 1. 1. 0.\n",
      " 0. 1. 1. 0. 1. 0. 1. 0. 1. 1. 1. 1.]\n",
      "---------------------------------\n",
      "-----------------\n",
      "SVC(C=1000, gamma='auto') being used\n",
      "train scores: [1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         0.98305085 1.\n",
      " 1.         1.         1.         1.         1.         0.98305085\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.        ]\n",
      "test scores: [1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 0. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 0. 1. 1. 0. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "---------------------------------\n",
      "-----------------\n",
      "SGDClassifier(random_state=2021) being used\n",
      "train scores: [1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         0.50847458 1.\n",
      " 1.         0.50847458 1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         0.47457627 1.         0.49152542 1.         1.\n",
      " 1.         1.         1.         0.55932203 0.47457627 0.47457627\n",
      " 1.         0.52542373 1.         1.         0.52542373 0.52542373\n",
      " 1.         1.         1.         0.50847458 1.         1.        ]\n",
      "test scores: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 0. 1. 0. 1. 0. 1. 1. 1. 1. 1. 1.]\n",
      "---------------------------------\n",
      "############################\n",
      "Begining train_test function\n",
      "############################\n",
      "File the data is being pulled from: ./variable_check/eig_centrality.csv\n",
      "Data is of shape (60, 295)\n",
      "Columns with all Zeros are being removed\n",
      "-----------------\n",
      "AdaBoostClassifier() being used\n",
      "train scores: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "test scores: [1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 0. 0. 0. 1. 0. 1. 0. 0. 0. 1. 0. 0. 0.\n",
      " 0. 0. 0. 1. 1. 0. 1. 0. 0. 1. 0. 1. 0. 0. 1. 0. 1. 0. 1. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 1. 1. 1. 0. 0. 0. 1. 1.]\n",
      "---------------------------------\n",
      "-----------------\n",
      "GradientBoostingClassifier() being used\n",
      "train scores: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "test scores: [1. 1. 1. 0. 0. 1. 1. 1. 0. 1. 1. 0. 0. 1. 1. 0. 0. 0. 1. 0. 0. 0. 1. 0.\n",
      " 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 1. 1. 0. 1. 0. 1. 0. 1. 1. 0. 1. 0. 0.\n",
      " 1. 0. 1. 0. 1. 0. 1. 0. 0. 1. 0. 1.]\n",
      "---------------------------------\n",
      "-----------------\n",
      "RandomForestClassifier() being used\n",
      "train scores: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "test scores: [0. 1. 1. 1. 1. 1. 0. 1. 0. 1. 1. 0. 0. 1. 1. 0. 0. 0. 1. 0. 0. 1. 0. 0.\n",
      " 1. 1. 0. 0. 1. 0. 0. 1. 0. 0. 0. 1. 0. 0. 1. 0. 1. 0. 0. 1. 1. 0. 0. 0.\n",
      " 1. 1. 1. 0. 1. 1. 1. 0. 0. 1. 1. 0.]\n",
      "---------------------------------\n",
      "-----------------\n",
      "DecisionTreeClassifier() being used\n",
      "train scores: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "test scores: [0. 1. 1. 1. 1. 1. 0. 0. 0. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 1. 0. 1. 0. 0. 1. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 1. 0. 0.\n",
      " 0. 1. 0. 0. 0. 1. 1. 0. 1. 1. 1. 0.]\n",
      "---------------------------------\n",
      "-----------------\n",
      "ExtraTreesClassifier() being used\n",
      "train scores: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "test scores: [0. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 0. 0. 1. 1. 0. 1. 0. 1. 0. 0. 0. 1. 0.\n",
      " 0. 1. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 1. 1. 0. 1. 0. 0. 1. 1. 1. 0. 0.\n",
      " 0. 1. 1. 0. 1. 1. 1. 0. 0. 1. 1. 1.]\n",
      "---------------------------------\n",
      "-----------------\n",
      "SVC(C=1000, gamma='auto') being used\n",
      "train scores: [0.98305085 0.98305085 0.98305085 0.98305085 0.98305085 0.98305085\n",
      " 0.98305085 0.98305085 0.98305085 0.98305085 0.98305085 0.98305085\n",
      " 1.         0.98305085 0.98305085 0.98305085 0.98305085 0.98305085\n",
      " 0.98305085 0.96610169 0.98305085 0.98305085 0.98305085 0.98305085\n",
      " 0.98305085 0.98305085 0.98305085 0.98305085 0.98305085 0.98305085\n",
      " 0.98305085 0.98305085 0.98305085 0.98305085 0.98305085 0.98305085\n",
      " 0.98305085 0.98305085 0.98305085 1.         0.98305085 0.98305085\n",
      " 0.98305085 0.98305085 0.98305085 0.98305085 0.98305085 0.98305085\n",
      " 0.98305085 0.98305085 0.98305085 0.98305085 0.98305085 0.98305085\n",
      " 0.98305085 0.98305085 0.98305085 0.98305085 0.98305085 0.98305085]\n",
      "test scores: [0. 1. 1. 1. 0. 1. 0. 1. 0. 1. 1. 0. 0. 1. 1. 0. 1. 0. 1. 0. 0. 0. 1. 0.\n",
      " 0. 1. 0. 1. 1. 0. 1. 1. 0. 0. 0. 1. 0. 0. 1. 0. 1. 0. 1. 1. 1. 1. 0. 0.\n",
      " 1. 1. 1. 1. 1. 0. 1. 0. 0. 1. 1. 0.]\n",
      "---------------------------------\n",
      "-----------------\n",
      "SGDClassifier(random_state=2021) being used\n",
      "train scores: [1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         0.52542373 1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         0.52542373 1.         1.        ]\n",
      "test scores: [0. 1. 0. 1. 0. 1. 0. 1. 0. 1. 1. 0. 0. 1. 1. 0. 1. 0. 1. 0. 0. 0. 0. 0.\n",
      " 0. 1. 0. 0. 1. 0. 0. 1. 0. 1. 0. 1. 1. 0. 1. 0. 0. 0. 1. 1. 1. 1. 0. 0.\n",
      " 1. 1. 1. 0. 1. 0. 1. 0. 0. 0. 1. 0.]\n",
      "---------------------------------\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "# view results\n",
    "master_df.head(40)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                   filename                             model  \\\n",
       "0    ./variable_check/eig_centrality_65.csv              AdaBoostClassifier()   \n",
       "1    ./variable_check/eig_centrality_65.csv      GradientBoostingClassifier()   \n",
       "2    ./variable_check/eig_centrality_65.csv          RandomForestClassifier()   \n",
       "3    ./variable_check/eig_centrality_65.csv          DecisionTreeClassifier()   \n",
       "4    ./variable_check/eig_centrality_65.csv            ExtraTreesClassifier()   \n",
       "5    ./variable_check/eig_centrality_65.csv         SVC(C=1000, gamma='auto')   \n",
       "6    ./variable_check/eig_centrality_65.csv  SGDClassifier(random_state=2021)   \n",
       "7    ./variable_check/eig_centrality_75.csv              AdaBoostClassifier()   \n",
       "8    ./variable_check/eig_centrality_75.csv      GradientBoostingClassifier()   \n",
       "9    ./variable_check/eig_centrality_75.csv          RandomForestClassifier()   \n",
       "10   ./variable_check/eig_centrality_75.csv          DecisionTreeClassifier()   \n",
       "11   ./variable_check/eig_centrality_75.csv            ExtraTreesClassifier()   \n",
       "12   ./variable_check/eig_centrality_75.csv         SVC(C=1000, gamma='auto')   \n",
       "13   ./variable_check/eig_centrality_75.csv  SGDClassifier(random_state=2021)   \n",
       "14   ./variable_check/eig_centrality_10.csv              AdaBoostClassifier()   \n",
       "15   ./variable_check/eig_centrality_10.csv      GradientBoostingClassifier()   \n",
       "16   ./variable_check/eig_centrality_10.csv          RandomForestClassifier()   \n",
       "17   ./variable_check/eig_centrality_10.csv          DecisionTreeClassifier()   \n",
       "18   ./variable_check/eig_centrality_10.csv            ExtraTreesClassifier()   \n",
       "19   ./variable_check/eig_centrality_10.csv         SVC(C=1000, gamma='auto')   \n",
       "20   ./variable_check/eig_centrality_10.csv  SGDClassifier(random_state=2021)   \n",
       "21    ./variable_check/eig_centrality_3.csv              AdaBoostClassifier()   \n",
       "22    ./variable_check/eig_centrality_3.csv      GradientBoostingClassifier()   \n",
       "23    ./variable_check/eig_centrality_3.csv          RandomForestClassifier()   \n",
       "24    ./variable_check/eig_centrality_3.csv          DecisionTreeClassifier()   \n",
       "25    ./variable_check/eig_centrality_3.csv            ExtraTreesClassifier()   \n",
       "26    ./variable_check/eig_centrality_3.csv         SVC(C=1000, gamma='auto')   \n",
       "27    ./variable_check/eig_centrality_3.csv  SGDClassifier(random_state=2021)   \n",
       "28  ./variable_check/eig_centrality_160.csv              AdaBoostClassifier()   \n",
       "29  ./variable_check/eig_centrality_160.csv      GradientBoostingClassifier()   \n",
       "30  ./variable_check/eig_centrality_160.csv          RandomForestClassifier()   \n",
       "31  ./variable_check/eig_centrality_160.csv          DecisionTreeClassifier()   \n",
       "32  ./variable_check/eig_centrality_160.csv            ExtraTreesClassifier()   \n",
       "33  ./variable_check/eig_centrality_160.csv         SVC(C=1000, gamma='auto')   \n",
       "34  ./variable_check/eig_centrality_160.csv  SGDClassifier(random_state=2021)   \n",
       "35    ./variable_check/eig_centrality_1.csv              AdaBoostClassifier()   \n",
       "36    ./variable_check/eig_centrality_1.csv      GradientBoostingClassifier()   \n",
       "37    ./variable_check/eig_centrality_1.csv          RandomForestClassifier()   \n",
       "38    ./variable_check/eig_centrality_1.csv          DecisionTreeClassifier()   \n",
       "39    ./variable_check/eig_centrality_1.csv            ExtraTreesClassifier()   \n",
       "\n",
       "                                         train_scores  \\\n",
       "0   [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...   \n",
       "1   [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...   \n",
       "2   [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...   \n",
       "3   [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...   \n",
       "4   [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...   \n",
       "5   [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...   \n",
       "6   [0.492, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.492, 1...   \n",
       "7   [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...   \n",
       "8   [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...   \n",
       "9   [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...   \n",
       "10  [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...   \n",
       "11  [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...   \n",
       "12  [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...   \n",
       "13  [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...   \n",
       "14  [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...   \n",
       "15  [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...   \n",
       "16  [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...   \n",
       "17  [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...   \n",
       "18  [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...   \n",
       "19  [0.847, 0.847, 0.847, 0.847, 0.847, 0.847, 0.8...   \n",
       "20  [0.814, 0.814, 0.831, 0.492, 0.831, 0.797, 0.8...   \n",
       "21  [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...   \n",
       "22  [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...   \n",
       "23  [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...   \n",
       "24  [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...   \n",
       "25  [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...   \n",
       "26  [0.661, 0.712, 0.678, 0.712, 0.712, 0.712, 0.6...   \n",
       "27  [0.661, 0.644, 0.644, 0.644, 0.661, 0.542, 0.5...   \n",
       "28  [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...   \n",
       "29  [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...   \n",
       "30  [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...   \n",
       "31  [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...   \n",
       "32  [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...   \n",
       "33  [1.0, 0.983, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9...   \n",
       "34  [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...   \n",
       "35  [0.932, 0.898, 0.898, 0.898, 0.881, 0.881, 0.8...   \n",
       "36  [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...   \n",
       "37  [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...   \n",
       "38  [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...   \n",
       "39  [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...   \n",
       "\n",
       "                                          test_scores  min_test  avg_test  \\\n",
       "0   [1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, ...       0.0  0.633333   \n",
       "1   [0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, ...       0.0  0.550000   \n",
       "2   [0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, ...       0.0  0.683333   \n",
       "3   [0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, ...       0.0  0.483333   \n",
       "4   [0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, ...       0.0  0.733333   \n",
       "5   [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...       1.0  1.000000   \n",
       "6   [0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, ...       0.0  0.833333   \n",
       "7   [1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, ...       0.0  0.550000   \n",
       "8   [0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, ...       0.0  0.533333   \n",
       "9   [0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, ...       0.0  0.650000   \n",
       "10  [0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, ...       0.0  0.516667   \n",
       "11  [1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, ...       0.0  0.533333   \n",
       "12  [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...       0.0  0.983333   \n",
       "13  [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...       0.0  0.916667   \n",
       "14  [0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, ...       0.0  0.550000   \n",
       "15  [0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, ...       0.0  0.550000   \n",
       "16  [0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...       0.0  0.683333   \n",
       "17  [0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, ...       0.0  0.533333   \n",
       "18  [0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...       0.0  0.683333   \n",
       "19  [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...       0.0  0.800000   \n",
       "20  [1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...       0.0  0.766667   \n",
       "21  [0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, ...       0.0  0.516667   \n",
       "22  [0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, ...       0.0  0.600000   \n",
       "23  [0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, ...       0.0  0.550000   \n",
       "24  [0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, ...       0.0  0.566667   \n",
       "25  [0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, ...       0.0  0.683333   \n",
       "26  [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, ...       0.0  0.633333   \n",
       "27  [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, ...       0.0  0.816667   \n",
       "28  [1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, ...       0.0  0.516667   \n",
       "29  [0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, ...       0.0  0.483333   \n",
       "30  [0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, ...       0.0  0.516667   \n",
       "31  [0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, ...       0.0  0.433333   \n",
       "32  [0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, ...       0.0  0.600000   \n",
       "33  [0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, ...       0.0  0.750000   \n",
       "34  [0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, ...       0.0  0.633333   \n",
       "35  [0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, ...       0.0  0.550000   \n",
       "36  [0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, ...       0.0  0.550000   \n",
       "37  [0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, ...       0.0  0.550000   \n",
       "38  [0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, ...       0.0  0.550000   \n",
       "39  [0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, ...       0.0  0.533333   \n",
       "\n",
       "    max_test col_num_zeroed len_col_num_zeroed len_col_left notes  \n",
       "0        1.0             {}                  0           65  None  \n",
       "1        1.0             {}                  0           65  None  \n",
       "2        1.0             {}                  0           65  None  \n",
       "3        1.0             {}                  0           65  None  \n",
       "4        1.0             {}                  0           65  None  \n",
       "5        1.0             {}                  0           65  None  \n",
       "6        1.0             {}                  0           65  None  \n",
       "7        1.0             {}                  0           75  None  \n",
       "8        1.0             {}                  0           75  None  \n",
       "9        1.0             {}                  0           75  None  \n",
       "10       1.0             {}                  0           75  None  \n",
       "11       1.0             {}                  0           75  None  \n",
       "12       1.0             {}                  0           75  None  \n",
       "13       1.0             {}                  0           75  None  \n",
       "14       1.0             {}                  0           10  None  \n",
       "15       1.0             {}                  0           10  None  \n",
       "16       1.0             {}                  0           10  None  \n",
       "17       1.0             {}                  0           10  None  \n",
       "18       1.0             {}                  0           10  None  \n",
       "19       1.0             {}                  0           10  None  \n",
       "20       1.0             {}                  0           10  None  \n",
       "21       1.0             {}                  0            3  None  \n",
       "22       1.0             {}                  0            3  None  \n",
       "23       1.0             {}                  0            3  None  \n",
       "24       1.0             {}                  0            3  None  \n",
       "25       1.0             {}                  0            3  None  \n",
       "26       1.0             {}                  0            3  None  \n",
       "27       1.0             {}                  0            3  None  \n",
       "28       1.0             {}                  0          160  None  \n",
       "29       1.0             {}                  0          160  None  \n",
       "30       1.0             {}                  0          160  None  \n",
       "31       1.0             {}                  0          160  None  \n",
       "32       1.0             {}                  0          160  None  \n",
       "33       1.0             {}                  0          160  None  \n",
       "34       1.0             {}                  0          160  None  \n",
       "35       1.0             {}                  0            1  None  \n",
       "36       1.0             {}                  0            1  None  \n",
       "37       1.0             {}                  0            1  None  \n",
       "38       1.0             {}                  0            1  None  \n",
       "39       1.0             {}                  0            1  None  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>model</th>\n",
       "      <th>train_scores</th>\n",
       "      <th>test_scores</th>\n",
       "      <th>min_test</th>\n",
       "      <th>avg_test</th>\n",
       "      <th>max_test</th>\n",
       "      <th>col_num_zeroed</th>\n",
       "      <th>len_col_num_zeroed</th>\n",
       "      <th>len_col_left</th>\n",
       "      <th>notes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>./variable_check/eig_centrality_65.csv</td>\n",
       "      <td>AdaBoostClassifier()</td>\n",
       "      <td>[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...</td>\n",
       "      <td>[1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.633333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{}</td>\n",
       "      <td>0</td>\n",
       "      <td>65</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>./variable_check/eig_centrality_65.csv</td>\n",
       "      <td>GradientBoostingClassifier()</td>\n",
       "      <td>[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...</td>\n",
       "      <td>[0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{}</td>\n",
       "      <td>0</td>\n",
       "      <td>65</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>./variable_check/eig_centrality_65.csv</td>\n",
       "      <td>RandomForestClassifier()</td>\n",
       "      <td>[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...</td>\n",
       "      <td>[0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.683333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{}</td>\n",
       "      <td>0</td>\n",
       "      <td>65</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>./variable_check/eig_centrality_65.csv</td>\n",
       "      <td>DecisionTreeClassifier()</td>\n",
       "      <td>[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...</td>\n",
       "      <td>[0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.483333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{}</td>\n",
       "      <td>0</td>\n",
       "      <td>65</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>./variable_check/eig_centrality_65.csv</td>\n",
       "      <td>ExtraTreesClassifier()</td>\n",
       "      <td>[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...</td>\n",
       "      <td>[0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{}</td>\n",
       "      <td>0</td>\n",
       "      <td>65</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>./variable_check/eig_centrality_65.csv</td>\n",
       "      <td>SVC(C=1000, gamma='auto')</td>\n",
       "      <td>[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...</td>\n",
       "      <td>[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{}</td>\n",
       "      <td>0</td>\n",
       "      <td>65</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>./variable_check/eig_centrality_65.csv</td>\n",
       "      <td>SGDClassifier(random_state=2021)</td>\n",
       "      <td>[0.492, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.492, 1...</td>\n",
       "      <td>[0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{}</td>\n",
       "      <td>0</td>\n",
       "      <td>65</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>./variable_check/eig_centrality_75.csv</td>\n",
       "      <td>AdaBoostClassifier()</td>\n",
       "      <td>[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...</td>\n",
       "      <td>[1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{}</td>\n",
       "      <td>0</td>\n",
       "      <td>75</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>./variable_check/eig_centrality_75.csv</td>\n",
       "      <td>GradientBoostingClassifier()</td>\n",
       "      <td>[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...</td>\n",
       "      <td>[0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{}</td>\n",
       "      <td>0</td>\n",
       "      <td>75</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>./variable_check/eig_centrality_75.csv</td>\n",
       "      <td>RandomForestClassifier()</td>\n",
       "      <td>[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...</td>\n",
       "      <td>[0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.650000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{}</td>\n",
       "      <td>0</td>\n",
       "      <td>75</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>./variable_check/eig_centrality_75.csv</td>\n",
       "      <td>DecisionTreeClassifier()</td>\n",
       "      <td>[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...</td>\n",
       "      <td>[0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.516667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{}</td>\n",
       "      <td>0</td>\n",
       "      <td>75</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>./variable_check/eig_centrality_75.csv</td>\n",
       "      <td>ExtraTreesClassifier()</td>\n",
       "      <td>[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...</td>\n",
       "      <td>[1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{}</td>\n",
       "      <td>0</td>\n",
       "      <td>75</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>./variable_check/eig_centrality_75.csv</td>\n",
       "      <td>SVC(C=1000, gamma='auto')</td>\n",
       "      <td>[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...</td>\n",
       "      <td>[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.983333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{}</td>\n",
       "      <td>0</td>\n",
       "      <td>75</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>./variable_check/eig_centrality_75.csv</td>\n",
       "      <td>SGDClassifier(random_state=2021)</td>\n",
       "      <td>[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...</td>\n",
       "      <td>[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{}</td>\n",
       "      <td>0</td>\n",
       "      <td>75</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>./variable_check/eig_centrality_10.csv</td>\n",
       "      <td>AdaBoostClassifier()</td>\n",
       "      <td>[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...</td>\n",
       "      <td>[0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{}</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>./variable_check/eig_centrality_10.csv</td>\n",
       "      <td>GradientBoostingClassifier()</td>\n",
       "      <td>[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...</td>\n",
       "      <td>[0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{}</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>./variable_check/eig_centrality_10.csv</td>\n",
       "      <td>RandomForestClassifier()</td>\n",
       "      <td>[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...</td>\n",
       "      <td>[0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.683333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{}</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>./variable_check/eig_centrality_10.csv</td>\n",
       "      <td>DecisionTreeClassifier()</td>\n",
       "      <td>[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...</td>\n",
       "      <td>[0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{}</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>./variable_check/eig_centrality_10.csv</td>\n",
       "      <td>ExtraTreesClassifier()</td>\n",
       "      <td>[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...</td>\n",
       "      <td>[0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.683333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{}</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>./variable_check/eig_centrality_10.csv</td>\n",
       "      <td>SVC(C=1000, gamma='auto')</td>\n",
       "      <td>[0.847, 0.847, 0.847, 0.847, 0.847, 0.847, 0.8...</td>\n",
       "      <td>[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{}</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>./variable_check/eig_centrality_10.csv</td>\n",
       "      <td>SGDClassifier(random_state=2021)</td>\n",
       "      <td>[0.814, 0.814, 0.831, 0.492, 0.831, 0.797, 0.8...</td>\n",
       "      <td>[1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.766667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{}</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>./variable_check/eig_centrality_3.csv</td>\n",
       "      <td>AdaBoostClassifier()</td>\n",
       "      <td>[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...</td>\n",
       "      <td>[0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.516667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{}</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>./variable_check/eig_centrality_3.csv</td>\n",
       "      <td>GradientBoostingClassifier()</td>\n",
       "      <td>[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...</td>\n",
       "      <td>[0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{}</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>./variable_check/eig_centrality_3.csv</td>\n",
       "      <td>RandomForestClassifier()</td>\n",
       "      <td>[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...</td>\n",
       "      <td>[0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{}</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>./variable_check/eig_centrality_3.csv</td>\n",
       "      <td>DecisionTreeClassifier()</td>\n",
       "      <td>[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...</td>\n",
       "      <td>[0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.566667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{}</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>./variable_check/eig_centrality_3.csv</td>\n",
       "      <td>ExtraTreesClassifier()</td>\n",
       "      <td>[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...</td>\n",
       "      <td>[0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.683333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{}</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>./variable_check/eig_centrality_3.csv</td>\n",
       "      <td>SVC(C=1000, gamma='auto')</td>\n",
       "      <td>[0.661, 0.712, 0.678, 0.712, 0.712, 0.712, 0.6...</td>\n",
       "      <td>[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.633333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{}</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>./variable_check/eig_centrality_3.csv</td>\n",
       "      <td>SGDClassifier(random_state=2021)</td>\n",
       "      <td>[0.661, 0.644, 0.644, 0.644, 0.661, 0.542, 0.5...</td>\n",
       "      <td>[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.816667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{}</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>./variable_check/eig_centrality_160.csv</td>\n",
       "      <td>AdaBoostClassifier()</td>\n",
       "      <td>[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...</td>\n",
       "      <td>[1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.516667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{}</td>\n",
       "      <td>0</td>\n",
       "      <td>160</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>./variable_check/eig_centrality_160.csv</td>\n",
       "      <td>GradientBoostingClassifier()</td>\n",
       "      <td>[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...</td>\n",
       "      <td>[0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.483333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{}</td>\n",
       "      <td>0</td>\n",
       "      <td>160</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>./variable_check/eig_centrality_160.csv</td>\n",
       "      <td>RandomForestClassifier()</td>\n",
       "      <td>[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...</td>\n",
       "      <td>[0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.516667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{}</td>\n",
       "      <td>0</td>\n",
       "      <td>160</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>./variable_check/eig_centrality_160.csv</td>\n",
       "      <td>DecisionTreeClassifier()</td>\n",
       "      <td>[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...</td>\n",
       "      <td>[0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.433333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{}</td>\n",
       "      <td>0</td>\n",
       "      <td>160</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>./variable_check/eig_centrality_160.csv</td>\n",
       "      <td>ExtraTreesClassifier()</td>\n",
       "      <td>[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...</td>\n",
       "      <td>[0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{}</td>\n",
       "      <td>0</td>\n",
       "      <td>160</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>./variable_check/eig_centrality_160.csv</td>\n",
       "      <td>SVC(C=1000, gamma='auto')</td>\n",
       "      <td>[1.0, 0.983, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9...</td>\n",
       "      <td>[0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{}</td>\n",
       "      <td>0</td>\n",
       "      <td>160</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>./variable_check/eig_centrality_160.csv</td>\n",
       "      <td>SGDClassifier(random_state=2021)</td>\n",
       "      <td>[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...</td>\n",
       "      <td>[0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.633333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{}</td>\n",
       "      <td>0</td>\n",
       "      <td>160</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>./variable_check/eig_centrality_1.csv</td>\n",
       "      <td>AdaBoostClassifier()</td>\n",
       "      <td>[0.932, 0.898, 0.898, 0.898, 0.881, 0.881, 0.8...</td>\n",
       "      <td>[0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{}</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>./variable_check/eig_centrality_1.csv</td>\n",
       "      <td>GradientBoostingClassifier()</td>\n",
       "      <td>[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...</td>\n",
       "      <td>[0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{}</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>./variable_check/eig_centrality_1.csv</td>\n",
       "      <td>RandomForestClassifier()</td>\n",
       "      <td>[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...</td>\n",
       "      <td>[0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{}</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>./variable_check/eig_centrality_1.csv</td>\n",
       "      <td>DecisionTreeClassifier()</td>\n",
       "      <td>[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...</td>\n",
       "      <td>[0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{}</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>./variable_check/eig_centrality_1.csv</td>\n",
       "      <td>ExtraTreesClassifier()</td>\n",
       "      <td>[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...</td>\n",
       "      <td>[0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{}</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "# Sort values by average test value\n",
    "master_df.sort_values(by=['avg_test'],axis=0, ascending=False)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                    filename                         model  \\\n",
       "5     ./variable_check/eig_centrality_65.csv     SVC(C=1000, gamma='auto')   \n",
       "54                ./variable_check/60x61.csv     SVC(C=1000, gamma='auto')   \n",
       "12    ./variable_check/eig_centrality_75.csv     SVC(C=1000, gamma='auto')   \n",
       "82    ./variable_check/eig_centrality_85.csv     SVC(C=1000, gamma='auto')   \n",
       "103   ./variable_check/eig_centrality_92.csv     SVC(C=1000, gamma='auto')   \n",
       "..                                       ...                           ...   \n",
       "86   ./variable_check/eig_centrality_268.csv      RandomForestClassifier()   \n",
       "87   ./variable_check/eig_centrality_268.csv      DecisionTreeClassifier()   \n",
       "45   ./variable_check/eig_centrality_166.csv      DecisionTreeClassifier()   \n",
       "92   ./variable_check/eig_centrality_122.csv  GradientBoostingClassifier()   \n",
       "43   ./variable_check/eig_centrality_166.csv  GradientBoostingClassifier()   \n",
       "\n",
       "                                          train_scores  \\\n",
       "5    [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...   \n",
       "54   [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...   \n",
       "12   [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...   \n",
       "82   [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...   \n",
       "103  [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...   \n",
       "..                                                 ...   \n",
       "86   [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...   \n",
       "87   [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...   \n",
       "45   [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...   \n",
       "92   [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...   \n",
       "43   [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...   \n",
       "\n",
       "                                           test_scores  min_test  avg_test  \\\n",
       "5    [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...       1.0  1.000000   \n",
       "54   [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...       0.0  0.983333   \n",
       "12   [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...       0.0  0.983333   \n",
       "82   [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...       0.0  0.966667   \n",
       "103  [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...       0.0  0.966667   \n",
       "..                                                 ...       ...       ...   \n",
       "86   [0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, ...       0.0  0.416667   \n",
       "87   [0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, ...       0.0  0.416667   \n",
       "45   [0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, ...       0.0  0.416667   \n",
       "92   [0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, ...       0.0  0.416667   \n",
       "43   [0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, ...       0.0  0.383333   \n",
       "\n",
       "     max_test col_num_zeroed len_col_num_zeroed len_col_left notes  \n",
       "5         1.0             {}                  0           65  None  \n",
       "54        1.0             {}                  0           60  None  \n",
       "12        1.0             {}                  0           75  None  \n",
       "82        1.0             {}                  0           85  None  \n",
       "103       1.0             {}                  0           92  None  \n",
       "..        ...            ...                ...          ...   ...  \n",
       "86        1.0             {}                  0          268  None  \n",
       "87        1.0             {}                  0          268  None  \n",
       "45        1.0             {}                  0          166  None  \n",
       "92        1.0             {}                  0          122  None  \n",
       "43        1.0             {}                  0          166  None  \n",
       "\n",
       "[126 rows x 11 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>model</th>\n",
       "      <th>train_scores</th>\n",
       "      <th>test_scores</th>\n",
       "      <th>min_test</th>\n",
       "      <th>avg_test</th>\n",
       "      <th>max_test</th>\n",
       "      <th>col_num_zeroed</th>\n",
       "      <th>len_col_num_zeroed</th>\n",
       "      <th>len_col_left</th>\n",
       "      <th>notes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>./variable_check/eig_centrality_65.csv</td>\n",
       "      <td>SVC(C=1000, gamma='auto')</td>\n",
       "      <td>[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...</td>\n",
       "      <td>[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{}</td>\n",
       "      <td>0</td>\n",
       "      <td>65</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>./variable_check/60x61.csv</td>\n",
       "      <td>SVC(C=1000, gamma='auto')</td>\n",
       "      <td>[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...</td>\n",
       "      <td>[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.983333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{}</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>./variable_check/eig_centrality_75.csv</td>\n",
       "      <td>SVC(C=1000, gamma='auto')</td>\n",
       "      <td>[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...</td>\n",
       "      <td>[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.983333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{}</td>\n",
       "      <td>0</td>\n",
       "      <td>75</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>./variable_check/eig_centrality_85.csv</td>\n",
       "      <td>SVC(C=1000, gamma='auto')</td>\n",
       "      <td>[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...</td>\n",
       "      <td>[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{}</td>\n",
       "      <td>0</td>\n",
       "      <td>85</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>./variable_check/eig_centrality_92.csv</td>\n",
       "      <td>SVC(C=1000, gamma='auto')</td>\n",
       "      <td>[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...</td>\n",
       "      <td>[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{}</td>\n",
       "      <td>0</td>\n",
       "      <td>92</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>./variable_check/eig_centrality_268.csv</td>\n",
       "      <td>RandomForestClassifier()</td>\n",
       "      <td>[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{}</td>\n",
       "      <td>0</td>\n",
       "      <td>268</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>./variable_check/eig_centrality_268.csv</td>\n",
       "      <td>DecisionTreeClassifier()</td>\n",
       "      <td>[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{}</td>\n",
       "      <td>0</td>\n",
       "      <td>268</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>./variable_check/eig_centrality_166.csv</td>\n",
       "      <td>DecisionTreeClassifier()</td>\n",
       "      <td>[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...</td>\n",
       "      <td>[0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{}</td>\n",
       "      <td>0</td>\n",
       "      <td>166</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>./variable_check/eig_centrality_122.csv</td>\n",
       "      <td>GradientBoostingClassifier()</td>\n",
       "      <td>[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...</td>\n",
       "      <td>[0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{}</td>\n",
       "      <td>0</td>\n",
       "      <td>122</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>./variable_check/eig_centrality_166.csv</td>\n",
       "      <td>GradientBoostingClassifier()</td>\n",
       "      <td>[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...</td>\n",
       "      <td>[0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.383333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{}</td>\n",
       "      <td>0</td>\n",
       "      <td>166</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>126 rows × 11 columns</p>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "# Save the results to disk\n",
    "master_df.to_csv('./all_data_files_results.csv')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "source": [
    "# plot results as number of features\n",
    "# master_df.plot.scatter(x='len_col_left', y='avg_test', c='model', colormap='jet')\n",
    "sns.relplot(data=master_df, x='len_col_left', y='avg_test', hue='model')"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<seaborn.axisgrid.FacetGrid at 0x1643311c0>"
      ]
     },
     "metadata": {},
     "execution_count": 28
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<Figure size 574.25x360 with 1 Axes>"
      ],
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<svg height=\"352.434375pt\" version=\"1.1\" viewBox=\"0 0 543.983611 352.434375\" width=\"543.983611pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n <metadata>\n  <rdf:RDF xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\n   <cc:Work>\n    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\n    <dc:date>2021-10-28T11:31:49.342880</dc:date>\n    <dc:format>image/svg+xml</dc:format>\n    <dc:creator>\n     <cc:Agent>\n      <dc:title>Matplotlib v3.4.3, https://matplotlib.org/</dc:title>\n     </cc:Agent>\n    </dc:creator>\n   </cc:Work>\n  </rdf:RDF>\n </metadata>\n <defs>\n  <style type=\"text/css\">*{stroke-linecap:butt;stroke-linejoin:round;}</style>\n </defs>\n <g id=\"figure_1\">\n  <g id=\"patch_1\">\n   <path d=\"M 0 352.434375 \nL 543.983611 352.434375 \nL 543.983611 0 \nL 0 0 \nz\n\" style=\"fill:none;\"/>\n  </g>\n  <g id=\"axes_1\">\n   <g id=\"patch_2\">\n    <path d=\"M 43.78125 314.6 \nL 321.791111 314.6 \nL 321.791111 7.2 \nL 43.78125 7.2 \nz\n\" style=\"fill:#ffffff;\"/>\n   </g>\n   <g id=\"PathCollection_1\">\n    <defs>\n     <path d=\"M 0 3 \nC 0.795609 3 1.55874 2.683901 2.12132 2.12132 \nC 2.683901 1.55874 3 0.795609 3 -0 \nC 3 -0.795609 2.683901 -1.55874 2.12132 -2.12132 \nC 1.55874 -2.683901 0.795609 -3 0 -3 \nC -0.795609 -3 -1.55874 -2.683901 -2.12132 -2.12132 \nC -2.683901 -1.55874 -3 -0.795609 -3 0 \nC -3 0.795609 -2.683901 1.55874 -2.12132 2.12132 \nC -1.55874 2.683901 -0.795609 3 0 3 \nz\n\" id=\"C0_0_afe91af170\"/>\n    </defs>\n    <g clip-path=\"url(#pbe494d9388)\">\n     <use style=\"fill:#1f77b4;stroke:#ffffff;stroke-width:0.48;\" x=\"115.885412\" xlink:href=\"#C0_0_afe91af170\" y=\"187.334889\"/>\n    </g>\n    <g clip-path=\"url(#pbe494d9388)\">\n     <use style=\"fill:#ff7f0e;stroke:#ffffff;stroke-width:0.48;\" x=\"115.885412\" xlink:href=\"#C0_0_afe91af170\" y=\"225.099017\"/>\n    </g>\n    <g clip-path=\"url(#pbe494d9388)\">\n     <use style=\"fill:#2ca02c;stroke:#ffffff;stroke-width:0.48;\" x=\"115.885412\" xlink:href=\"#C0_0_afe91af170\" y=\"164.676413\"/>\n    </g>\n    <g clip-path=\"url(#pbe494d9388)\">\n     <use style=\"fill:#d62728;stroke:#ffffff;stroke-width:0.48;\" x=\"115.885412\" xlink:href=\"#C0_0_afe91af170\" y=\"255.310319\"/>\n    </g>\n    <g clip-path=\"url(#pbe494d9388)\">\n     <use style=\"fill:#9467bd;stroke:#ffffff;stroke-width:0.48;\" x=\"115.885412\" xlink:href=\"#C0_0_afe91af170\" y=\"142.017936\"/>\n    </g>\n    <g clip-path=\"url(#pbe494d9388)\">\n     <use style=\"fill:#8c564b;stroke:#ffffff;stroke-width:0.48;\" x=\"115.885412\" xlink:href=\"#C0_0_afe91af170\" y=\"21.172727\"/>\n    </g>\n    <g clip-path=\"url(#pbe494d9388)\">\n     <use style=\"fill:#e377c2;stroke:#ffffff;stroke-width:0.48;\" x=\"115.885412\" xlink:href=\"#C0_0_afe91af170\" y=\"96.700983\"/>\n    </g>\n    <g clip-path=\"url(#pbe494d9388)\">\n     <use style=\"fill:#1f77b4;stroke:#ffffff;stroke-width:0.48;\" x=\"125.177185\" xlink:href=\"#C0_0_afe91af170\" y=\"225.099017\"/>\n    </g>\n    <g clip-path=\"url(#pbe494d9388)\">\n     <use style=\"fill:#ff7f0e;stroke:#ffffff;stroke-width:0.48;\" x=\"125.177185\" xlink:href=\"#C0_0_afe91af170\" y=\"232.651843\"/>\n    </g>\n    <g clip-path=\"url(#pbe494d9388)\">\n     <use style=\"fill:#2ca02c;stroke:#ffffff;stroke-width:0.48;\" x=\"125.177185\" xlink:href=\"#C0_0_afe91af170\" y=\"179.782064\"/>\n    </g>\n    <g clip-path=\"url(#pbe494d9388)\">\n     <use style=\"fill:#d62728;stroke:#ffffff;stroke-width:0.48;\" x=\"125.177185\" xlink:href=\"#C0_0_afe91af170\" y=\"240.204668\"/>\n    </g>\n    <g clip-path=\"url(#pbe494d9388)\">\n     <use style=\"fill:#9467bd;stroke:#ffffff;stroke-width:0.48;\" x=\"125.177185\" xlink:href=\"#C0_0_afe91af170\" y=\"232.651843\"/>\n    </g>\n    <g clip-path=\"url(#pbe494d9388)\">\n     <use style=\"fill:#8c564b;stroke:#ffffff;stroke-width:0.48;\" x=\"125.177185\" xlink:href=\"#C0_0_afe91af170\" y=\"28.725553\"/>\n    </g>\n    <g clip-path=\"url(#pbe494d9388)\">\n     <use style=\"fill:#e377c2;stroke:#ffffff;stroke-width:0.48;\" x=\"125.177185\" xlink:href=\"#C0_0_afe91af170\" y=\"58.936855\"/>\n    </g>\n    <g clip-path=\"url(#pbe494d9388)\">\n     <use style=\"fill:#1f77b4;stroke:#ffffff;stroke-width:0.48;\" x=\"64.780658\" xlink:href=\"#C0_0_afe91af170\" y=\"225.099017\"/>\n    </g>\n    <g clip-path=\"url(#pbe494d9388)\">\n     <use style=\"fill:#ff7f0e;stroke:#ffffff;stroke-width:0.48;\" x=\"64.780658\" xlink:href=\"#C0_0_afe91af170\" y=\"225.099017\"/>\n    </g>\n    <g clip-path=\"url(#pbe494d9388)\">\n     <use style=\"fill:#2ca02c;stroke:#ffffff;stroke-width:0.48;\" x=\"64.780658\" xlink:href=\"#C0_0_afe91af170\" y=\"164.676413\"/>\n    </g>\n    <g clip-path=\"url(#pbe494d9388)\">\n     <use style=\"fill:#d62728;stroke:#ffffff;stroke-width:0.48;\" x=\"64.780658\" xlink:href=\"#C0_0_afe91af170\" y=\"232.651843\"/>\n    </g>\n    <g clip-path=\"url(#pbe494d9388)\">\n     <use style=\"fill:#9467bd;stroke:#ffffff;stroke-width:0.48;\" x=\"64.780658\" xlink:href=\"#C0_0_afe91af170\" y=\"164.676413\"/>\n    </g>\n    <g clip-path=\"url(#pbe494d9388)\">\n     <use style=\"fill:#8c564b;stroke:#ffffff;stroke-width:0.48;\" x=\"64.780658\" xlink:href=\"#C0_0_afe91af170\" y=\"111.806634\"/>\n    </g>\n    <g clip-path=\"url(#pbe494d9388)\">\n     <use style=\"fill:#e377c2;stroke:#ffffff;stroke-width:0.48;\" x=\"64.780658\" xlink:href=\"#C0_0_afe91af170\" y=\"126.912285\"/>\n    </g>\n    <g clip-path=\"url(#pbe494d9388)\">\n     <use style=\"fill:#1f77b4;stroke:#ffffff;stroke-width:0.48;\" x=\"58.276417\" xlink:href=\"#C0_0_afe91af170\" y=\"240.204668\"/>\n    </g>\n    <g clip-path=\"url(#pbe494d9388)\">\n     <use style=\"fill:#ff7f0e;stroke:#ffffff;stroke-width:0.48;\" x=\"58.276417\" xlink:href=\"#C0_0_afe91af170\" y=\"202.440541\"/>\n    </g>\n    <g clip-path=\"url(#pbe494d9388)\">\n     <use style=\"fill:#2ca02c;stroke:#ffffff;stroke-width:0.48;\" x=\"58.276417\" xlink:href=\"#C0_0_afe91af170\" y=\"225.099017\"/>\n    </g>\n    <g clip-path=\"url(#pbe494d9388)\">\n     <use style=\"fill:#d62728;stroke:#ffffff;stroke-width:0.48;\" x=\"58.276417\" xlink:href=\"#C0_0_afe91af170\" y=\"217.546192\"/>\n    </g>\n    <g clip-path=\"url(#pbe494d9388)\">\n     <use style=\"fill:#9467bd;stroke:#ffffff;stroke-width:0.48;\" x=\"58.276417\" xlink:href=\"#C0_0_afe91af170\" y=\"164.676413\"/>\n    </g>\n    <g clip-path=\"url(#pbe494d9388)\">\n     <use style=\"fill:#8c564b;stroke:#ffffff;stroke-width:0.48;\" x=\"58.276417\" xlink:href=\"#C0_0_afe91af170\" y=\"187.334889\"/>\n    </g>\n    <g clip-path=\"url(#pbe494d9388)\">\n     <use style=\"fill:#e377c2;stroke:#ffffff;stroke-width:0.48;\" x=\"58.276417\" xlink:href=\"#C0_0_afe91af170\" y=\"104.253808\"/>\n    </g>\n    <g clip-path=\"url(#pbe494d9388)\">\n     <use style=\"fill:#1f77b4;stroke:#ffffff;stroke-width:0.48;\" x=\"204.157259\" xlink:href=\"#C0_0_afe91af170\" y=\"240.204668\"/>\n    </g>\n    <g clip-path=\"url(#pbe494d9388)\">\n     <use style=\"fill:#ff7f0e;stroke:#ffffff;stroke-width:0.48;\" x=\"204.157259\" xlink:href=\"#C0_0_afe91af170\" y=\"255.310319\"/>\n    </g>\n    <g clip-path=\"url(#pbe494d9388)\">\n     <use style=\"fill:#2ca02c;stroke:#ffffff;stroke-width:0.48;\" x=\"204.157259\" xlink:href=\"#C0_0_afe91af170\" y=\"240.204668\"/>\n    </g>\n    <g clip-path=\"url(#pbe494d9388)\">\n     <use style=\"fill:#d62728;stroke:#ffffff;stroke-width:0.48;\" x=\"204.157259\" xlink:href=\"#C0_0_afe91af170\" y=\"277.968796\"/>\n    </g>\n    <g clip-path=\"url(#pbe494d9388)\">\n     <use style=\"fill:#9467bd;stroke:#ffffff;stroke-width:0.48;\" x=\"204.157259\" xlink:href=\"#C0_0_afe91af170\" y=\"202.440541\"/>\n    </g>\n    <g clip-path=\"url(#pbe494d9388)\">\n     <use style=\"fill:#8c564b;stroke:#ffffff;stroke-width:0.48;\" x=\"204.157259\" xlink:href=\"#C0_0_afe91af170\" y=\"134.465111\"/>\n    </g>\n    <g clip-path=\"url(#pbe494d9388)\">\n     <use style=\"fill:#e377c2;stroke:#ffffff;stroke-width:0.48;\" x=\"204.157259\" xlink:href=\"#C0_0_afe91af170\" y=\"187.334889\"/>\n    </g>\n    <g clip-path=\"url(#pbe494d9388)\">\n     <use style=\"fill:#1f77b4;stroke:#ffffff;stroke-width:0.48;\" x=\"56.418062\" xlink:href=\"#C0_0_afe91af170\" y=\"225.099017\"/>\n    </g>\n    <g clip-path=\"url(#pbe494d9388)\">\n     <use style=\"fill:#ff7f0e;stroke:#ffffff;stroke-width:0.48;\" x=\"56.418062\" xlink:href=\"#C0_0_afe91af170\" y=\"225.099017\"/>\n    </g>\n    <g clip-path=\"url(#pbe494d9388)\">\n     <use style=\"fill:#2ca02c;stroke:#ffffff;stroke-width:0.48;\" x=\"56.418062\" xlink:href=\"#C0_0_afe91af170\" y=\"225.099017\"/>\n    </g>\n    <g clip-path=\"url(#pbe494d9388)\">\n     <use style=\"fill:#d62728;stroke:#ffffff;stroke-width:0.48;\" x=\"56.418062\" xlink:href=\"#C0_0_afe91af170\" y=\"225.099017\"/>\n    </g>\n    <g clip-path=\"url(#pbe494d9388)\">\n     <use style=\"fill:#9467bd;stroke:#ffffff;stroke-width:0.48;\" x=\"56.418062\" xlink:href=\"#C0_0_afe91af170\" y=\"232.651843\"/>\n    </g>\n    <g clip-path=\"url(#pbe494d9388)\">\n     <use style=\"fill:#8c564b;stroke:#ffffff;stroke-width:0.48;\" x=\"56.418062\" xlink:href=\"#C0_0_afe91af170\" y=\"187.334889\"/>\n    </g>\n    <g clip-path=\"url(#pbe494d9388)\">\n     <use style=\"fill:#e377c2;stroke:#ffffff;stroke-width:0.48;\" x=\"56.418062\" xlink:href=\"#C0_0_afe91af170\" y=\"104.253808\"/>\n    </g>\n    <g clip-path=\"url(#pbe494d9388)\">\n     <use style=\"fill:#1f77b4;stroke:#ffffff;stroke-width:0.48;\" x=\"209.732324\" xlink:href=\"#C0_0_afe91af170\" y=\"240.204668\"/>\n    </g>\n    <g clip-path=\"url(#pbe494d9388)\">\n     <use style=\"fill:#ff7f0e;stroke:#ffffff;stroke-width:0.48;\" x=\"209.732324\" xlink:href=\"#C0_0_afe91af170\" y=\"300.627273\"/>\n    </g>\n    <g clip-path=\"url(#pbe494d9388)\">\n     <use style=\"fill:#2ca02c;stroke:#ffffff;stroke-width:0.48;\" x=\"209.732324\" xlink:href=\"#C0_0_afe91af170\" y=\"232.651843\"/>\n    </g>\n    <g clip-path=\"url(#pbe494d9388)\">\n     <use style=\"fill:#d62728;stroke:#ffffff;stroke-width:0.48;\" x=\"209.732324\" xlink:href=\"#C0_0_afe91af170\" y=\"285.521622\"/>\n    </g>\n    <g clip-path=\"url(#pbe494d9388)\">\n     <use style=\"fill:#9467bd;stroke:#ffffff;stroke-width:0.48;\" x=\"209.732324\" xlink:href=\"#C0_0_afe91af170\" y=\"262.863145\"/>\n    </g>\n    <g clip-path=\"url(#pbe494d9388)\">\n     <use style=\"fill:#8c564b;stroke:#ffffff;stroke-width:0.48;\" x=\"209.732324\" xlink:href=\"#C0_0_afe91af170\" y=\"119.359459\"/>\n    </g>\n    <g clip-path=\"url(#pbe494d9388)\">\n     <use style=\"fill:#e377c2;stroke:#ffffff;stroke-width:0.48;\" x=\"209.732324\" xlink:href=\"#C0_0_afe91af170\" y=\"187.334889\"/>\n    </g>\n    <g clip-path=\"url(#pbe494d9388)\">\n     <use style=\"fill:#1f77b4;stroke:#ffffff;stroke-width:0.48;\" x=\"111.239525\" xlink:href=\"#C0_0_afe91af170\" y=\"179.782064\"/>\n    </g>\n    <g clip-path=\"url(#pbe494d9388)\">\n     <use style=\"fill:#ff7f0e;stroke:#ffffff;stroke-width:0.48;\" x=\"111.239525\" xlink:href=\"#C0_0_afe91af170\" y=\"255.310319\"/>\n    </g>\n    <g clip-path=\"url(#pbe494d9388)\">\n     <use style=\"fill:#2ca02c;stroke:#ffffff;stroke-width:0.48;\" x=\"111.239525\" xlink:href=\"#C0_0_afe91af170\" y=\"179.782064\"/>\n    </g>\n    <g clip-path=\"url(#pbe494d9388)\">\n     <use style=\"fill:#d62728;stroke:#ffffff;stroke-width:0.48;\" x=\"111.239525\" xlink:href=\"#C0_0_afe91af170\" y=\"262.863145\"/>\n    </g>\n    <g clip-path=\"url(#pbe494d9388)\">\n     <use style=\"fill:#9467bd;stroke:#ffffff;stroke-width:0.48;\" x=\"111.239525\" xlink:href=\"#C0_0_afe91af170\" y=\"164.676413\"/>\n    </g>\n    <g clip-path=\"url(#pbe494d9388)\">\n     <use style=\"fill:#8c564b;stroke:#ffffff;stroke-width:0.48;\" x=\"111.239525\" xlink:href=\"#C0_0_afe91af170\" y=\"28.725553\"/>\n    </g>\n    <g clip-path=\"url(#pbe494d9388)\">\n     <use style=\"fill:#e377c2;stroke:#ffffff;stroke-width:0.48;\" x=\"111.239525\" xlink:href=\"#C0_0_afe91af170\" y=\"66.489681\"/>\n    </g>\n    <g clip-path=\"url(#pbe494d9388)\">\n     <use style=\"fill:#1f77b4;stroke:#ffffff;stroke-width:0.48;\" x=\"61.993126\" xlink:href=\"#C0_0_afe91af170\" y=\"240.204668\"/>\n    </g>\n    <g clip-path=\"url(#pbe494d9388)\">\n     <use style=\"fill:#ff7f0e;stroke:#ffffff;stroke-width:0.48;\" x=\"61.993126\" xlink:href=\"#C0_0_afe91af170\" y=\"217.546192\"/>\n    </g>\n    <g clip-path=\"url(#pbe494d9388)\">\n     <use style=\"fill:#2ca02c;stroke:#ffffff;stroke-width:0.48;\" x=\"61.993126\" xlink:href=\"#C0_0_afe91af170\" y=\"194.887715\"/>\n    </g>\n    <g clip-path=\"url(#pbe494d9388)\">\n     <use style=\"fill:#d62728;stroke:#ffffff;stroke-width:0.48;\" x=\"61.993126\" xlink:href=\"#C0_0_afe91af170\" y=\"194.887715\"/>\n    </g>\n    <g clip-path=\"url(#pbe494d9388)\">\n     <use style=\"fill:#9467bd;stroke:#ffffff;stroke-width:0.48;\" x=\"61.993126\" xlink:href=\"#C0_0_afe91af170\" y=\"179.782064\"/>\n    </g>\n    <g clip-path=\"url(#pbe494d9388)\">\n     <use style=\"fill:#8c564b;stroke:#ffffff;stroke-width:0.48;\" x=\"61.993126\" xlink:href=\"#C0_0_afe91af170\" y=\"142.017936\"/>\n    </g>\n    <g clip-path=\"url(#pbe494d9388)\">\n     <use style=\"fill:#e377c2;stroke:#ffffff;stroke-width:0.48;\" x=\"61.993126\" xlink:href=\"#C0_0_afe91af170\" y=\"149.570762\"/>\n    </g>\n    <g clip-path=\"url(#pbe494d9388)\">\n     <use style=\"fill:#1f77b4;stroke:#ffffff;stroke-width:0.48;\" x=\"77.789141\" xlink:href=\"#C0_0_afe91af170\" y=\"187.334889\"/>\n    </g>\n    <g clip-path=\"url(#pbe494d9388)\">\n     <use style=\"fill:#ff7f0e;stroke:#ffffff;stroke-width:0.48;\" x=\"77.789141\" xlink:href=\"#C0_0_afe91af170\" y=\"202.440541\"/>\n    </g>\n    <g clip-path=\"url(#pbe494d9388)\">\n     <use style=\"fill:#2ca02c;stroke:#ffffff;stroke-width:0.48;\" x=\"77.789141\" xlink:href=\"#C0_0_afe91af170\" y=\"164.676413\"/>\n    </g>\n    <g clip-path=\"url(#pbe494d9388)\">\n     <use style=\"fill:#d62728;stroke:#ffffff;stroke-width:0.48;\" x=\"77.789141\" xlink:href=\"#C0_0_afe91af170\" y=\"194.887715\"/>\n    </g>\n    <g clip-path=\"url(#pbe494d9388)\">\n     <use style=\"fill:#9467bd;stroke:#ffffff;stroke-width:0.48;\" x=\"77.789141\" xlink:href=\"#C0_0_afe91af170\" y=\"126.912285\"/>\n    </g>\n    <g clip-path=\"url(#pbe494d9388)\">\n     <use style=\"fill:#8c564b;stroke:#ffffff;stroke-width:0.48;\" x=\"77.789141\" xlink:href=\"#C0_0_afe91af170\" y=\"74.042506\"/>\n    </g>\n    <g clip-path=\"url(#pbe494d9388)\">\n     <use style=\"fill:#e377c2;stroke:#ffffff;stroke-width:0.48;\" x=\"77.789141\" xlink:href=\"#C0_0_afe91af170\" y=\"126.912285\"/>\n    </g>\n    <g clip-path=\"url(#pbe494d9388)\">\n     <use style=\"fill:#1f77b4;stroke:#ffffff;stroke-width:0.48;\" x=\"87.080914\" xlink:href=\"#C0_0_afe91af170\" y=\"172.229238\"/>\n    </g>\n    <g clip-path=\"url(#pbe494d9388)\">\n     <use style=\"fill:#ff7f0e;stroke:#ffffff;stroke-width:0.48;\" x=\"87.080914\" xlink:href=\"#C0_0_afe91af170\" y=\"209.993366\"/>\n    </g>\n    <g clip-path=\"url(#pbe494d9388)\">\n     <use style=\"fill:#2ca02c;stroke:#ffffff;stroke-width:0.48;\" x=\"87.080914\" xlink:href=\"#C0_0_afe91af170\" y=\"126.912285\"/>\n    </g>\n    <g clip-path=\"url(#pbe494d9388)\">\n     <use style=\"fill:#d62728;stroke:#ffffff;stroke-width:0.48;\" x=\"87.080914\" xlink:href=\"#C0_0_afe91af170\" y=\"179.782064\"/>\n    </g>\n    <g clip-path=\"url(#pbe494d9388)\">\n     <use style=\"fill:#9467bd;stroke:#ffffff;stroke-width:0.48;\" x=\"87.080914\" xlink:href=\"#C0_0_afe91af170\" y=\"149.570762\"/>\n    </g>\n    <g clip-path=\"url(#pbe494d9388)\">\n     <use style=\"fill:#8c564b;stroke:#ffffff;stroke-width:0.48;\" x=\"87.080914\" xlink:href=\"#C0_0_afe91af170\" y=\"81.595332\"/>\n    </g>\n    <g clip-path=\"url(#pbe494d9388)\">\n     <use style=\"fill:#e377c2;stroke:#ffffff;stroke-width:0.48;\" x=\"87.080914\" xlink:href=\"#C0_0_afe91af170\" y=\"126.912285\"/>\n    </g>\n    <g clip-path=\"url(#pbe494d9388)\">\n     <use style=\"fill:#1f77b4;stroke:#ffffff;stroke-width:0.48;\" x=\"134.468959\" xlink:href=\"#C0_0_afe91af170\" y=\"232.651843\"/>\n    </g>\n    <g clip-path=\"url(#pbe494d9388)\">\n     <use style=\"fill:#ff7f0e;stroke:#ffffff;stroke-width:0.48;\" x=\"134.468959\" xlink:href=\"#C0_0_afe91af170\" y=\"232.651843\"/>\n    </g>\n    <g clip-path=\"url(#pbe494d9388)\">\n     <use style=\"fill:#2ca02c;stroke:#ffffff;stroke-width:0.48;\" x=\"134.468959\" xlink:href=\"#C0_0_afe91af170\" y=\"164.676413\"/>\n    </g>\n    <g clip-path=\"url(#pbe494d9388)\">\n     <use style=\"fill:#d62728;stroke:#ffffff;stroke-width:0.48;\" x=\"134.468959\" xlink:href=\"#C0_0_afe91af170\" y=\"262.863145\"/>\n    </g>\n    <g clip-path=\"url(#pbe494d9388)\">\n     <use style=\"fill:#9467bd;stroke:#ffffff;stroke-width:0.48;\" x=\"134.468959\" xlink:href=\"#C0_0_afe91af170\" y=\"194.887715\"/>\n    </g>\n    <g clip-path=\"url(#pbe494d9388)\">\n     <use style=\"fill:#8c564b;stroke:#ffffff;stroke-width:0.48;\" x=\"134.468959\" xlink:href=\"#C0_0_afe91af170\" y=\"36.278378\"/>\n    </g>\n    <g clip-path=\"url(#pbe494d9388)\">\n     <use style=\"fill:#e377c2;stroke:#ffffff;stroke-width:0.48;\" x=\"134.468959\" xlink:href=\"#C0_0_afe91af170\" y=\"58.936855\"/>\n    </g>\n    <g clip-path=\"url(#pbe494d9388)\">\n     <use style=\"fill:#1f77b4;stroke:#ffffff;stroke-width:0.48;\" x=\"304.508413\" xlink:href=\"#C0_0_afe91af170\" y=\"277.968796\"/>\n    </g>\n    <g clip-path=\"url(#pbe494d9388)\">\n     <use style=\"fill:#ff7f0e;stroke:#ffffff;stroke-width:0.48;\" x=\"304.508413\" xlink:href=\"#C0_0_afe91af170\" y=\"270.415971\"/>\n    </g>\n    <g clip-path=\"url(#pbe494d9388)\">\n     <use style=\"fill:#2ca02c;stroke:#ffffff;stroke-width:0.48;\" x=\"304.508413\" xlink:href=\"#C0_0_afe91af170\" y=\"285.521622\"/>\n    </g>\n    <g clip-path=\"url(#pbe494d9388)\">\n     <use style=\"fill:#d62728;stroke:#ffffff;stroke-width:0.48;\" x=\"304.508413\" xlink:href=\"#C0_0_afe91af170\" y=\"285.521622\"/>\n    </g>\n    <g clip-path=\"url(#pbe494d9388)\">\n     <use style=\"fill:#9467bd;stroke:#ffffff;stroke-width:0.48;\" x=\"304.508413\" xlink:href=\"#C0_0_afe91af170\" y=\"247.757494\"/>\n    </g>\n    <g clip-path=\"url(#pbe494d9388)\">\n     <use style=\"fill:#8c564b;stroke:#ffffff;stroke-width:0.48;\" x=\"304.508413\" xlink:href=\"#C0_0_afe91af170\" y=\"232.651843\"/>\n    </g>\n    <g clip-path=\"url(#pbe494d9388)\">\n     <use style=\"fill:#e377c2;stroke:#ffffff;stroke-width:0.48;\" x=\"304.508413\" xlink:href=\"#C0_0_afe91af170\" y=\"270.415971\"/>\n    </g>\n    <g clip-path=\"url(#pbe494d9388)\">\n     <use style=\"fill:#1f77b4;stroke:#ffffff;stroke-width:0.48;\" x=\"168.84852\" xlink:href=\"#C0_0_afe91af170\" y=\"255.310319\"/>\n    </g>\n    <g clip-path=\"url(#pbe494d9388)\">\n     <use style=\"fill:#ff7f0e;stroke:#ffffff;stroke-width:0.48;\" x=\"168.84852\" xlink:href=\"#C0_0_afe91af170\" y=\"285.521622\"/>\n    </g>\n    <g clip-path=\"url(#pbe494d9388)\">\n     <use style=\"fill:#2ca02c;stroke:#ffffff;stroke-width:0.48;\" x=\"168.84852\" xlink:href=\"#C0_0_afe91af170\" y=\"217.546192\"/>\n    </g>\n    <g clip-path=\"url(#pbe494d9388)\">\n     <use style=\"fill:#d62728;stroke:#ffffff;stroke-width:0.48;\" x=\"168.84852\" xlink:href=\"#C0_0_afe91af170\" y=\"240.204668\"/>\n    </g>\n    <g clip-path=\"url(#pbe494d9388)\">\n     <use style=\"fill:#9467bd;stroke:#ffffff;stroke-width:0.48;\" x=\"168.84852\" xlink:href=\"#C0_0_afe91af170\" y=\"232.651843\"/>\n    </g>\n    <g clip-path=\"url(#pbe494d9388)\">\n     <use style=\"fill:#8c564b;stroke:#ffffff;stroke-width:0.48;\" x=\"168.84852\" xlink:href=\"#C0_0_afe91af170\" y=\"142.017936\"/>\n    </g>\n    <g clip-path=\"url(#pbe494d9388)\">\n     <use style=\"fill:#e377c2;stroke:#ffffff;stroke-width:0.48;\" x=\"168.84852\" xlink:href=\"#C0_0_afe91af170\" y=\"134.465111\"/>\n    </g>\n    <g clip-path=\"url(#pbe494d9388)\">\n     <use style=\"fill:#1f77b4;stroke:#ffffff;stroke-width:0.48;\" x=\"140.9732\" xlink:href=\"#C0_0_afe91af170\" y=\"194.887715\"/>\n    </g>\n    <g clip-path=\"url(#pbe494d9388)\">\n     <use style=\"fill:#ff7f0e;stroke:#ffffff;stroke-width:0.48;\" x=\"140.9732\" xlink:href=\"#C0_0_afe91af170\" y=\"255.310319\"/>\n    </g>\n    <g clip-path=\"url(#pbe494d9388)\">\n     <use style=\"fill:#2ca02c;stroke:#ffffff;stroke-width:0.48;\" x=\"140.9732\" xlink:href=\"#C0_0_afe91af170\" y=\"225.099017\"/>\n    </g>\n    <g clip-path=\"url(#pbe494d9388)\">\n     <use style=\"fill:#d62728;stroke:#ffffff;stroke-width:0.48;\" x=\"140.9732\" xlink:href=\"#C0_0_afe91af170\" y=\"262.863145\"/>\n    </g>\n    <g clip-path=\"url(#pbe494d9388)\">\n     <use style=\"fill:#9467bd;stroke:#ffffff;stroke-width:0.48;\" x=\"140.9732\" xlink:href=\"#C0_0_afe91af170\" y=\"172.229238\"/>\n    </g>\n    <g clip-path=\"url(#pbe494d9388)\">\n     <use style=\"fill:#8c564b;stroke:#ffffff;stroke-width:0.48;\" x=\"140.9732\" xlink:href=\"#C0_0_afe91af170\" y=\"36.278378\"/>\n    </g>\n    <g clip-path=\"url(#pbe494d9388)\">\n     <use style=\"fill:#e377c2;stroke:#ffffff;stroke-width:0.48;\" x=\"140.9732\" xlink:href=\"#C0_0_afe91af170\" y=\"104.253808\"/>\n    </g>\n    <g clip-path=\"url(#pbe494d9388)\">\n     <use style=\"fill:#1f77b4;stroke:#ffffff;stroke-width:0.48;\" x=\"155.840038\" xlink:href=\"#C0_0_afe91af170\" y=\"202.440541\"/>\n    </g>\n    <g clip-path=\"url(#pbe494d9388)\">\n     <use style=\"fill:#ff7f0e;stroke:#ffffff;stroke-width:0.48;\" x=\"155.840038\" xlink:href=\"#C0_0_afe91af170\" y=\"262.863145\"/>\n    </g>\n    <g clip-path=\"url(#pbe494d9388)\">\n     <use style=\"fill:#2ca02c;stroke:#ffffff;stroke-width:0.48;\" x=\"155.840038\" xlink:href=\"#C0_0_afe91af170\" y=\"225.099017\"/>\n    </g>\n    <g clip-path=\"url(#pbe494d9388)\">\n     <use style=\"fill:#d62728;stroke:#ffffff;stroke-width:0.48;\" x=\"155.840038\" xlink:href=\"#C0_0_afe91af170\" y=\"270.415971\"/>\n    </g>\n    <g clip-path=\"url(#pbe494d9388)\">\n     <use style=\"fill:#9467bd;stroke:#ffffff;stroke-width:0.48;\" x=\"155.840038\" xlink:href=\"#C0_0_afe91af170\" y=\"194.887715\"/>\n    </g>\n    <g clip-path=\"url(#pbe494d9388)\">\n     <use style=\"fill:#8c564b;stroke:#ffffff;stroke-width:0.48;\" x=\"155.840038\" xlink:href=\"#C0_0_afe91af170\" y=\"51.384029\"/>\n    </g>\n    <g clip-path=\"url(#pbe494d9388)\">\n     <use style=\"fill:#e377c2;stroke:#ffffff;stroke-width:0.48;\" x=\"155.840038\" xlink:href=\"#C0_0_afe91af170\" y=\"119.359459\"/>\n    </g>\n    <g clip-path=\"url(#pbe494d9388)\">\n     <use style=\"fill:#1f77b4;stroke:#ffffff;stroke-width:0.48;\" x=\"96.372688\" xlink:href=\"#C0_0_afe91af170\" y=\"157.123587\"/>\n    </g>\n    <g clip-path=\"url(#pbe494d9388)\">\n     <use style=\"fill:#ff7f0e;stroke:#ffffff;stroke-width:0.48;\" x=\"96.372688\" xlink:href=\"#C0_0_afe91af170\" y=\"240.204668\"/>\n    </g>\n    <g clip-path=\"url(#pbe494d9388)\">\n     <use style=\"fill:#2ca02c;stroke:#ffffff;stroke-width:0.48;\" x=\"96.372688\" xlink:href=\"#C0_0_afe91af170\" y=\"164.676413\"/>\n    </g>\n    <g clip-path=\"url(#pbe494d9388)\">\n     <use style=\"fill:#d62728;stroke:#ffffff;stroke-width:0.48;\" x=\"96.372688\" xlink:href=\"#C0_0_afe91af170\" y=\"225.099017\"/>\n    </g>\n    <g clip-path=\"url(#pbe494d9388)\">\n     <use style=\"fill:#9467bd;stroke:#ffffff;stroke-width:0.48;\" x=\"96.372688\" xlink:href=\"#C0_0_afe91af170\" y=\"157.123587\"/>\n    </g>\n    <g clip-path=\"url(#pbe494d9388)\">\n     <use style=\"fill:#8c564b;stroke:#ffffff;stroke-width:0.48;\" x=\"96.372688\" xlink:href=\"#C0_0_afe91af170\" y=\"74.042506\"/>\n    </g>\n    <g clip-path=\"url(#pbe494d9388)\">\n     <use style=\"fill:#e377c2;stroke:#ffffff;stroke-width:0.48;\" x=\"96.372688\" xlink:href=\"#C0_0_afe91af170\" y=\"66.489681\"/>\n    </g>\n    <g clip-path=\"url(#pbe494d9388)\">\n     <use style=\"fill:#1f77b4;stroke:#ffffff;stroke-width:0.48;\" x=\"309.154299\" xlink:href=\"#C0_0_afe91af170\" y=\"277.968796\"/>\n    </g>\n    <g clip-path=\"url(#pbe494d9388)\">\n     <use style=\"fill:#ff7f0e;stroke:#ffffff;stroke-width:0.48;\" x=\"309.154299\" xlink:href=\"#C0_0_afe91af170\" y=\"270.415971\"/>\n    </g>\n    <g clip-path=\"url(#pbe494d9388)\">\n     <use style=\"fill:#2ca02c;stroke:#ffffff;stroke-width:0.48;\" x=\"309.154299\" xlink:href=\"#C0_0_afe91af170\" y=\"255.310319\"/>\n    </g>\n    <g clip-path=\"url(#pbe494d9388)\">\n     <use style=\"fill:#d62728;stroke:#ffffff;stroke-width:0.48;\" x=\"309.154299\" xlink:href=\"#C0_0_afe91af170\" y=\"270.415971\"/>\n    </g>\n    <g clip-path=\"url(#pbe494d9388)\">\n     <use style=\"fill:#9467bd;stroke:#ffffff;stroke-width:0.48;\" x=\"309.154299\" xlink:href=\"#C0_0_afe91af170\" y=\"240.204668\"/>\n    </g>\n    <g clip-path=\"url(#pbe494d9388)\">\n     <use style=\"fill:#8c564b;stroke:#ffffff;stroke-width:0.48;\" x=\"309.154299\" xlink:href=\"#C0_0_afe91af170\" y=\"232.651843\"/>\n    </g>\n    <g clip-path=\"url(#pbe494d9388)\">\n     <use style=\"fill:#e377c2;stroke:#ffffff;stroke-width:0.48;\" x=\"309.154299\" xlink:href=\"#C0_0_afe91af170\" y=\"270.415971\"/>\n    </g>\n   </g>\n   <g id=\"PathCollection_2\"/>\n   <g id=\"PathCollection_3\"/>\n   <g id=\"PathCollection_4\"/>\n   <g id=\"PathCollection_5\"/>\n   <g id=\"PathCollection_6\"/>\n   <g id=\"PathCollection_7\"/>\n   <g id=\"PathCollection_8\"/>\n   <g id=\"matplotlib.axis_1\">\n    <g id=\"xtick_1\">\n     <g id=\"line2d_1\">\n      <defs>\n       <path d=\"M 0 0 \nL 0 3.5 \n\" id=\"m31dc1b2699\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n      </defs>\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"55.488885\" xlink:href=\"#m31dc1b2699\" y=\"314.6\"/>\n      </g>\n     </g>\n     <g id=\"text_1\">\n      <!-- 0 -->\n      <g transform=\"translate(52.307635 329.198437)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 2034 4250 \nQ 1547 4250 1301 3770 \nQ 1056 3291 1056 2328 \nQ 1056 1369 1301 889 \nQ 1547 409 2034 409 \nQ 2525 409 2770 889 \nQ 3016 1369 3016 2328 \nQ 3016 3291 2770 3770 \nQ 2525 4250 2034 4250 \nz\nM 2034 4750 \nQ 2819 4750 3233 4129 \nQ 3647 3509 3647 2328 \nQ 3647 1150 3233 529 \nQ 2819 -91 2034 -91 \nQ 1250 -91 836 529 \nQ 422 1150 422 2328 \nQ 422 3509 836 4129 \nQ 1250 4750 2034 4750 \nz\n\" id=\"DejaVuSans-30\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-30\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_2\">\n     <g id=\"line2d_2\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"101.947752\" xlink:href=\"#m31dc1b2699\" y=\"314.6\"/>\n      </g>\n     </g>\n     <g id=\"text_2\">\n      <!-- 50 -->\n      <g transform=\"translate(95.585252 329.198437)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 691 4666 \nL 3169 4666 \nL 3169 4134 \nL 1269 4134 \nL 1269 2991 \nQ 1406 3038 1543 3061 \nQ 1681 3084 1819 3084 \nQ 2600 3084 3056 2656 \nQ 3513 2228 3513 1497 \nQ 3513 744 3044 326 \nQ 2575 -91 1722 -91 \nQ 1428 -91 1123 -41 \nQ 819 9 494 109 \nL 494 744 \nQ 775 591 1075 516 \nQ 1375 441 1709 441 \nQ 2250 441 2565 725 \nQ 2881 1009 2881 1497 \nQ 2881 1984 2565 2268 \nQ 2250 2553 1709 2553 \nQ 1456 2553 1204 2497 \nQ 953 2441 691 2322 \nL 691 4666 \nz\n\" id=\"DejaVuSans-35\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-35\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-30\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_3\">\n     <g id=\"line2d_3\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"148.406619\" xlink:href=\"#m31dc1b2699\" y=\"314.6\"/>\n      </g>\n     </g>\n     <g id=\"text_3\">\n      <!-- 100 -->\n      <g transform=\"translate(138.862869 329.198437)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 794 531 \nL 1825 531 \nL 1825 4091 \nL 703 3866 \nL 703 4441 \nL 1819 4666 \nL 2450 4666 \nL 2450 531 \nL 3481 531 \nL 3481 0 \nL 794 0 \nL 794 531 \nz\n\" id=\"DejaVuSans-31\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-31\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-30\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-30\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_4\">\n     <g id=\"line2d_4\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"194.865486\" xlink:href=\"#m31dc1b2699\" y=\"314.6\"/>\n      </g>\n     </g>\n     <g id=\"text_4\">\n      <!-- 150 -->\n      <g transform=\"translate(185.321736 329.198437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-31\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-35\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-30\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_5\">\n     <g id=\"line2d_5\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"241.324353\" xlink:href=\"#m31dc1b2699\" y=\"314.6\"/>\n      </g>\n     </g>\n     <g id=\"text_5\">\n      <!-- 200 -->\n      <g transform=\"translate(231.780603 329.198437)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 1228 531 \nL 3431 531 \nL 3431 0 \nL 469 0 \nL 469 531 \nQ 828 903 1448 1529 \nQ 2069 2156 2228 2338 \nQ 2531 2678 2651 2914 \nQ 2772 3150 2772 3378 \nQ 2772 3750 2511 3984 \nQ 2250 4219 1831 4219 \nQ 1534 4219 1204 4116 \nQ 875 4013 500 3803 \nL 500 4441 \nQ 881 4594 1212 4672 \nQ 1544 4750 1819 4750 \nQ 2544 4750 2975 4387 \nQ 3406 4025 3406 3419 \nQ 3406 3131 3298 2873 \nQ 3191 2616 2906 2266 \nQ 2828 2175 2409 1742 \nQ 1991 1309 1228 531 \nz\n\" id=\"DejaVuSans-32\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-32\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-30\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-30\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_6\">\n     <g id=\"line2d_6\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"287.78322\" xlink:href=\"#m31dc1b2699\" y=\"314.6\"/>\n      </g>\n     </g>\n     <g id=\"text_6\">\n      <!-- 250 -->\n      <g transform=\"translate(278.23947 329.198437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-32\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-35\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-30\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"text_7\">\n     <!-- len_col_left -->\n     <g transform=\"translate(154.855712 342.876562)scale(0.1 -0.1)\">\n      <defs>\n       <path d=\"M 603 4863 \nL 1178 4863 \nL 1178 0 \nL 603 0 \nL 603 4863 \nz\n\" id=\"DejaVuSans-6c\" transform=\"scale(0.015625)\"/>\n       <path d=\"M 3597 1894 \nL 3597 1613 \nL 953 1613 \nQ 991 1019 1311 708 \nQ 1631 397 2203 397 \nQ 2534 397 2845 478 \nQ 3156 559 3463 722 \nL 3463 178 \nQ 3153 47 2828 -22 \nQ 2503 -91 2169 -91 \nQ 1331 -91 842 396 \nQ 353 884 353 1716 \nQ 353 2575 817 3079 \nQ 1281 3584 2069 3584 \nQ 2775 3584 3186 3129 \nQ 3597 2675 3597 1894 \nz\nM 3022 2063 \nQ 3016 2534 2758 2815 \nQ 2500 3097 2075 3097 \nQ 1594 3097 1305 2825 \nQ 1016 2553 972 2059 \nL 3022 2063 \nz\n\" id=\"DejaVuSans-65\" transform=\"scale(0.015625)\"/>\n       <path d=\"M 3513 2113 \nL 3513 0 \nL 2938 0 \nL 2938 2094 \nQ 2938 2591 2744 2837 \nQ 2550 3084 2163 3084 \nQ 1697 3084 1428 2787 \nQ 1159 2491 1159 1978 \nL 1159 0 \nL 581 0 \nL 581 3500 \nL 1159 3500 \nL 1159 2956 \nQ 1366 3272 1645 3428 \nQ 1925 3584 2291 3584 \nQ 2894 3584 3203 3211 \nQ 3513 2838 3513 2113 \nz\n\" id=\"DejaVuSans-6e\" transform=\"scale(0.015625)\"/>\n       <path d=\"M 3263 -1063 \nL 3263 -1509 \nL -63 -1509 \nL -63 -1063 \nL 3263 -1063 \nz\n\" id=\"DejaVuSans-5f\" transform=\"scale(0.015625)\"/>\n       <path d=\"M 3122 3366 \nL 3122 2828 \nQ 2878 2963 2633 3030 \nQ 2388 3097 2138 3097 \nQ 1578 3097 1268 2742 \nQ 959 2388 959 1747 \nQ 959 1106 1268 751 \nQ 1578 397 2138 397 \nQ 2388 397 2633 464 \nQ 2878 531 3122 666 \nL 3122 134 \nQ 2881 22 2623 -34 \nQ 2366 -91 2075 -91 \nQ 1284 -91 818 406 \nQ 353 903 353 1747 \nQ 353 2603 823 3093 \nQ 1294 3584 2113 3584 \nQ 2378 3584 2631 3529 \nQ 2884 3475 3122 3366 \nz\n\" id=\"DejaVuSans-63\" transform=\"scale(0.015625)\"/>\n       <path d=\"M 1959 3097 \nQ 1497 3097 1228 2736 \nQ 959 2375 959 1747 \nQ 959 1119 1226 758 \nQ 1494 397 1959 397 \nQ 2419 397 2687 759 \nQ 2956 1122 2956 1747 \nQ 2956 2369 2687 2733 \nQ 2419 3097 1959 3097 \nz\nM 1959 3584 \nQ 2709 3584 3137 3096 \nQ 3566 2609 3566 1747 \nQ 3566 888 3137 398 \nQ 2709 -91 1959 -91 \nQ 1206 -91 779 398 \nQ 353 888 353 1747 \nQ 353 2609 779 3096 \nQ 1206 3584 1959 3584 \nz\n\" id=\"DejaVuSans-6f\" transform=\"scale(0.015625)\"/>\n       <path d=\"M 2375 4863 \nL 2375 4384 \nL 1825 4384 \nQ 1516 4384 1395 4259 \nQ 1275 4134 1275 3809 \nL 1275 3500 \nL 2222 3500 \nL 2222 3053 \nL 1275 3053 \nL 1275 0 \nL 697 0 \nL 697 3053 \nL 147 3053 \nL 147 3500 \nL 697 3500 \nL 697 3744 \nQ 697 4328 969 4595 \nQ 1241 4863 1831 4863 \nL 2375 4863 \nz\n\" id=\"DejaVuSans-66\" transform=\"scale(0.015625)\"/>\n       <path d=\"M 1172 4494 \nL 1172 3500 \nL 2356 3500 \nL 2356 3053 \nL 1172 3053 \nL 1172 1153 \nQ 1172 725 1289 603 \nQ 1406 481 1766 481 \nL 2356 481 \nL 2356 0 \nL 1766 0 \nQ 1100 0 847 248 \nQ 594 497 594 1153 \nL 594 3053 \nL 172 3053 \nL 172 3500 \nL 594 3500 \nL 594 4494 \nL 1172 4494 \nz\n\" id=\"DejaVuSans-74\" transform=\"scale(0.015625)\"/>\n      </defs>\n      <use xlink:href=\"#DejaVuSans-6c\"/>\n      <use x=\"27.783203\" xlink:href=\"#DejaVuSans-65\"/>\n      <use x=\"89.306641\" xlink:href=\"#DejaVuSans-6e\"/>\n      <use x=\"152.685547\" xlink:href=\"#DejaVuSans-5f\"/>\n      <use x=\"202.685547\" xlink:href=\"#DejaVuSans-63\"/>\n      <use x=\"257.666016\" xlink:href=\"#DejaVuSans-6f\"/>\n      <use x=\"318.847656\" xlink:href=\"#DejaVuSans-6c\"/>\n      <use x=\"346.630859\" xlink:href=\"#DejaVuSans-5f\"/>\n      <use x=\"396.630859\" xlink:href=\"#DejaVuSans-6c\"/>\n      <use x=\"424.414062\" xlink:href=\"#DejaVuSans-65\"/>\n      <use x=\"485.9375\" xlink:href=\"#DejaVuSans-66\"/>\n      <use x=\"519.392578\" xlink:href=\"#DejaVuSans-74\"/>\n     </g>\n    </g>\n   </g>\n   <g id=\"matplotlib.axis_2\">\n    <g id=\"ytick_1\">\n     <g id=\"line2d_7\">\n      <defs>\n       <path d=\"M 0 0 \nL -3.5 0 \n\" id=\"m8ca4b38b1d\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n      </defs>\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"43.78125\" xlink:href=\"#m8ca4b38b1d\" y=\"293.074447\"/>\n      </g>\n     </g>\n     <g id=\"text_8\">\n      <!-- 0.4 -->\n      <g transform=\"translate(20.878125 296.873666)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 684 794 \nL 1344 794 \nL 1344 0 \nL 684 0 \nL 684 794 \nz\n\" id=\"DejaVuSans-2e\" transform=\"scale(0.015625)\"/>\n        <path d=\"M 2419 4116 \nL 825 1625 \nL 2419 1625 \nL 2419 4116 \nz\nM 2253 4666 \nL 3047 4666 \nL 3047 1625 \nL 3713 1625 \nL 3713 1100 \nL 3047 1100 \nL 3047 0 \nL 2419 0 \nL 2419 1100 \nL 313 1100 \nL 313 1709 \nL 2253 4666 \nz\n\" id=\"DejaVuSans-34\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-30\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-2e\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-34\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_2\">\n     <g id=\"line2d_8\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"43.78125\" xlink:href=\"#m8ca4b38b1d\" y=\"247.757494\"/>\n      </g>\n     </g>\n     <g id=\"text_9\">\n      <!-- 0.5 -->\n      <g transform=\"translate(20.878125 251.556713)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-30\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-2e\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-35\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_3\">\n     <g id=\"line2d_9\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"43.78125\" xlink:href=\"#m8ca4b38b1d\" y=\"202.440541\"/>\n      </g>\n     </g>\n     <g id=\"text_10\">\n      <!-- 0.6 -->\n      <g transform=\"translate(20.878125 206.239759)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 2113 2584 \nQ 1688 2584 1439 2293 \nQ 1191 2003 1191 1497 \nQ 1191 994 1439 701 \nQ 1688 409 2113 409 \nQ 2538 409 2786 701 \nQ 3034 994 3034 1497 \nQ 3034 2003 2786 2293 \nQ 2538 2584 2113 2584 \nz\nM 3366 4563 \nL 3366 3988 \nQ 3128 4100 2886 4159 \nQ 2644 4219 2406 4219 \nQ 1781 4219 1451 3797 \nQ 1122 3375 1075 2522 \nQ 1259 2794 1537 2939 \nQ 1816 3084 2150 3084 \nQ 2853 3084 3261 2657 \nQ 3669 2231 3669 1497 \nQ 3669 778 3244 343 \nQ 2819 -91 2113 -91 \nQ 1303 -91 875 529 \nQ 447 1150 447 2328 \nQ 447 3434 972 4092 \nQ 1497 4750 2381 4750 \nQ 2619 4750 2861 4703 \nQ 3103 4656 3366 4563 \nz\n\" id=\"DejaVuSans-36\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-30\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-2e\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-36\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_4\">\n     <g id=\"line2d_10\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"43.78125\" xlink:href=\"#m8ca4b38b1d\" y=\"157.123587\"/>\n      </g>\n     </g>\n     <g id=\"text_11\">\n      <!-- 0.7 -->\n      <g transform=\"translate(20.878125 160.922806)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 525 4666 \nL 3525 4666 \nL 3525 4397 \nL 1831 0 \nL 1172 0 \nL 2766 4134 \nL 525 4134 \nL 525 4666 \nz\n\" id=\"DejaVuSans-37\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-30\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-2e\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-37\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_5\">\n     <g id=\"line2d_11\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"43.78125\" xlink:href=\"#m8ca4b38b1d\" y=\"111.806634\"/>\n      </g>\n     </g>\n     <g id=\"text_12\">\n      <!-- 0.8 -->\n      <g transform=\"translate(20.878125 115.605853)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 2034 2216 \nQ 1584 2216 1326 1975 \nQ 1069 1734 1069 1313 \nQ 1069 891 1326 650 \nQ 1584 409 2034 409 \nQ 2484 409 2743 651 \nQ 3003 894 3003 1313 \nQ 3003 1734 2745 1975 \nQ 2488 2216 2034 2216 \nz\nM 1403 2484 \nQ 997 2584 770 2862 \nQ 544 3141 544 3541 \nQ 544 4100 942 4425 \nQ 1341 4750 2034 4750 \nQ 2731 4750 3128 4425 \nQ 3525 4100 3525 3541 \nQ 3525 3141 3298 2862 \nQ 3072 2584 2669 2484 \nQ 3125 2378 3379 2068 \nQ 3634 1759 3634 1313 \nQ 3634 634 3220 271 \nQ 2806 -91 2034 -91 \nQ 1263 -91 848 271 \nQ 434 634 434 1313 \nQ 434 1759 690 2068 \nQ 947 2378 1403 2484 \nz\nM 1172 3481 \nQ 1172 3119 1398 2916 \nQ 1625 2713 2034 2713 \nQ 2441 2713 2670 2916 \nQ 2900 3119 2900 3481 \nQ 2900 3844 2670 4047 \nQ 2441 4250 2034 4250 \nQ 1625 4250 1398 4047 \nQ 1172 3844 1172 3481 \nz\n\" id=\"DejaVuSans-38\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-30\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-2e\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-38\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_6\">\n     <g id=\"line2d_12\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"43.78125\" xlink:href=\"#m8ca4b38b1d\" y=\"66.489681\"/>\n      </g>\n     </g>\n     <g id=\"text_13\">\n      <!-- 0.9 -->\n      <g transform=\"translate(20.878125 70.288899)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 703 97 \nL 703 672 \nQ 941 559 1184 500 \nQ 1428 441 1663 441 \nQ 2288 441 2617 861 \nQ 2947 1281 2994 2138 \nQ 2813 1869 2534 1725 \nQ 2256 1581 1919 1581 \nQ 1219 1581 811 2004 \nQ 403 2428 403 3163 \nQ 403 3881 828 4315 \nQ 1253 4750 1959 4750 \nQ 2769 4750 3195 4129 \nQ 3622 3509 3622 2328 \nQ 3622 1225 3098 567 \nQ 2575 -91 1691 -91 \nQ 1453 -91 1209 -44 \nQ 966 3 703 97 \nz\nM 1959 2075 \nQ 2384 2075 2632 2365 \nQ 2881 2656 2881 3163 \nQ 2881 3666 2632 3958 \nQ 2384 4250 1959 4250 \nQ 1534 4250 1286 3958 \nQ 1038 3666 1038 3163 \nQ 1038 2656 1286 2365 \nQ 1534 2075 1959 2075 \nz\n\" id=\"DejaVuSans-39\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-30\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-2e\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-39\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_7\">\n     <g id=\"line2d_13\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"43.78125\" xlink:href=\"#m8ca4b38b1d\" y=\"21.172727\"/>\n      </g>\n     </g>\n     <g id=\"text_14\">\n      <!-- 1.0 -->\n      <g transform=\"translate(20.878125 24.971946)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-31\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-2e\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-30\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"text_15\">\n     <!-- avg_test -->\n     <g transform=\"translate(14.520313 182.199219)rotate(-90)scale(0.1 -0.1)\">\n      <defs>\n       <path d=\"M 2194 1759 \nQ 1497 1759 1228 1600 \nQ 959 1441 959 1056 \nQ 959 750 1161 570 \nQ 1363 391 1709 391 \nQ 2188 391 2477 730 \nQ 2766 1069 2766 1631 \nL 2766 1759 \nL 2194 1759 \nz\nM 3341 1997 \nL 3341 0 \nL 2766 0 \nL 2766 531 \nQ 2569 213 2275 61 \nQ 1981 -91 1556 -91 \nQ 1019 -91 701 211 \nQ 384 513 384 1019 \nQ 384 1609 779 1909 \nQ 1175 2209 1959 2209 \nL 2766 2209 \nL 2766 2266 \nQ 2766 2663 2505 2880 \nQ 2244 3097 1772 3097 \nQ 1472 3097 1187 3025 \nQ 903 2953 641 2809 \nL 641 3341 \nQ 956 3463 1253 3523 \nQ 1550 3584 1831 3584 \nQ 2591 3584 2966 3190 \nQ 3341 2797 3341 1997 \nz\n\" id=\"DejaVuSans-61\" transform=\"scale(0.015625)\"/>\n       <path d=\"M 191 3500 \nL 800 3500 \nL 1894 563 \nL 2988 3500 \nL 3597 3500 \nL 2284 0 \nL 1503 0 \nL 191 3500 \nz\n\" id=\"DejaVuSans-76\" transform=\"scale(0.015625)\"/>\n       <path d=\"M 2906 1791 \nQ 2906 2416 2648 2759 \nQ 2391 3103 1925 3103 \nQ 1463 3103 1205 2759 \nQ 947 2416 947 1791 \nQ 947 1169 1205 825 \nQ 1463 481 1925 481 \nQ 2391 481 2648 825 \nQ 2906 1169 2906 1791 \nz\nM 3481 434 \nQ 3481 -459 3084 -895 \nQ 2688 -1331 1869 -1331 \nQ 1566 -1331 1297 -1286 \nQ 1028 -1241 775 -1147 \nL 775 -588 \nQ 1028 -725 1275 -790 \nQ 1522 -856 1778 -856 \nQ 2344 -856 2625 -561 \nQ 2906 -266 2906 331 \nL 2906 616 \nQ 2728 306 2450 153 \nQ 2172 0 1784 0 \nQ 1141 0 747 490 \nQ 353 981 353 1791 \nQ 353 2603 747 3093 \nQ 1141 3584 1784 3584 \nQ 2172 3584 2450 3431 \nQ 2728 3278 2906 2969 \nL 2906 3500 \nL 3481 3500 \nL 3481 434 \nz\n\" id=\"DejaVuSans-67\" transform=\"scale(0.015625)\"/>\n       <path d=\"M 2834 3397 \nL 2834 2853 \nQ 2591 2978 2328 3040 \nQ 2066 3103 1784 3103 \nQ 1356 3103 1142 2972 \nQ 928 2841 928 2578 \nQ 928 2378 1081 2264 \nQ 1234 2150 1697 2047 \nL 1894 2003 \nQ 2506 1872 2764 1633 \nQ 3022 1394 3022 966 \nQ 3022 478 2636 193 \nQ 2250 -91 1575 -91 \nQ 1294 -91 989 -36 \nQ 684 19 347 128 \nL 347 722 \nQ 666 556 975 473 \nQ 1284 391 1588 391 \nQ 1994 391 2212 530 \nQ 2431 669 2431 922 \nQ 2431 1156 2273 1281 \nQ 2116 1406 1581 1522 \nL 1381 1569 \nQ 847 1681 609 1914 \nQ 372 2147 372 2553 \nQ 372 3047 722 3315 \nQ 1072 3584 1716 3584 \nQ 2034 3584 2315 3537 \nQ 2597 3491 2834 3397 \nz\n\" id=\"DejaVuSans-73\" transform=\"scale(0.015625)\"/>\n      </defs>\n      <use xlink:href=\"#DejaVuSans-61\"/>\n      <use x=\"61.279297\" xlink:href=\"#DejaVuSans-76\"/>\n      <use x=\"120.458984\" xlink:href=\"#DejaVuSans-67\"/>\n      <use x=\"183.935547\" xlink:href=\"#DejaVuSans-5f\"/>\n      <use x=\"233.935547\" xlink:href=\"#DejaVuSans-74\"/>\n      <use x=\"273.144531\" xlink:href=\"#DejaVuSans-65\"/>\n      <use x=\"334.667969\" xlink:href=\"#DejaVuSans-73\"/>\n      <use x=\"386.767578\" xlink:href=\"#DejaVuSans-74\"/>\n     </g>\n    </g>\n   </g>\n   <g id=\"patch_3\">\n    <path d=\"M 43.78125 314.6 \nL 43.78125 7.2 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_4\">\n    <path d=\"M 43.78125 314.6 \nL 321.791111 314.6 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n  </g>\n  <g id=\"legend_1\">\n   <g id=\"text_16\">\n    <!-- model -->\n    <g transform=\"translate(416.317205 127.464062)scale(0.1 -0.1)\">\n     <defs>\n      <path d=\"M 3328 2828 \nQ 3544 3216 3844 3400 \nQ 4144 3584 4550 3584 \nQ 5097 3584 5394 3201 \nQ 5691 2819 5691 2113 \nL 5691 0 \nL 5113 0 \nL 5113 2094 \nQ 5113 2597 4934 2840 \nQ 4756 3084 4391 3084 \nQ 3944 3084 3684 2787 \nQ 3425 2491 3425 1978 \nL 3425 0 \nL 2847 0 \nL 2847 2094 \nQ 2847 2600 2669 2842 \nQ 2491 3084 2119 3084 \nQ 1678 3084 1418 2786 \nQ 1159 2488 1159 1978 \nL 1159 0 \nL 581 0 \nL 581 3500 \nL 1159 3500 \nL 1159 2956 \nQ 1356 3278 1631 3431 \nQ 1906 3584 2284 3584 \nQ 2666 3584 2933 3390 \nQ 3200 3197 3328 2828 \nz\n\" id=\"DejaVuSans-6d\" transform=\"scale(0.015625)\"/>\n      <path d=\"M 2906 2969 \nL 2906 4863 \nL 3481 4863 \nL 3481 0 \nL 2906 0 \nL 2906 525 \nQ 2725 213 2448 61 \nQ 2172 -91 1784 -91 \nQ 1150 -91 751 415 \nQ 353 922 353 1747 \nQ 353 2572 751 3078 \nQ 1150 3584 1784 3584 \nQ 2172 3584 2448 3432 \nQ 2725 3281 2906 2969 \nz\nM 947 1747 \nQ 947 1113 1208 752 \nQ 1469 391 1925 391 \nQ 2381 391 2643 752 \nQ 2906 1113 2906 1747 \nQ 2906 2381 2643 2742 \nQ 2381 3103 1925 3103 \nQ 1469 3103 1208 2742 \nQ 947 2381 947 1747 \nz\n\" id=\"DejaVuSans-64\" transform=\"scale(0.015625)\"/>\n     </defs>\n     <use xlink:href=\"#DejaVuSans-6d\"/>\n     <use x=\"97.412109\" xlink:href=\"#DejaVuSans-6f\"/>\n     <use x=\"158.59375\" xlink:href=\"#DejaVuSans-64\"/>\n     <use x=\"222.070312\" xlink:href=\"#DejaVuSans-65\"/>\n     <use x=\"283.59375\" xlink:href=\"#DejaVuSans-6c\"/>\n    </g>\n   </g>\n   <g id=\"PathCollection_9\">\n    <defs>\n     <path d=\"M 0 3 \nC 0.795609 3 1.55874 2.683901 2.12132 2.12132 \nC 2.683901 1.55874 3 0.795609 3 0 \nC 3 -0.795609 2.683901 -1.55874 2.12132 -2.12132 \nC 1.55874 -2.683901 0.795609 -3 0 -3 \nC -0.795609 -3 -1.55874 -2.683901 -2.12132 -2.12132 \nC -2.683901 -1.55874 -3 -0.795609 -3 0 \nC -3 0.795609 -2.683901 1.55874 -2.12132 2.12132 \nC -1.55874 2.683901 -0.795609 3 0 3 \nz\n\" id=\"m5ad12a2e79\" style=\"stroke:#1f77b4;\"/>\n    </defs>\n    <g>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"338.789861\" xlink:href=\"#m5ad12a2e79\" y=\"139.517187\"/>\n    </g>\n   </g>\n   <g id=\"text_17\">\n    <!-- AdaBoostClassifier() -->\n    <g transform=\"translate(356.789861 142.142187)scale(0.1 -0.1)\">\n     <defs>\n      <path d=\"M 2188 4044 \nL 1331 1722 \nL 3047 1722 \nL 2188 4044 \nz\nM 1831 4666 \nL 2547 4666 \nL 4325 0 \nL 3669 0 \nL 3244 1197 \nL 1141 1197 \nL 716 0 \nL 50 0 \nL 1831 4666 \nz\n\" id=\"DejaVuSans-41\" transform=\"scale(0.015625)\"/>\n      <path d=\"M 1259 2228 \nL 1259 519 \nL 2272 519 \nQ 2781 519 3026 730 \nQ 3272 941 3272 1375 \nQ 3272 1813 3026 2020 \nQ 2781 2228 2272 2228 \nL 1259 2228 \nz\nM 1259 4147 \nL 1259 2741 \nL 2194 2741 \nQ 2656 2741 2882 2914 \nQ 3109 3088 3109 3444 \nQ 3109 3797 2882 3972 \nQ 2656 4147 2194 4147 \nL 1259 4147 \nz\nM 628 4666 \nL 2241 4666 \nQ 2963 4666 3353 4366 \nQ 3744 4066 3744 3513 \nQ 3744 3084 3544 2831 \nQ 3344 2578 2956 2516 \nQ 3422 2416 3680 2098 \nQ 3938 1781 3938 1306 \nQ 3938 681 3513 340 \nQ 3088 0 2303 0 \nL 628 0 \nL 628 4666 \nz\n\" id=\"DejaVuSans-42\" transform=\"scale(0.015625)\"/>\n      <path d=\"M 4122 4306 \nL 4122 3641 \nQ 3803 3938 3442 4084 \nQ 3081 4231 2675 4231 \nQ 1875 4231 1450 3742 \nQ 1025 3253 1025 2328 \nQ 1025 1406 1450 917 \nQ 1875 428 2675 428 \nQ 3081 428 3442 575 \nQ 3803 722 4122 1019 \nL 4122 359 \nQ 3791 134 3420 21 \nQ 3050 -91 2638 -91 \nQ 1578 -91 968 557 \nQ 359 1206 359 2328 \nQ 359 3453 968 4101 \nQ 1578 4750 2638 4750 \nQ 3056 4750 3426 4639 \nQ 3797 4528 4122 4306 \nz\n\" id=\"DejaVuSans-43\" transform=\"scale(0.015625)\"/>\n      <path d=\"M 603 3500 \nL 1178 3500 \nL 1178 0 \nL 603 0 \nL 603 3500 \nz\nM 603 4863 \nL 1178 4863 \nL 1178 4134 \nL 603 4134 \nL 603 4863 \nz\n\" id=\"DejaVuSans-69\" transform=\"scale(0.015625)\"/>\n      <path d=\"M 2631 2963 \nQ 2534 3019 2420 3045 \nQ 2306 3072 2169 3072 \nQ 1681 3072 1420 2755 \nQ 1159 2438 1159 1844 \nL 1159 0 \nL 581 0 \nL 581 3500 \nL 1159 3500 \nL 1159 2956 \nQ 1341 3275 1631 3429 \nQ 1922 3584 2338 3584 \nQ 2397 3584 2469 3576 \nQ 2541 3569 2628 3553 \nL 2631 2963 \nz\n\" id=\"DejaVuSans-72\" transform=\"scale(0.015625)\"/>\n      <path d=\"M 1984 4856 \nQ 1566 4138 1362 3434 \nQ 1159 2731 1159 2009 \nQ 1159 1288 1364 580 \nQ 1569 -128 1984 -844 \nL 1484 -844 \nQ 1016 -109 783 600 \nQ 550 1309 550 2009 \nQ 550 2706 781 3412 \nQ 1013 4119 1484 4856 \nL 1984 4856 \nz\n\" id=\"DejaVuSans-28\" transform=\"scale(0.015625)\"/>\n      <path d=\"M 513 4856 \nL 1013 4856 \nQ 1481 4119 1714 3412 \nQ 1947 2706 1947 2009 \nQ 1947 1309 1714 600 \nQ 1481 -109 1013 -844 \nL 513 -844 \nQ 928 -128 1133 580 \nQ 1338 1288 1338 2009 \nQ 1338 2731 1133 3434 \nQ 928 4138 513 4856 \nz\n\" id=\"DejaVuSans-29\" transform=\"scale(0.015625)\"/>\n     </defs>\n     <use xlink:href=\"#DejaVuSans-41\"/>\n     <use x=\"66.658203\" xlink:href=\"#DejaVuSans-64\"/>\n     <use x=\"130.134766\" xlink:href=\"#DejaVuSans-61\"/>\n     <use x=\"191.414062\" xlink:href=\"#DejaVuSans-42\"/>\n     <use x=\"260.017578\" xlink:href=\"#DejaVuSans-6f\"/>\n     <use x=\"321.199219\" xlink:href=\"#DejaVuSans-6f\"/>\n     <use x=\"382.380859\" xlink:href=\"#DejaVuSans-73\"/>\n     <use x=\"434.480469\" xlink:href=\"#DejaVuSans-74\"/>\n     <use x=\"473.689453\" xlink:href=\"#DejaVuSans-43\"/>\n     <use x=\"543.513672\" xlink:href=\"#DejaVuSans-6c\"/>\n     <use x=\"571.296875\" xlink:href=\"#DejaVuSans-61\"/>\n     <use x=\"632.576172\" xlink:href=\"#DejaVuSans-73\"/>\n     <use x=\"684.675781\" xlink:href=\"#DejaVuSans-73\"/>\n     <use x=\"736.775391\" xlink:href=\"#DejaVuSans-69\"/>\n     <use x=\"764.558594\" xlink:href=\"#DejaVuSans-66\"/>\n     <use x=\"799.763672\" xlink:href=\"#DejaVuSans-69\"/>\n     <use x=\"827.546875\" xlink:href=\"#DejaVuSans-65\"/>\n     <use x=\"889.070312\" xlink:href=\"#DejaVuSans-72\"/>\n     <use x=\"930.183594\" xlink:href=\"#DejaVuSans-28\"/>\n     <use x=\"969.197266\" xlink:href=\"#DejaVuSans-29\"/>\n    </g>\n   </g>\n   <g id=\"PathCollection_10\">\n    <defs>\n     <path d=\"M 0 3 \nC 0.795609 3 1.55874 2.683901 2.12132 2.12132 \nC 2.683901 1.55874 3 0.795609 3 0 \nC 3 -0.795609 2.683901 -1.55874 2.12132 -2.12132 \nC 1.55874 -2.683901 0.795609 -3 0 -3 \nC -0.795609 -3 -1.55874 -2.683901 -2.12132 -2.12132 \nC -2.683901 -1.55874 -3 -0.795609 -3 0 \nC -3 0.795609 -2.683901 1.55874 -2.12132 2.12132 \nC -1.55874 2.683901 -0.795609 3 0 3 \nz\n\" id=\"m4b87edc6c1\" style=\"stroke:#ff7f0e;\"/>\n    </defs>\n    <g>\n     <use style=\"fill:#ff7f0e;stroke:#ff7f0e;\" x=\"338.789861\" xlink:href=\"#m4b87edc6c1\" y=\"154.195312\"/>\n    </g>\n   </g>\n   <g id=\"text_18\">\n    <!-- GradientBoostingClassifier() -->\n    <g transform=\"translate(356.789861 156.820312)scale(0.1 -0.1)\">\n     <defs>\n      <path d=\"M 3809 666 \nL 3809 1919 \nL 2778 1919 \nL 2778 2438 \nL 4434 2438 \nL 4434 434 \nQ 4069 175 3628 42 \nQ 3188 -91 2688 -91 \nQ 1594 -91 976 548 \nQ 359 1188 359 2328 \nQ 359 3472 976 4111 \nQ 1594 4750 2688 4750 \nQ 3144 4750 3555 4637 \nQ 3966 4525 4313 4306 \nL 4313 3634 \nQ 3963 3931 3569 4081 \nQ 3175 4231 2741 4231 \nQ 1884 4231 1454 3753 \nQ 1025 3275 1025 2328 \nQ 1025 1384 1454 906 \nQ 1884 428 2741 428 \nQ 3075 428 3337 486 \nQ 3600 544 3809 666 \nz\n\" id=\"DejaVuSans-47\" transform=\"scale(0.015625)\"/>\n     </defs>\n     <use xlink:href=\"#DejaVuSans-47\"/>\n     <use x=\"77.490234\" xlink:href=\"#DejaVuSans-72\"/>\n     <use x=\"118.603516\" xlink:href=\"#DejaVuSans-61\"/>\n     <use x=\"179.882812\" xlink:href=\"#DejaVuSans-64\"/>\n     <use x=\"243.359375\" xlink:href=\"#DejaVuSans-69\"/>\n     <use x=\"271.142578\" xlink:href=\"#DejaVuSans-65\"/>\n     <use x=\"332.666016\" xlink:href=\"#DejaVuSans-6e\"/>\n     <use x=\"396.044922\" xlink:href=\"#DejaVuSans-74\"/>\n     <use x=\"435.253906\" xlink:href=\"#DejaVuSans-42\"/>\n     <use x=\"503.857422\" xlink:href=\"#DejaVuSans-6f\"/>\n     <use x=\"565.039062\" xlink:href=\"#DejaVuSans-6f\"/>\n     <use x=\"626.220703\" xlink:href=\"#DejaVuSans-73\"/>\n     <use x=\"678.320312\" xlink:href=\"#DejaVuSans-74\"/>\n     <use x=\"717.529297\" xlink:href=\"#DejaVuSans-69\"/>\n     <use x=\"745.3125\" xlink:href=\"#DejaVuSans-6e\"/>\n     <use x=\"808.691406\" xlink:href=\"#DejaVuSans-67\"/>\n     <use x=\"872.167969\" xlink:href=\"#DejaVuSans-43\"/>\n     <use x=\"941.992188\" xlink:href=\"#DejaVuSans-6c\"/>\n     <use x=\"969.775391\" xlink:href=\"#DejaVuSans-61\"/>\n     <use x=\"1031.054688\" xlink:href=\"#DejaVuSans-73\"/>\n     <use x=\"1083.154297\" xlink:href=\"#DejaVuSans-73\"/>\n     <use x=\"1135.253906\" xlink:href=\"#DejaVuSans-69\"/>\n     <use x=\"1163.037109\" xlink:href=\"#DejaVuSans-66\"/>\n     <use x=\"1198.242188\" xlink:href=\"#DejaVuSans-69\"/>\n     <use x=\"1226.025391\" xlink:href=\"#DejaVuSans-65\"/>\n     <use x=\"1287.548828\" xlink:href=\"#DejaVuSans-72\"/>\n     <use x=\"1328.662109\" xlink:href=\"#DejaVuSans-28\"/>\n     <use x=\"1367.675781\" xlink:href=\"#DejaVuSans-29\"/>\n    </g>\n   </g>\n   <g id=\"PathCollection_11\">\n    <defs>\n     <path d=\"M 0 3 \nC 0.795609 3 1.55874 2.683901 2.12132 2.12132 \nC 2.683901 1.55874 3 0.795609 3 0 \nC 3 -0.795609 2.683901 -1.55874 2.12132 -2.12132 \nC 1.55874 -2.683901 0.795609 -3 0 -3 \nC -0.795609 -3 -1.55874 -2.683901 -2.12132 -2.12132 \nC -2.683901 -1.55874 -3 -0.795609 -3 0 \nC -3 0.795609 -2.683901 1.55874 -2.12132 2.12132 \nC -1.55874 2.683901 -0.795609 3 0 3 \nz\n\" id=\"mda70e704ec\" style=\"stroke:#2ca02c;\"/>\n    </defs>\n    <g>\n     <use style=\"fill:#2ca02c;stroke:#2ca02c;\" x=\"338.789861\" xlink:href=\"#mda70e704ec\" y=\"168.873437\"/>\n    </g>\n   </g>\n   <g id=\"text_19\">\n    <!-- RandomForestClassifier() -->\n    <g transform=\"translate(356.789861 171.498437)scale(0.1 -0.1)\">\n     <defs>\n      <path d=\"M 2841 2188 \nQ 3044 2119 3236 1894 \nQ 3428 1669 3622 1275 \nL 4263 0 \nL 3584 0 \nL 2988 1197 \nQ 2756 1666 2539 1819 \nQ 2322 1972 1947 1972 \nL 1259 1972 \nL 1259 0 \nL 628 0 \nL 628 4666 \nL 2053 4666 \nQ 2853 4666 3247 4331 \nQ 3641 3997 3641 3322 \nQ 3641 2881 3436 2590 \nQ 3231 2300 2841 2188 \nz\nM 1259 4147 \nL 1259 2491 \nL 2053 2491 \nQ 2509 2491 2742 2702 \nQ 2975 2913 2975 3322 \nQ 2975 3731 2742 3939 \nQ 2509 4147 2053 4147 \nL 1259 4147 \nz\n\" id=\"DejaVuSans-52\" transform=\"scale(0.015625)\"/>\n      <path d=\"M 628 4666 \nL 3309 4666 \nL 3309 4134 \nL 1259 4134 \nL 1259 2759 \nL 3109 2759 \nL 3109 2228 \nL 1259 2228 \nL 1259 0 \nL 628 0 \nL 628 4666 \nz\n\" id=\"DejaVuSans-46\" transform=\"scale(0.015625)\"/>\n     </defs>\n     <use xlink:href=\"#DejaVuSans-52\"/>\n     <use x=\"67.232422\" xlink:href=\"#DejaVuSans-61\"/>\n     <use x=\"128.511719\" xlink:href=\"#DejaVuSans-6e\"/>\n     <use x=\"191.890625\" xlink:href=\"#DejaVuSans-64\"/>\n     <use x=\"255.367188\" xlink:href=\"#DejaVuSans-6f\"/>\n     <use x=\"316.548828\" xlink:href=\"#DejaVuSans-6d\"/>\n     <use x=\"413.960938\" xlink:href=\"#DejaVuSans-46\"/>\n     <use x=\"467.855469\" xlink:href=\"#DejaVuSans-6f\"/>\n     <use x=\"529.037109\" xlink:href=\"#DejaVuSans-72\"/>\n     <use x=\"567.900391\" xlink:href=\"#DejaVuSans-65\"/>\n     <use x=\"629.423828\" xlink:href=\"#DejaVuSans-73\"/>\n     <use x=\"681.523438\" xlink:href=\"#DejaVuSans-74\"/>\n     <use x=\"720.732422\" xlink:href=\"#DejaVuSans-43\"/>\n     <use x=\"790.556641\" xlink:href=\"#DejaVuSans-6c\"/>\n     <use x=\"818.339844\" xlink:href=\"#DejaVuSans-61\"/>\n     <use x=\"879.619141\" xlink:href=\"#DejaVuSans-73\"/>\n     <use x=\"931.71875\" xlink:href=\"#DejaVuSans-73\"/>\n     <use x=\"983.818359\" xlink:href=\"#DejaVuSans-69\"/>\n     <use x=\"1011.601562\" xlink:href=\"#DejaVuSans-66\"/>\n     <use x=\"1046.806641\" xlink:href=\"#DejaVuSans-69\"/>\n     <use x=\"1074.589844\" xlink:href=\"#DejaVuSans-65\"/>\n     <use x=\"1136.113281\" xlink:href=\"#DejaVuSans-72\"/>\n     <use x=\"1177.226562\" xlink:href=\"#DejaVuSans-28\"/>\n     <use x=\"1216.240234\" xlink:href=\"#DejaVuSans-29\"/>\n    </g>\n   </g>\n   <g id=\"PathCollection_12\">\n    <defs>\n     <path d=\"M 0 3 \nC 0.795609 3 1.55874 2.683901 2.12132 2.12132 \nC 2.683901 1.55874 3 0.795609 3 0 \nC 3 -0.795609 2.683901 -1.55874 2.12132 -2.12132 \nC 1.55874 -2.683901 0.795609 -3 0 -3 \nC -0.795609 -3 -1.55874 -2.683901 -2.12132 -2.12132 \nC -2.683901 -1.55874 -3 -0.795609 -3 0 \nC -3 0.795609 -2.683901 1.55874 -2.12132 2.12132 \nC -1.55874 2.683901 -0.795609 3 0 3 \nz\n\" id=\"me0d3db2f6c\" style=\"stroke:#d62728;\"/>\n    </defs>\n    <g>\n     <use style=\"fill:#d62728;stroke:#d62728;\" x=\"338.789861\" xlink:href=\"#me0d3db2f6c\" y=\"183.551562\"/>\n    </g>\n   </g>\n   <g id=\"text_20\">\n    <!-- DecisionTreeClassifier() -->\n    <g transform=\"translate(356.789861 186.176562)scale(0.1 -0.1)\">\n     <defs>\n      <path d=\"M 1259 4147 \nL 1259 519 \nL 2022 519 \nQ 2988 519 3436 956 \nQ 3884 1394 3884 2338 \nQ 3884 3275 3436 3711 \nQ 2988 4147 2022 4147 \nL 1259 4147 \nz\nM 628 4666 \nL 1925 4666 \nQ 3281 4666 3915 4102 \nQ 4550 3538 4550 2338 \nQ 4550 1131 3912 565 \nQ 3275 0 1925 0 \nL 628 0 \nL 628 4666 \nz\n\" id=\"DejaVuSans-44\" transform=\"scale(0.015625)\"/>\n      <path d=\"M -19 4666 \nL 3928 4666 \nL 3928 4134 \nL 2272 4134 \nL 2272 0 \nL 1638 0 \nL 1638 4134 \nL -19 4134 \nL -19 4666 \nz\n\" id=\"DejaVuSans-54\" transform=\"scale(0.015625)\"/>\n     </defs>\n     <use xlink:href=\"#DejaVuSans-44\"/>\n     <use x=\"77.001953\" xlink:href=\"#DejaVuSans-65\"/>\n     <use x=\"138.525391\" xlink:href=\"#DejaVuSans-63\"/>\n     <use x=\"193.505859\" xlink:href=\"#DejaVuSans-69\"/>\n     <use x=\"221.289062\" xlink:href=\"#DejaVuSans-73\"/>\n     <use x=\"273.388672\" xlink:href=\"#DejaVuSans-69\"/>\n     <use x=\"301.171875\" xlink:href=\"#DejaVuSans-6f\"/>\n     <use x=\"362.353516\" xlink:href=\"#DejaVuSans-6e\"/>\n     <use x=\"425.732422\" xlink:href=\"#DejaVuSans-54\"/>\n     <use x=\"472.066406\" xlink:href=\"#DejaVuSans-72\"/>\n     <use x=\"510.929688\" xlink:href=\"#DejaVuSans-65\"/>\n     <use x=\"572.453125\" xlink:href=\"#DejaVuSans-65\"/>\n     <use x=\"633.976562\" xlink:href=\"#DejaVuSans-43\"/>\n     <use x=\"703.800781\" xlink:href=\"#DejaVuSans-6c\"/>\n     <use x=\"731.583984\" xlink:href=\"#DejaVuSans-61\"/>\n     <use x=\"792.863281\" xlink:href=\"#DejaVuSans-73\"/>\n     <use x=\"844.962891\" xlink:href=\"#DejaVuSans-73\"/>\n     <use x=\"897.0625\" xlink:href=\"#DejaVuSans-69\"/>\n     <use x=\"924.845703\" xlink:href=\"#DejaVuSans-66\"/>\n     <use x=\"960.050781\" xlink:href=\"#DejaVuSans-69\"/>\n     <use x=\"987.833984\" xlink:href=\"#DejaVuSans-65\"/>\n     <use x=\"1049.357422\" xlink:href=\"#DejaVuSans-72\"/>\n     <use x=\"1090.470703\" xlink:href=\"#DejaVuSans-28\"/>\n     <use x=\"1129.484375\" xlink:href=\"#DejaVuSans-29\"/>\n    </g>\n   </g>\n   <g id=\"PathCollection_13\">\n    <defs>\n     <path d=\"M 0 3 \nC 0.795609 3 1.55874 2.683901 2.12132 2.12132 \nC 2.683901 1.55874 3 0.795609 3 0 \nC 3 -0.795609 2.683901 -1.55874 2.12132 -2.12132 \nC 1.55874 -2.683901 0.795609 -3 0 -3 \nC -0.795609 -3 -1.55874 -2.683901 -2.12132 -2.12132 \nC -2.683901 -1.55874 -3 -0.795609 -3 0 \nC -3 0.795609 -2.683901 1.55874 -2.12132 2.12132 \nC -1.55874 2.683901 -0.795609 3 0 3 \nz\n\" id=\"m660aaeceeb\" style=\"stroke:#9467bd;\"/>\n    </defs>\n    <g>\n     <use style=\"fill:#9467bd;stroke:#9467bd;\" x=\"338.789861\" xlink:href=\"#m660aaeceeb\" y=\"198.229687\"/>\n    </g>\n   </g>\n   <g id=\"text_21\">\n    <!-- ExtraTreesClassifier() -->\n    <g transform=\"translate(356.789861 200.854687)scale(0.1 -0.1)\">\n     <defs>\n      <path d=\"M 628 4666 \nL 3578 4666 \nL 3578 4134 \nL 1259 4134 \nL 1259 2753 \nL 3481 2753 \nL 3481 2222 \nL 1259 2222 \nL 1259 531 \nL 3634 531 \nL 3634 0 \nL 628 0 \nL 628 4666 \nz\n\" id=\"DejaVuSans-45\" transform=\"scale(0.015625)\"/>\n      <path d=\"M 3513 3500 \nL 2247 1797 \nL 3578 0 \nL 2900 0 \nL 1881 1375 \nL 863 0 \nL 184 0 \nL 1544 1831 \nL 300 3500 \nL 978 3500 \nL 1906 2253 \nL 2834 3500 \nL 3513 3500 \nz\n\" id=\"DejaVuSans-78\" transform=\"scale(0.015625)\"/>\n     </defs>\n     <use xlink:href=\"#DejaVuSans-45\"/>\n     <use x=\"63.183594\" xlink:href=\"#DejaVuSans-78\"/>\n     <use x=\"122.363281\" xlink:href=\"#DejaVuSans-74\"/>\n     <use x=\"161.572266\" xlink:href=\"#DejaVuSans-72\"/>\n     <use x=\"202.685547\" xlink:href=\"#DejaVuSans-61\"/>\n     <use x=\"263.964844\" xlink:href=\"#DejaVuSans-54\"/>\n     <use x=\"310.298828\" xlink:href=\"#DejaVuSans-72\"/>\n     <use x=\"349.162109\" xlink:href=\"#DejaVuSans-65\"/>\n     <use x=\"410.685547\" xlink:href=\"#DejaVuSans-65\"/>\n     <use x=\"472.208984\" xlink:href=\"#DejaVuSans-73\"/>\n     <use x=\"524.308594\" xlink:href=\"#DejaVuSans-43\"/>\n     <use x=\"594.132812\" xlink:href=\"#DejaVuSans-6c\"/>\n     <use x=\"621.916016\" xlink:href=\"#DejaVuSans-61\"/>\n     <use x=\"683.195312\" xlink:href=\"#DejaVuSans-73\"/>\n     <use x=\"735.294922\" xlink:href=\"#DejaVuSans-73\"/>\n     <use x=\"787.394531\" xlink:href=\"#DejaVuSans-69\"/>\n     <use x=\"815.177734\" xlink:href=\"#DejaVuSans-66\"/>\n     <use x=\"850.382812\" xlink:href=\"#DejaVuSans-69\"/>\n     <use x=\"878.166016\" xlink:href=\"#DejaVuSans-65\"/>\n     <use x=\"939.689453\" xlink:href=\"#DejaVuSans-72\"/>\n     <use x=\"980.802734\" xlink:href=\"#DejaVuSans-28\"/>\n     <use x=\"1019.816406\" xlink:href=\"#DejaVuSans-29\"/>\n    </g>\n   </g>\n   <g id=\"PathCollection_14\">\n    <defs>\n     <path d=\"M 0 3 \nC 0.795609 3 1.55874 2.683901 2.12132 2.12132 \nC 2.683901 1.55874 3 0.795609 3 0 \nC 3 -0.795609 2.683901 -1.55874 2.12132 -2.12132 \nC 1.55874 -2.683901 0.795609 -3 0 -3 \nC -0.795609 -3 -1.55874 -2.683901 -2.12132 -2.12132 \nC -2.683901 -1.55874 -3 -0.795609 -3 0 \nC -3 0.795609 -2.683901 1.55874 -2.12132 2.12132 \nC -1.55874 2.683901 -0.795609 3 0 3 \nz\n\" id=\"mc8050c364d\" style=\"stroke:#8c564b;\"/>\n    </defs>\n    <g>\n     <use style=\"fill:#8c564b;stroke:#8c564b;\" x=\"338.789861\" xlink:href=\"#mc8050c364d\" y=\"212.907812\"/>\n    </g>\n   </g>\n   <g id=\"text_22\">\n    <!-- SVC(C=1000, gamma='auto') -->\n    <g transform=\"translate(356.789861 215.532812)scale(0.1 -0.1)\">\n     <defs>\n      <path d=\"M 3425 4513 \nL 3425 3897 \nQ 3066 4069 2747 4153 \nQ 2428 4238 2131 4238 \nQ 1616 4238 1336 4038 \nQ 1056 3838 1056 3469 \nQ 1056 3159 1242 3001 \nQ 1428 2844 1947 2747 \nL 2328 2669 \nQ 3034 2534 3370 2195 \nQ 3706 1856 3706 1288 \nQ 3706 609 3251 259 \nQ 2797 -91 1919 -91 \nQ 1588 -91 1214 -16 \nQ 841 59 441 206 \nL 441 856 \nQ 825 641 1194 531 \nQ 1563 422 1919 422 \nQ 2459 422 2753 634 \nQ 3047 847 3047 1241 \nQ 3047 1584 2836 1778 \nQ 2625 1972 2144 2069 \nL 1759 2144 \nQ 1053 2284 737 2584 \nQ 422 2884 422 3419 \nQ 422 4038 858 4394 \nQ 1294 4750 2059 4750 \nQ 2388 4750 2728 4690 \nQ 3069 4631 3425 4513 \nz\n\" id=\"DejaVuSans-53\" transform=\"scale(0.015625)\"/>\n      <path d=\"M 1831 0 \nL 50 4666 \nL 709 4666 \nL 2188 738 \nL 3669 4666 \nL 4325 4666 \nL 2547 0 \nL 1831 0 \nz\n\" id=\"DejaVuSans-56\" transform=\"scale(0.015625)\"/>\n      <path d=\"M 678 2906 \nL 4684 2906 \nL 4684 2381 \nL 678 2381 \nL 678 2906 \nz\nM 678 1631 \nL 4684 1631 \nL 4684 1100 \nL 678 1100 \nL 678 1631 \nz\n\" id=\"DejaVuSans-3d\" transform=\"scale(0.015625)\"/>\n      <path d=\"M 750 794 \nL 1409 794 \nL 1409 256 \nL 897 -744 \nL 494 -744 \nL 750 256 \nL 750 794 \nz\n\" id=\"DejaVuSans-2c\" transform=\"scale(0.015625)\"/>\n      <path id=\"DejaVuSans-20\" transform=\"scale(0.015625)\"/>\n      <path d=\"M 1147 4666 \nL 1147 2931 \nL 616 2931 \nL 616 4666 \nL 1147 4666 \nz\n\" id=\"DejaVuSans-27\" transform=\"scale(0.015625)\"/>\n      <path d=\"M 544 1381 \nL 544 3500 \nL 1119 3500 \nL 1119 1403 \nQ 1119 906 1312 657 \nQ 1506 409 1894 409 \nQ 2359 409 2629 706 \nQ 2900 1003 2900 1516 \nL 2900 3500 \nL 3475 3500 \nL 3475 0 \nL 2900 0 \nL 2900 538 \nQ 2691 219 2414 64 \nQ 2138 -91 1772 -91 \nQ 1169 -91 856 284 \nQ 544 659 544 1381 \nz\nM 1991 3584 \nL 1991 3584 \nz\n\" id=\"DejaVuSans-75\" transform=\"scale(0.015625)\"/>\n     </defs>\n     <use xlink:href=\"#DejaVuSans-53\"/>\n     <use x=\"63.476562\" xlink:href=\"#DejaVuSans-56\"/>\n     <use x=\"131.884766\" xlink:href=\"#DejaVuSans-43\"/>\n     <use x=\"201.708984\" xlink:href=\"#DejaVuSans-28\"/>\n     <use x=\"240.722656\" xlink:href=\"#DejaVuSans-43\"/>\n     <use x=\"310.546875\" xlink:href=\"#DejaVuSans-3d\"/>\n     <use x=\"394.335938\" xlink:href=\"#DejaVuSans-31\"/>\n     <use x=\"457.958984\" xlink:href=\"#DejaVuSans-30\"/>\n     <use x=\"521.582031\" xlink:href=\"#DejaVuSans-30\"/>\n     <use x=\"585.205078\" xlink:href=\"#DejaVuSans-30\"/>\n     <use x=\"648.828125\" xlink:href=\"#DejaVuSans-2c\"/>\n     <use x=\"680.615234\" xlink:href=\"#DejaVuSans-20\"/>\n     <use x=\"712.402344\" xlink:href=\"#DejaVuSans-67\"/>\n     <use x=\"775.878906\" xlink:href=\"#DejaVuSans-61\"/>\n     <use x=\"837.158203\" xlink:href=\"#DejaVuSans-6d\"/>\n     <use x=\"934.570312\" xlink:href=\"#DejaVuSans-6d\"/>\n     <use x=\"1031.982422\" xlink:href=\"#DejaVuSans-61\"/>\n     <use x=\"1093.261719\" xlink:href=\"#DejaVuSans-3d\"/>\n     <use x=\"1177.050781\" xlink:href=\"#DejaVuSans-27\"/>\n     <use x=\"1204.541016\" xlink:href=\"#DejaVuSans-61\"/>\n     <use x=\"1265.820312\" xlink:href=\"#DejaVuSans-75\"/>\n     <use x=\"1329.199219\" xlink:href=\"#DejaVuSans-74\"/>\n     <use x=\"1368.408203\" xlink:href=\"#DejaVuSans-6f\"/>\n     <use x=\"1429.589844\" xlink:href=\"#DejaVuSans-27\"/>\n     <use x=\"1457.080078\" xlink:href=\"#DejaVuSans-29\"/>\n    </g>\n   </g>\n   <g id=\"PathCollection_15\">\n    <defs>\n     <path d=\"M 0 3 \nC 0.795609 3 1.55874 2.683901 2.12132 2.12132 \nC 2.683901 1.55874 3 0.795609 3 0 \nC 3 -0.795609 2.683901 -1.55874 2.12132 -2.12132 \nC 1.55874 -2.683901 0.795609 -3 0 -3 \nC -0.795609 -3 -1.55874 -2.683901 -2.12132 -2.12132 \nC -2.683901 -1.55874 -3 -0.795609 -3 0 \nC -3 0.795609 -2.683901 1.55874 -2.12132 2.12132 \nC -1.55874 2.683901 -0.795609 3 0 3 \nz\n\" id=\"m1a2dd60c73\" style=\"stroke:#e377c2;\"/>\n    </defs>\n    <g>\n     <use style=\"fill:#e377c2;stroke:#e377c2;\" x=\"338.789861\" xlink:href=\"#m1a2dd60c73\" y=\"227.585937\"/>\n    </g>\n   </g>\n   <g id=\"text_23\">\n    <!-- SGDClassifier(random_state=2021) -->\n    <g transform=\"translate(356.789861 230.210937)scale(0.1 -0.1)\">\n     <use xlink:href=\"#DejaVuSans-53\"/>\n     <use x=\"63.476562\" xlink:href=\"#DejaVuSans-47\"/>\n     <use x=\"140.966797\" xlink:href=\"#DejaVuSans-44\"/>\n     <use x=\"217.96875\" xlink:href=\"#DejaVuSans-43\"/>\n     <use x=\"287.792969\" xlink:href=\"#DejaVuSans-6c\"/>\n     <use x=\"315.576172\" xlink:href=\"#DejaVuSans-61\"/>\n     <use x=\"376.855469\" xlink:href=\"#DejaVuSans-73\"/>\n     <use x=\"428.955078\" xlink:href=\"#DejaVuSans-73\"/>\n     <use x=\"481.054688\" xlink:href=\"#DejaVuSans-69\"/>\n     <use x=\"508.837891\" xlink:href=\"#DejaVuSans-66\"/>\n     <use x=\"544.042969\" xlink:href=\"#DejaVuSans-69\"/>\n     <use x=\"571.826172\" xlink:href=\"#DejaVuSans-65\"/>\n     <use x=\"633.349609\" xlink:href=\"#DejaVuSans-72\"/>\n     <use x=\"674.462891\" xlink:href=\"#DejaVuSans-28\"/>\n     <use x=\"713.476562\" xlink:href=\"#DejaVuSans-72\"/>\n     <use x=\"754.589844\" xlink:href=\"#DejaVuSans-61\"/>\n     <use x=\"815.869141\" xlink:href=\"#DejaVuSans-6e\"/>\n     <use x=\"879.248047\" xlink:href=\"#DejaVuSans-64\"/>\n     <use x=\"942.724609\" xlink:href=\"#DejaVuSans-6f\"/>\n     <use x=\"1003.90625\" xlink:href=\"#DejaVuSans-6d\"/>\n     <use x=\"1101.318359\" xlink:href=\"#DejaVuSans-5f\"/>\n     <use x=\"1151.318359\" xlink:href=\"#DejaVuSans-73\"/>\n     <use x=\"1203.417969\" xlink:href=\"#DejaVuSans-74\"/>\n     <use x=\"1242.626953\" xlink:href=\"#DejaVuSans-61\"/>\n     <use x=\"1303.90625\" xlink:href=\"#DejaVuSans-74\"/>\n     <use x=\"1343.115234\" xlink:href=\"#DejaVuSans-65\"/>\n     <use x=\"1404.638672\" xlink:href=\"#DejaVuSans-3d\"/>\n     <use x=\"1488.427734\" xlink:href=\"#DejaVuSans-32\"/>\n     <use x=\"1552.050781\" xlink:href=\"#DejaVuSans-30\"/>\n     <use x=\"1615.673828\" xlink:href=\"#DejaVuSans-32\"/>\n     <use x=\"1679.296875\" xlink:href=\"#DejaVuSans-31\"/>\n     <use x=\"1742.919922\" xlink:href=\"#DejaVuSans-29\"/>\n    </g>\n   </g>\n  </g>\n </g>\n <defs>\n  <clipPath id=\"pbe494d9388\">\n   <rect height=\"307.4\" width=\"278.009861\" x=\"43.78125\" y=\"7.2\"/>\n  </clipPath>\n </defs>\n</svg>\n",
      "image/png": "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"
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.9.6",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.6 64-bit ('base': conda)"
  },
  "interpreter": {
   "hash": "95ec9ec1504d83f612128e0fb229072f90bbb4cb09d9d5d93b5dd26e0ca2cfd1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}